---
title: "Fgrandis_ad/intr"
author: "Elias"
date: "May 11, 2018"
output: html_document
---

Fundulus grandis adapting to contamination

#Files

##Uploading files to NCBI

```{r}
library(XML)
library(tidyr)
library(stringr)
library(dplyr)
library(gtools)
library(naturalsort)
library(RCurl)
library(ggplot2)
library(reshape2)

```

## Downloaded .bam files to computer
```{bash}
#log into NIH
ftp ftp-private.ncbi.nlm.nih.gov
#Go to directory
cd uploads/oziolor@gmail.com_4XM4FcAt/new_folder
#turn off interactive mode so it doesn't ask you to submit each freaking sample
prompt
#Submit all samples
mput BU*
```

#Trimming
## Trimming fastq files

```{bash}
java -jar ~/Computing/Trimmomatic-0.33/trimmomatic-0.33.jar PE
-basein ~/share/Project_Project1/Sample_BU(write_out)/*R1_001.fastq.gz
-baseout ~/share/Project_Project1/Sample_BU(write_out)/BU(write_out).fastq.gz
ILLUMINACLIP:Computing/Trimmomatic-0.33/adapters/TruSeq3-PE-2.fa:2:30:10 LEADING:3 TRAILING:3 SLIDINGWINDOW:4:15 MINLEN:36 HEADCROP:6
```

#Mapping and variant calling

## Mapping in groups of 50 for speed

```{bash}
#!/bin/bash

BWA=/home/oziolore/restoreFromData/program/bwa-0.7.15/bwa
SBL=/home/oziolore/restoreFromData/program/samblaster/samblaster
outdir=/home/oziolore/restoreFromData/fhet/data/align2/
genome=/home/oziolore/restoreFromData/fhet/data/genome2/unsplit_merge.fasta
stools=/home/oziolore/restoreFromData/program/samtools-1.5/samtools

for i in {004..050}
        do
	fq1=/home/oziolore/restoreFromData/fhet/data/unmapped/combined1P_BU000$i.fastq.gz
        fq2=/home/oziolore/restoreFromData/fhet/data/unmapped/combined2P_BU000$i.fastq.gz
        sam=$(echo $fq1 | grep -oP "BU[0-9]+")
        pop=$(cat /home/oziolore/restoreFromData/fhet/data/list/pop_samples | grep $sam | cut -f 2)
        rg=$(echo \@RG\\tID:$sam.combined\\tPL:Illumina\\tPU:x\\tLB:combined\\tSM:$sam.$pop)
        outdir=/home/oziolore/restoreFromData/fhet/data/align2
        outroot=$sam\_$pop
        cmdline=$BWA\ mem\ $genome\ -t\ 2\ -R\ $rg\ $fq1\ $fq2
        $cmdline | $SBL -e -d $outdir/$outroot.disc.sam -s $outdir/$outroot.split.sam | \
        $stools view -S -h -u - | \
        $stools sort -T $outdir/$outroot - > $outdir/$outroot.bam
done

```

## Excluding high coverage regions

* start by getting coverage over the genome

```{bash}
/data/oziolore/program/samtools-1.5/samtools depth \
-d 10000 /data/oziolore/fhet/data/align2/all_merged2.bam | \
gzip > /data/oziolore/fhet/data/coverage2/coverage_allbases.txt.gz
```

* Get a random 10Mb chunk of the genome to see distribution
  + load a fasta file and do this

```{r}
#Getting 10Mb of random regions to makea decision on [cluster]

#!/bin/bash
dir=/home/oziolore/restoreFromData/fhet/data/coverage

zcat $dir/coverage_allbases.txt.gz | \
sort -R | \
head -n 10000000 | \
gzip > $dir/cov_10Mbrand.txt.gz

#used the following line to create a genome file in the /genome2/ subfolder
awk -v OFS='\t' {'print $1,$2'} $fai > $genome
```

* Plot it to see distribution

```{r}
setwd("~/analysis/data/admixture/")
cov<-read.table("~/analysis/data/angsd/cov_10Mbrand.txt.gz",header=F)
names<-c("chrom","pos","cov")

hist(cov$cov,breaks=1000)

subw<-cov$cov<300
hist(cov[subw,"cov"],breaks=1000)
summary(cov$cov)
summary(cov[subw,"cov"])
```

* group these regions in a file

```{bash}
zcat /data/oziolore/fhet/data/coverage2/coverage_allbases2.txt.gz | \
awk '{OFS="\t"}{s=$2-1}{print $1,s,$2,$3}' | \
awk '{OFS="\t"}{if($4>200){print}}' | \
/data/oziolore/program/bedtools2/bin/bedtools merge -i - -d 10 -c 4 -o count > /data/oziolore/fhet/data/coverage2/hicov.bed
```

* Check how much of the genome you threw out

```{r}
setwd("~/")
hi<-read.table("~/hicov.bed",header=F)
sum(hi[,4])
```

## Variant calling with freebayes

* Check number of scaffolds you have and sub your job into that many under jobs

```{bash}
#!/bin/bash
#PBS -l nodes=1:ppn=1
#PBS -J 1-2000
cd /home/oziolore/restoreFromData/fhet/data/varcall/scaffold/


#files
genome=/home/oziolore/restoreFromData/fhet/data/genome2/unsplit_merge.fasta
my_fai=/home/oziolore/restoreFromData/fhet/data/genome2/unsplit_merge.fasta.fai
mergebam=/home/oziolore/restoreFromData/fhet/data/align2/all_merged2.bam
popsfile=/home/oziolore/restoreFromData/fhet/data/list2/populations2.txt
hicov=/home/oziolore/restoreFromData/fhet/data/coverage2/hicov.bed
reg_file=/home/oziolore/restoreFromData/fhet/data/genome2/unsplit_merge.genome

#programs
my_freebayes=/home/oziolore/restoreFromData/program/freebayes/bin/freebayes
my_samtools=/home/oziolore/restoreFromData/program/samtools-1.5/samtools
my_bgz=/home/oziolore/restoreFromData/program/htslib/bgzip
my_bedtools=/home/oziolore/restoreFromData/program/bedtools2/bin/bedtools

#region to investigate

crap=$(echo $PBS_ARRAY_INDEX)
scaf=$(sed "$crap q;d" $reg_file | cut -f1)
end=$(sed "$crap q;d" $reg_file | cut -f2)
region=$scaf:1-$end 

#directories and files

outdir=/home/oziolore/restoreFromData/fhet/data/varcall/scaffold/
outfile=$scaf.vcf.bgz

$my_samtools view -q 30 -f 2 -h -b  $mergebam $region | \
$my_bedtools intersect -v -a stdin -b $hicov | \
$my_freebayes $regions 36 -f $genome --populations $popsfile --stdin | \
$my_bgz > $outdir/$outfile

echo $outdir
echo $region
echo $outfile
echo $crap

```

#Divergence statistics #1

## FST with Weir and Cockerham

* using vcflib you can do pairwise Fst for all organisms

```{bash}
#!/bin/bash

#PBS -l nodes=1:ppn=1
#PBS -J 1-21

cd /home/oziolore/restoreFromData/fhet/scripts/fst/

pops=BB\ VB\ PB\ SJ\ BNP\ GB\ SP
outdir=/data/oziolore/fhet/data/fst2
popfile=/data/oziolore/fhet/data/list2/pop_samples
my_wcfst=/data/oziolore/program/vcflib/bin/wcFst
my_pfst=/data/oziolore/program/vcflib/bin/pFst
my_vcf=/data/oziolore/fhet/data/varcall/filtered_chr.vcf.bgz
my_bgzip=/data/oziolore/program/htslib/bgzip


pair=$(for i in {1..6}
do
	ii=$(expr $i + 1)
	for j in $(seq $ii 7)
	do echo $pops | cut -f $i,$j -d ' '
done
done | \
sed -n "$(echo $PBS_ARRAY_INDEX)p")

echo $PBS_ARRAY_INDEX

pop1=$(echo $pair | cut -f 1 -d ' ')
pop2=$(echo $pair | cut -f 2 -d ' ')

echo $pop1 $pop2

target=$(grep -n $pop1 $popfile | cut -f 1 -d ":" | awk '{s=$1-1}{print s}' | tr '\n' ',' | \
sed 's/,$//')

background=$(grep -n $pop2 $popfile | cut -f 1 -d ":" | awk '{s=$1-1}{print s}' | tr '\n' ',' | \
sed 's/,$//')

outfile1=$pop1.$pop2.wcfst.bgz
outfile2=$pop1.$pop2.pfst.bgz

out1=$outdir/$outfile1
out2=$outdir/$outfile2

echo $out1
echo $out2

echo $target
echo $background
echo $outfile1
echo $outfile2

$my_wcfst \
--target $target \
--background $background \
--file $my_vcf \
--type GL | \
$my_bgzip>$out1

$my_pfst \
--target $target \
--background $background \
--file $my_vcf \
--type GL | \
$my_bgzip>$out2

```

* merging these to 1kb windows

```{bash}
#!/bin/bash

#PBS -l nodes=1:ppn=8
#PBS -l walltime=24:00:00

#program/file
fst_files=/data/oziolore/fhet/data/fst2
my_bedtools=/data/oziolore/program/bedtools2/bin/bedtools
my_genome=/data/oziolore/fhet/data/genome2/unsplit_merge.genome
my_window=/data/oziolore/fhet/data/windows2/new_noah.1kb.bed

for file in /data/oziolore/fhet/data/fst2/*wcfst.bgz
do
	outfile=$(echo $file | sed 's/wcfst.bgz/fst.1kb.bed/')

	zcat $file | \
	awk '{OFS="\t"}{s=$2-1}{print $1,s,$2,$5}' | \
	$my_bedtools map \
	-a $my_window \
	-b stdin \
	-g $my_genome \
	-c 4 \
	-o mean,count> $outfile
done

```

* Compare these with estimates of Hudson's Fst

#Comparisons
* I am comparing fst data calculated with Weir&Cockerham 1984 (with correction for sample size) to one calculated from pi
* Comparing pi calculated by comparing individual snps to one calculated by SFS in ANGSD


##Fst statistic

* Weir & Cockerham Fst estimation includes correction for sample size
    + that has given some odd substructuring paterns for BB and SJ, which Noah has noticed are not present when Fst is calculated from pi (1-mean(pi1,pi2)/dxy)
    
* Let's take Noah's data where pi and dxy are calculated on a per SNP basis and take global and local Fst plots from that.

#Neutrality statistics

##calculation of pi and dxy by hand

```{r}
library(dplyr)
library(stringr)

cname <- c(
	"CHROM",
	"POS",
	"ID",
	"REF",
	"ALT",
	"QUAL",
	"FILTER",
	"INFO",
	"FORMAT",
	"BP-10",
	"BP-11",
	"BP-12",
	"BP-13",
	"BP-14",
	"BP-15",
	"BP-16",
	"BP-17",
	"BP-18",
	"BP-19",
	"BP-1",
	"BP-20",
	"BP-21",
	"BP-22",
	"BP-23",
	"BP-24",
	"BP-25",
	"BP-26",
	"BP-27",
	"BP-28",
	"BP-29",
	"BP-2",
	"BP-30",
	"BP-31",
	"BP-32",
	"BP-33",
	"BP-34",
	"BP-38",
	"BP-39",
	"BP-3",
	"BP-40",
	"BP-41",
	"BP-42",
	"BP-43",
	"BP-44",
	"BP-45",
	"BP-46",
	"BP-47",
	"BP-48",
	"BP-49",
	"BP-4",
	"BP-50",
	"BP-51",
	"BP-52",
	"BP-53",
	"BP-5",
	"BP-6",
	"BP-7",
	"BP-8",
	"BP-9",
	"ER-11",
	"ER-12",
	"ER-13",
	"ER-14",
	"ER-15",
	"ER-16",
	"ER-17",
	"ER-18",
	"ER-19",
	"ER-20",
	"ER-21",
	"ER-22",
	"ER-23",
	"ER-24",
	"ER-25",
	"ER-26",
	"ER-27",
	"ER-28",
	"ER-29",
	"ER-30",
	"ER-31",
	"ER-32",
	"ER-33",
	"ER-34",
	"ER-35",
	"ER-36",
	"ER-38",
	"ER-39",
	"ER-40",
	"ER-41",
	"ER-42",
	"ER-43",
	"ER-44",
	"ER-45",
	"ER-46",
	"ER-47",
	"ER-48",
	"ER-49",
	"ER-50",
	"ER-51",
	"ER-52",
	"ER-53",
	"ER-54",
	"ER-55",
	"ER-56",
	"ER-57",
	"ER-58",
	"ER-59",
	"ER-60",
	"F-10",
	"F-11",
	"F-12",
	"F-13",
	"F-14",
	"F-15",
	"F-16",
	"F-17",
	"F-18",
	"F-19",
	"F-1",
	"F-20",
	"F-21",
	"F-22",
	"F-23",
	"F-24",
	"F-25",
	"F-26",
	"F-27",
	"F-28",
	"F-29",
	"F-2",
	"F-30",
	"F-31",
	"F-32",
	"F-33",
	"F-34",
	"F-35",
	"F-39",
	"F-40",
	"F-41",
	"F-42",
	"F-43",
	"F-44",
	"F-45",
	"F-46",
	"F-47",
	"F-49",
	"F-4",
	"F-50",
	"F-51",
	"F-52",
	"F-53",
	"F-54",
	"F-5",
	"F-6",
	"F-7",
	"F-8",
	"F-9",
	"KC-11",
	"KC-13",
	"KC-14",
	"KC-15",
	"KC-16",
	"KC-18",
	"KC-19",
	"KC-1",
	"KC-20",
	"KC-22",
	"KC-23",
	"KC-26",
	"KC-27",
	"KC-28",
	"KC-29",
	"KC-2",
	"KC-30",
	"KC-32",
	"KC-33",
	"KC-34",
	"KC-35",
	"KC-36",
	"KC-37",
	"KC-38",
	"KC-39",
	"KC-3",
	"KC-40",
	"KC-41",
	"KC-42",
	"KC-43",
	"KC-44",
	"KC-45",
	"KC-46",
	"KC-47",
	"KC-48",
	"KC-49",
	"KC-4",
	"KC-50",
	"KC-51",
	"KC-52",
	"KC-54",
	"KC-55",
	"KC-56",
	"KC-5",
	"KC-6",
	"KC-7",
	"KC-9",
	"NYC-10",
	"NYC-11",
	"NYC-12",
	"NYC-13",
	"NYC-14",
	"NYC-15",
	"NYC-16",
	"NYC-17",
	"NYC-18",
	"NYC-19",
	"NYC-20",
	"NYC-21",
	"NYC-22",
	"NYC-23",
	"NYC-24",
	"NYC-25",
	"NYC-26",
	"NYC-27",
	"NYC-28",
	"NYC-29",
	"NYC-30",
	"NYC-31",
	"NYC-32",
	"NYC-33",
	"NYC-34",
	"NYC-40",
	"NYC-41",
	"NYC-42",
	"NYC-43",
	"NYC-44",
	"NYC-45",
	"NYC-46",
	"NYC-47",
	"NYC-48",
	"NYC-49",
	"NYC-50",
	"NYC-51",
	"NYC-52",
	"NYC-53",
	"NYC-54",
	"NYC-55",
	"NYC-8",
	"NYC-9",
	"SH-14",
	"SH-15",
	"SH-16",
	"SH-17",
	"SH-18",
	"SH-19",
	"SH-1",
	"SH-201",
	"SH-202",
	"SH-203",
	"SH-204",
	"SH-205",
	"SH-206",
	"SH-207",
	"SH-208",
	"SH-209",
	"SH-20",
	"SH-210",
	"SH-211",
	"SH-212",
	"SH-213",
	"SH-21",
	"SH-22",
	"SH-23",
	"SH-24",
	"SH-25",
	"SH-26",
	"SH-27",
	"SH-28",
	"SH-29",
	"SH-2",
	"SH-30",
	"SH-31",
	"SH-32",
	"SH-33",
	"SH-34",
	"SH-35",
	"SH-36",
	"SH-37",
	"SH-38",
	"SH-39",
	"SH-3",
	"SH-40",
	"SH-41",
	"SH-42",
	"SH-4",
	"SH-5",
	"SH-6",
	"SH-7",
	"SH-8",
	"BU000004.VB_B",
	"BU000005.VB_B",
	"BU000006.VB_B",
	"BU000007.VB_B",
	"BU000008.VB_B",
	"BU000012.SP",
	"BU000014.SP",
	"BU000017.SP",
	"BU000018.SP",
	"BU000023.SP",
	"BU000024.SP",
	"BU000025.SP",
	"BU000031.SP",
	"BU000032.SP",
	"BU000033.SP",
	"BU000035.SP",
	"BU000036.SP",
	"BU000037.SP",
	"BU000039.SP",
	"BU000041.SP",
	"BU000046.SP",
	"BU000048.SP",
	"BU000049.SP",
	"BU000052.SP",
	"BU000053.SP",
	"BU000054.SP",
	"BU000055.SP",
	"BU000056.SP",
	"BU000057.SP",
	"BU000062.GB",
	"BU000063.GB",
	"BU000064.GB",
	"BU000065.GB",
	"BU000066.GB",
	"BU000067.GB",
	"BU000068.GB",
	"BU000069.GB",
	"BU000070.GB",
	"BU000071.GB",
	"BU000072.GB",
	"BU000073.GB",
	"BU000074.GB",
	"BU000075.GB",
	"BU000076.GB",
	"BU000077.GB",
	"BU000078.GB",
	"BU000081.GB",
	"BU000082.GB",
	"BU000083.GB",
	"BU000084.GB",
	"BU000085.GB",
	"BU000086.GB",
	"BU000087.GB",
	"BU000088.GB",
	"BU000089.GB",
	"BU000090.GB",
	"BU000092.GB",
	"BU000093.GB",
	"BU000094.GB",
	"BU000095.GB",
	"BU000097.GB",
	"BU000100.GB",
	"BU000101.GB",
	"BU000102.GB",
	"BU000103.GB",
	"BU000104.GB",
	"BU000105.GB",
	"BU000106.GB",
	"BU000110.GB",
	"BU000116.GB",
	"BU000120.GB",
	"BU000121.GB",
	"BU000123.GB",
	"BU000124.GB",
	"BU000125.GB",
	"BU000126.GB",
	"BU000127.GB",
	"BU000129.VB_A",
	"BU000130.VB_A",
	"BU000131.VB_A",
	"BU000132.VB_A",
	"BU000133.VB_A",
	"BU000134.VB_A",
	"BU000135.VB_A",
	"BU000136.VB_A",
	"BU000137.VB_A",
	"BU000138.VB_A",
	"BU000139.VB_A",
	"BU000140.VB_A",
	"BU000141.VB_A",
	"BU000142.VB_A",
	"BU000144.VB_A",
	"BU000145.VB_A",
	"BU000148.VB_A",
	"BU000149.VB_A",
	"BU000150.VB_A",
	"BU000151.VB_A",
	"BU000152.VB_A",
	"BU000153.VB_A",
	"BU000155.VB_A",
	"BU000157.VB_A",
	"BU000158.VB_A",
	"BU000160.VB_A",
	"BU000161.VB_A",
	"BU000164.VB_A",
	"BU000165.VB_A",
	"BU000166.VB_A",
	"BU000167.VB_A",
	"BU000168.VB_B",
	"BU000169.VB_B",
	"BU000170.VB_B",
	"BU000171.VB_B",
	"BU000172.VB_B",
	"BU000173.VB_B",
	"BU000174.VB_B",
	"BU000175.VB_B",
	"BU000176.VB_B",
	"BU000177.VB_B",
	"BU000178.VB_B",
	"BU000179.VB_B",
	"BU000180.VB_B",
	"BU000182.PB_A",
	"BU000183.PB_A",
	"BU000184.PB_A",
	"BU000185.PB_A",
	"BU000186.PB_A",
	"BU000187.PB_A",
	"BU000188.PB_A",
	"BU000190.PB_A",
	"BU000191.PB_A",
	"BU000192.PB_A",
	"BU000193.PB_A",
	"BU000194.PB_A",
	"BU000195.PB_A",
	"BU000196.PB_A",
	"BU000197.PB_A",
	"BU000198.PB_A",
	"BU000199.PB_A",
	"BU000200.PB_A",
	"BU000201.PB_A",
	"BU000202.PB_A",
	"BU000203.PB_A",
	"BU000204.PB_A",
	"BU000205.PB_A",
	"BU000206.PB_A",
	"BU000207.PB_B",
	"BU000209.PB_B",
	"BU000210.PB_B",
	"BU000211.PB_B",
	"BU000212.PB_B",
	"BU000213.PB_B",
	"BU000214.PB_B",
	"BU000215.PB_B",
	"BU000217.PB_B",
	"BU000219.PB_B",
	"BU000223.PB_B",
	"BU000225.PB_B",
	"BU000226.PB_B",
	"BU000227.PB_B",
	"BU000228.PB_B",
	"BU000229.PB_B",
	"BU000230.PB_B",
	"BU000231.PB_B",
	"BU000233.PB_B",
	"BU000234.PB_B",
	"BU000235.PB_B",
	"BU000237.PB_B",
	"BU000242.PB_B",
	"BU000244.SP",
	"BU000245.SP",
	"BU000246.SP",
	"BU000248.SP",
	"BU000249.SP",
	"BU000250.SP",
	"BU000252.SP",
	"BU000253.SP",
	"BU000254.SP",
	"BU000255.SP",
	"BU000256.SP",
	"BU000257.SP",
	"BU000259.SP",
	"BU000260.SP",
	"BU000261.SP",
	"BU000262.SP",
	"BU000263.SP",
	"BU000264.SP",
	"BU000265.SP",
	"BU000266.SP",
	"BU000269.SP",
	"BU000270.SP",
	"BU000271.SP",
	"BU000272.SP",
	"BU000318.BNP",
	"BU000319.BNP",
	"BU000320.BNP",
	"BU000321.BNP",
	"BU000322.BNP",
	"BU000323.BNP",
	"BU000324.BNP",
	"BU000325.BNP",
	"BU000326.BNP",
	"BU000327.BNP",
	"BU000328.BNP",
	"BU000329.BNP",
	"BU000330.BNP",
	"BU000331.BNP",
	"BU000332.BNP",
	"BU000333.BNP",
	"BU000334.BNP",
	"BU000335.BNP",
	"BU000336.BNP",
	"BU000337.BNP",
	"BU000338.BNP",
	"BU000339.BNP",
	"BU000340.BNP",
	"BU000341.BNP",
	"BU000343.BNP",
	"BU000344.BNP",
	"BU000345.BNP",
	"BU000346.BNP",
	"BU000347.BNP",
	"BU000348.BNP",
	"BU000349.BNP",
	"BU000350.BNP",
	"BU000351.BNP",
	"BU000352.BNP",
	"BU000354.BNP",
	"BU000355.BNP",
	"BU000356.BNP",
	"BU000357.BNP",
	"BU000358.BNP",
	"BU000359.BNP",
	"BU000361.BNP",
	"BU000362.BNP",
	"BU000364.BNP",
	"BU000366.BNP",
	"BU000367.BNP",
	"BU000372.BNP",
	"BU000375.BNP",
	"BU000382.BB",
	"BU000383.BB",
	"BU000384.BB",
	"BU000386.BB",
	"BU000390.BB",
	"BU000391.BB",
	"BU000392.BB",
	"BU000393.BNP",
	"BU000397.BB",
	"BU000398.BB",
	"BU000400.BB",
	"BU000402.BB",
	"BU000403.BB",
	"BU000405.BB",
	"BU000406.BB",
	"BU000407.BB",
	"BU000408.BB",
	"BU000409.BB",
	"BU000410.BB",
	"BU000411.BB",
	"BU000413.BB",
	"BU000414.BB",
	"BU000415.BB",
	"BU000416.BB",
	"BU000417.BB",
	"BU000418.SJSP",
	"BU000419.SJSP",
	"BU000420.SJSP",
	"BU000421.SJSP",
	"BU000424.SJSP",
	"BU000425.SJSP",
	"BU000426.SJSP",
	"BU000427.SJSP",
	"BU000431.SJSP",
	"BU000432.SJSP",
	"BU000433.SJSP",
	"BU000439.SJSP",
	"BU000441.SJSP",
	"BU000442.SJSP",
	"BU000443.SJSP",
	"BU000444.SJSP",
	"BU000446.SJSP",
	"BU000449.SJSP",
	"BU000451.SJSP",
	"BU000454.SJSP",
	"BU000458.SJSP",
	"BU000460.SJSP",
	"BU000463.SJSP",
	"BU000464.SJSP")


options(scipen=99)
# get vector of sample population names
pop <- cname[10:585] %>% gsub("-.*","",.) %>% gsub(".*\\.","",.) %>% gsub("_.*","",.)
popu <- unique(pop)
popu <- sort(popu)

slist <- lapply(sort(popu), FUN=function(x){which(pop==x)})

# need to calculate pi from short haplotypes. 
# function "adist" can calculate ins,del,subs in pairwise fashion
# another option is to use CIGAR strings to reconstruct alignment,tossing out insertions
# third option is to actually align the sequences using, e.g biostrings?

# going to just use "adist". it's not correct, but good enough I hope. 
	# only going to count "substitutions" found by adist, equal cost for ins, del, sub

# calculate allele substitution distance matrix. 
	# alseq is a vector of allele sequences
	# for compatibility downstream, must contain ALL allele sequences from VCF record
ad <- function(alseq){

	# distance between alleles
	ad <- adist(alseq,counts=TRUE,costs=c(ins=2,del=2,subs=1))

	# inferred substitutions only, excluding indels
	d <- attr(ad,"counts")[,,3]

	return(d)

	}


# calculate pi 
	# for a matrix of allele distances (d)
	# and a vector of genotypes (alvec, coded 1..n, NOT 0..n) 
piw <- function(d,alvec){

	# counts of alleles
	ac <- alvec %>% factor(.,levels=1:dim(d)[1]) %>% table()

	if(length(ac)==1){return(0)}

	# counts of pairwise comparisons among alleles
	fc <- (ac %>% combn(.,2) %>% apply(.,MAR=2,FUN=prod))

	p <- sum(fc * d[lower.tri(d)])/choose(length(alvec),2)

	return(p)

	}

# calculate pi between two sets of alleles, as above. 
pib <- function(d,alvec1,alvec2){

	nal <- dim(d)[1]
	# counts of alleles
	ac <- c(alvec1,alvec2) %>% factor(.,levels=1:nal) %>% table()
	# bail out if no variation
	if(length(ac)==1){return(0)}

	# allele counts per population
	ac1 <- alvec1 %>% factor(.,levels=1:nal) %>% table()
	ac2 <- alvec2 %>% factor(.,levels=1:nal) %>% table()

	# counts of pairwise combinations
	fc <- cbind(ac1) %*% rbind(ac2)

	# calculate pi
	p <- sum(fc * d)/(length(alvec1) * length(alvec2))
	return(p)
	}


pis <- c()
pibs <- c()

f <- file("stdin")
open(f)
ind <- 1

while(length(line <- readLines(f,n=1)) > 0) {

	# skip comment lines
	if(grepl("^#",line)){next()}
	line <- str_split(line,"\\t") %>% unlist()

	ind <- ind + 1

	# genotype vector
	gt <- gsub(":.*","",line[10:585])
	gt <- as.numeric(gt)+1
	
	# list of vectors of haploid genotypes per population
	sgt <- lapply(slist,FUN=function(x,v){x <- v[x]; x[!is.na(x)]},v=gt)

	# if sample size doesn't equal at least vector, skip
	minsam <- c(3,3,5,5,5,3,5,5,3,5,3,3,3)
	samsize <- sapply(sgt,length)
	#cat(paste(samsize,collapse="\t",sep=""),"\n",sep="",file="samsize.allpops.txt",append=TRUE)
	if(!all(samsize>=minsam)){next()}

	# vector of alleles
	alleles <- c(line[4],unlist(str_split(line[5],",")))
	
	# # distance between alleles
	d <- ad(alleles)
	
	# caculate pi within
	pis <- sapply(sgt,piw,d=d) %>% round(.,digits=5)
	pibs <- apply(t(combn(sgt,2)),MAR=1,FUN=function(x){pib(d=d,x[[1]],x[[2]])})  %>% round(.,digits=5)
	p <- c(line[1],line[2],pis,pibs)

	cat(paste(p,collapse="\t",sep=""),"\n",sep="")

	if((ind %% 1000) == 0){write(ind,stderr())}

}

```

```{bash}
scp -P 2022 farm:/home/nreid/noah_stats.RData ~/analysis/data/comparison/noah_stats.RData
```

```{r}
load("~/analysis/data/comparison/noah_stats.RData")
write.table(lift,"~/analysis/data/fst/noah.1kb.bed",row.names = FALSE,col.names = FALSE,quote = FALSE,sep='\t')
```

* starting with the PBS statistic comparisons
    + grabbing my data and plotting outlier windows
    
```{r}
library(XML)
library(magrittr)
library(stringr)
library(dplyr)
library(gtools)
library(naturalsort)
library(stringr)
library(dplyr)
library(gtools)

#Reading in table and getting quantiles----
pbs<-read.table("~/analysis/data/fst/allpbs5kb",header=FALSE,stringsAsFactors = FALSE)
pbsname<-c("Scaf","start","end","BBpbs","VBpbs","PBpbs","SJpbs","BNPpbs","keep")
colnames(pbs)<-pbsname

pbsc<-pbs %>% 
  filter(str_detect(Scaf,"chr"))
subw<-pbsc[,9]>0

#Reorder Noah's data by chromosome
pbst<-cbind(lift[,1:3],pbstat[,4:9])
ord<-mixedorder(pbst$V1)
pbsn<-pbst[ord,]
#Plotting a regression against the PBS statistics calculated by Noah

pbsnc<-pbsn %>% 
  filter(str_detect(V1,"chr"))


pbsc$Scaf<-factor(pbsc$Scaf,levels=c("chr1","chr2","chr3","chr4","chr5","chr6","chr7","chr8","chr9","chr10",
                                     "chr11","chr12","chr13","chr14","chr15","chr16","chr17","chr18","chr19",
                                     "chr20","chr21","chr22","chr23","chr24"))

pbsnc$V1<-factor(pbsnc$V1,levels=c("chr1","chr2","chr3","chr4","chr5","chr6","chr7","chr8","chr9","chr10",
                                     "chr11","chr12","chr13","chr14","chr15","chr16","chr17","chr18","chr19",
                                     "chr20","chr21","chr22","chr23","chr24"))

palette(c("grey40","grey80"))
par(mfrow=c(2,1),mar=c(2,2,0,0))
plot(pbsc[subw,"BBpbs"],pch=20,cex=.2,col=as.factor(pbsc[subw,1]),bty='l',ylim=c(-0.5,3.5))
plot(pbsnc[subw,"BB"],pch=20,cex=.2,col=as.factor(pbsnc[subw,1]),bty='l',ylim=c(-0.5,3.5))

par(mfrow=c(2,1),mar=c(2,2,0,0))
plot(pbsc[subw,"VBpbs"],pch=20,cex=.2,col=as.factor(pbsc[subw,1]),bty='l',ylim=c(-0.5,3.5))
plot(pbsnc[subw,"VB"],pch=20,cex=.2,col=as.factor(pbsnc[subw,1]),bty='l',ylim=c(-0.5,3.5))

par(mfrow=c(2,1),mar=c(2,2,0,0))
plot(pbsc[subw,"PBpbs"],pch=20,cex=.2,col=as.factor(pbsc[subw,1]),bty='l',ylim=c(-0.5,3.5))
plot(pbsnc[subw,"PB"],pch=20,cex=.2,col=as.factor(pbsnc[subw,1]),bty='l',ylim=c(-0.5,3.5))

par(mfrow=c(2,1),mar=c(2,2,0,0))
plot(pbsc[subw,"SJpbs"],pch=20,cex=.2,col=as.factor(pbsc[subw,1]),bty='l',ylim=c(-0.5,3.5))
plot(pbsnc[subw,"SJSP"],pch=20,cex=.2,col=as.factor(pbsnc[subw,1]),bty='l',ylim=c(-0.5,3.5))

par(mfrow=c(2,1),mar=c(2,2,0,0))
plot(pbsc[subw,"BNPpbs"],pch=20,cex=.2,col=as.factor(pbsc[subw,1]),bty='l',ylim=c(-0.5,3.5))
plot(pbsnc[subw,"BNP"],pch=20,cex=.2,col=as.factor(pbsnc[subw,1]),bty='l',ylim=c(-0.5,3.5))

#Only works if you call the 1kb windows
# par(mfrow=c(3,2),mar=c(2,2,0,0))
# plot(pbsc[subw,"BBpbs"],pbsnc[subw,"BB"],pch=20,cex=.2)
# plot(pbsc[subw,"VBpbs"],pbsnc[subw,"VB"],pch=20,cex=.2)
# plot(pbsc[subw,"PBpbs"],pbsnc[subw,"PB"],pch=20,cex=.2)
# plot(pbsc[subw,"SJpbs"],pbsnc[subw,"SJSP"],pch=20,cex=.2)
# plot(pbsc[subw,"BNPpbs"],pbsnc[subw,"BNP"],pch=20,cex=.2)

```
    
##Calculating Genome-wide Fst and comparing

* Will use 2 ways of calculating genome wide Fst
    + Averaging Fst statistics from Weir & Cockerham windowed estimates of 1kb windows over the genome
    + Averaging Fst statistics with Hudson estimator from Noah's pi and dxy
    
* Starting with my 1kb estimates of genome-wide Fst (Weir&Cockerham)

```{r}
library("RColorBrewer")
library("lattice")
library("gplots")
#Loaidng list of fst files into a list object ----
fs <- list.files("~/analysis/data/fst/raw/", "*fst.1kb.bed",full.names=TRUE) # listing all the files for Fst calculated with W&C fst statistic

fst <- list()

for (i in 1:21){
	fst[[i]] <- read.table(fs[i],stringsAsFactors=FALSE)
	fst[[i]][,4] <- as.numeric(fst[[i]][,4])
} #reading in those files

nfs <- gsub(".*\\/","",fs) #renaming the columns by removing the "." in the names
nfs <- gsub(".fst.*","",nfs) #renaming by removing ".fst.*" from the name
names(fst)<-nfs

#selecting sites that ahave a minimum representation of 200 snps per region----
nsnps <-fst[[1]][,5]

for (i in 2:21){
  
  nsnps <- nsnps + fst[[i]][,5]
}

nsnps <- nsnps/21

subw <- nsnps > 20

#calculating FST for all

pops<-c("BB","VB","PB","SJ","BNP","GB","SP")
fsth<-matrix(nrow = 7,ncol=7) #creating matrix to hold fst data
colnames(fsth)<-pops
rownames(fsth)<-pops

for(i in pops){
  for(j in pops){
    if(i==j){next()}
    if(which(pops %in% i) < which(pops %in% j)){
      fsth[i,j]<-mean(fst[[paste(unique(c(i,j)),collapse=".")]][subw,4],na.rm=TRUE)
    } else{
      fsth[i,j]<-mean(fst[[paste(unique(c(j,i)),collapse=".")]][subw,4],na.rm=TRUE)
    }
  }
} #global fst calculation for each pair

#heatfst<-heatmap.2(fsth,Rowv=NA,Colv=NA,scale="none",margins=c(5,10),col=brewer.pal(9,"YlOrRd"),
                   #density.info="none", trace="none")
levelplot(fsth,aspect="iso",col.regions=brewer.pal(9,"YlOrRd"),scale=list(x=list(rot=45)),cuts=8) #Better plot than above
```

* Calculating genome wide Hudson statistic

```{r}
load("~/analysis/data/comparison/noah_stats.RData")
subw<-val[,4]>0
neutsum<-colSums(fst[subw,4:94],na.rm=TRUE) #summing up columns of pi and dxy statistics
snpsum<-sum(val[subw,4])
neutbase<-neutsum/snpsum

pops<-c("BB","VB","PB","SJSP","BNP","SP","GB")

fsth<-matrix(nrow = 7,ncol=7) #creating matrix to hold fst data
rownames(fsth)<- pops
colnames(fsth)<- pops

for(i in pops){
  for(j in pops){
    if(i==j){next()}
    fsth[i,j]<-1-((neutbase[i]+neutbase[j])/2)/neutbase[paste(sort(unique(c(i,j))),collapse=".")]
  }
}


levelplot(fsth,aspect="iso",col.regions=brewer.pal(9,"YlOrRd"),scale=list(x=list(rot=45)),cuts=8) #Better plot than above

```

* Calculating W&C with only 24 randomly selected individuals per populations to see if it's a problem of correcting for sample number

```{bash}
pops=BB\ VB\ PB\ SJ\ BNP\ GB\ SP
popfile=/data/oziolore/fhet/data/list2/pop_samples

for i in {1..7}
	do grep -n $pops $popfile | cut -f 1 -d ":" | awk '{s=$1-1}{print s}' | tr '\n' ',' | sed 's/,$//' | tr ',' '\n' | shuf -n 24 | sort | tr '\n' ',' | sed 's/,$//' > /data/oziolore/fhet/data/list2/BB_sub.txt

```

* Made a list of subsampled ones and running W&C on them

```{bash}
#!/bin/bash

#PBS -l nodes=1:ppn=1
#PBS -J 1-21

cd /home/oziolore/restoreFromData/fhet/scripts/fst/

pops=BB\ VB\ PB\ SJ\ BNP\ GB\ SP
outdir=/data/oziolore/fhet/data/fst2/subsample
popfile=/data/oziolore/fhet/data/list2/pop_samples
popdir=/data/oziolore/fhet/data/list2
my_wcfst=/data/oziolore/program/vcflib/bin/wcFst
my_pfst=/data/oziolore/program/vcflib/bin/pFst
my_vcf=/data/oziolore/fhet/data/varcall/filtered_chr.vcf.bgz
my_bgzip=/data/oziolore/program/htslib/bgzip


pair=$(for i in {1..6}
do
	ii=$(expr $i + 1)
	for j in $(seq $ii 7)
	do echo $pops | cut -f $i,$j -d ' '
done
done | \
sed -n "$(echo $PBS_ARRAY_INDEX)p")

echo $PBS_ARRAY_INDEX

pop1=$(echo $pair | cut -f 1 -d ' ')
pop2=$(echo $pair | cut -f 2 -d ' ')

echo $pop1 $pop2

target=$(cat $popdir/$pop1\_sub.txt)

background=$(cat $popdir/$pop2\_sub.txt)


outfile1=$pop1.$pop2.wcfst.bgz
outfile2=$pop1.$pop2.pfst.bgz

out1=$outdir/$outfile1
out2=$outdir/$outfile2

echo $out1
echo $out2
echo $target
echo $background
echo $outfile1
echo $outfile2

$my_wcfst \
--target $target \
--background $background \
--file $my_vcf \
--type GL | \
$my_bgzip>$out1

$my_pfst \
--target $target \
--background $background \
--file $my_vcf \
--type GL | \
$my_bgzip>$out2
```

```{r}
library("RColorBrewer")
library("lattice")
library("gplots")
#Loaidng list of fst files into a list object ----
fs <- list.files("~/analysis/data/fst/raw/subsample/", "*fst.1kb.bed",full.names=TRUE) # listing all the files for Fst calculated with W&C fst statistic

fst <- list()

for (i in 1:21){
	fst[[i]] <- read.table(fs[i],stringsAsFactors=FALSE)
	fst[[i]][,4] <- as.numeric(fst[[i]][,4])
} #reading in those files

nfs <- gsub(".*\\/","",fs) #renaming the columns by removing the "." in the names
nfs <- gsub(".fst.*","",nfs) #renaming by removing ".fst.*" from the name
names(fst)<-nfs

#selecting sites that ahave a minimum representation of 200 snps per region----
nsnps <-fst[[1]][,5]

for (i in 2:21){
  
  nsnps <- nsnps + fst[[i]][,5]
}

nsnps <- nsnps/21

subw <- nsnps > 20

#calculating FST for all

pops<-c("BB","VB","PB","SJ","BNP","GB","SP")
fsth<-matrix(nrow = 7,ncol=7) #creating matrix to hold fst data
colnames(fsth)<-pops
rownames(fsth)<-pops

for(i in pops){
  for(j in pops){
    if(i==j){next()}
    if(which(pops %in% i) < which(pops %in% j)){
      fsth[i,j]<-mean(fst[[paste(unique(c(i,j)),collapse=".")]][subw,4],na.rm=TRUE)
    } else{
      fsth[i,j]<-mean(fst[[paste(unique(c(j,i)),collapse=".")]][subw,4],na.rm=TRUE)
    }
  }
} #global fst calculation for each pair

#heatfst<-heatmap.2(fsth,Rowv=NA,Colv=NA,scale="none",margins=c(5,10),col=brewer.pal(9,"YlOrRd"),
                   #density.info="none", trace="none")
levelplot(fsth,aspect="iso",col.regions=brewer.pal(9,"YlOrRd"),scale=list(x=list(rot=45)),cuts=8) #Better plot than above

```

* When sampling the same number of individuals, now we have a more IBD like global Fst pattern, pointing to sampling number correction being the cuplrit here

* This suggests that W&C has a genome wide effect, but it still points to similar outliers

* Not a huge problem overall, but to do this properly I will repeat outlier analyses with Hudson estimator instead. It will take a bit, but oh well.

##Neutrality statistics with ANGSD
* Pi and Theta were calculated with SFS as prior for ANGSD
    + priors look a bit messed up (clumpy), suggesting they are not the best

```{r}
sf<-list.files("~/analysis/data/angsd/subsample/","*.sfs",full.names=TRUE)
cols<-c("black","grey40","grey80","firebrick2","lightpink","cadetblue1","cadetblue3")
pop<-list("bb","vb","pb","sj","bnp","sp","gb")

for(i in 1:7){
  pop[[i]]<-scan(sf[[i]])
}

par(mfrow=c(3,3),mar=c(2,2,2,2))
for(i in 1:7){
  plot(log(pop[[i]]),col=cols[i],pch=20,lwd=3)
}

```

* this is not great. The SFS is used in further estimations of SAF as a prior. We do see genome-wide shifts in theta and pi, but it is possible that those are due to errors in estimating SAF.

* Noah's has calculated pi and dxy on a per site basis, which doesn't rely on SFS. This doesn't show the same pattern of decreasing pi.

###installing ANGSD
* low coverage data neutral statistics, doing this with both subsample for genome wide estimates and for pop data, full datasets.

```{bash Installing ANGSD}
#[cluster]:/data/oziolore/program/
#Installing angsd

wget http://popgen.dk/software/download/angsd/angsd0.920.tar.gz
tar xf angsd0.920.tar.gz
cd htslib;make;cd ..
cd angsd
make HTSSRC=../htslib
cd ..

```

### High coverage threshold
* Took 10Mb of random regions throughout the genome and plotted coverage over them to decide what is an over-represented site threshold

```{bash Exploring high coverage}
#Getting coverage over all bases in the genome [cluster]
#starting with a merged bam of all individuals

samtools depth \
-d 10000 /home/oziolore/restoreFromData/fhet/data/align/all_merged.bam |\
gzip > /home/oziolore/restoreFromData/fhet/data/coverage/coverage_allbases.txt.gz

#Converting the high coverage data to bed file format [cluster]

zcat /home/oziolore/restoreFromData/fhet/data/coverage/coverage_allbases.txt.gz | \
awk '{OFS="\t"}{s=$2-1}{print $1,s,$2,$3}' | \
awk '{OFS="\t"}{if($4>300){print}}' | \
bedtools merge -i - -d 10 -c 4 -o count > /home/oziolore/restoreFromData/fhet/data/coverage/hicov.bed

#Getting 10Mb of random regions to makea decision on [cluster]

#!/bin/bash
dir=/home/oziolore/restoreFromData/fhet/data/coverage

zcat $dir/coverage_allbases.txt.gz | \
sort -R | \
head -n 10000000 | \
gzip > $dir/cov_10Mbrand.txt.gz

#used the following line to create a genome file in the /genome2/ subfolder
awk -v OFS='\t' {'print $1,$2'} $fai > $genome

```

### High coverage decision 
* Downloading that to personal computer to use r and make decision on the threshold for high coverage

```{bash Copying coverage to computer}
#downloading from cluster
scp kodiak:/data/oziolore/fhet/data/coverage/cov_10Mbrand.txt.gz /home/elias/analysis/data/angsd/
```

```{r deciding on a threshold of high coverage}
setwd("~/analysis/data/admixture/")
cov<-read.table("~/analysis/data/angsd/cov_10Mbrand.txt.gz",header=F) #reading in output of 10Mb random bases selected
colnames(cov)<-c("chrom","pos","coverage") #assigning names to columns of data

hist(cov$coverage,breaks=1000)
hist(cov$coverage,breaks=1000,xlim=c(0,300))

subw<-cov$cov<200
hist(cov[subw,"coverage"],breaks=1000)
summary(cov$cov)
summary(cov[subw,"coverage"])

#Qualitatively I will throw out sites above 200x coverage

```

### High coverage applying filter
* applying filter for high coverage sites to genome file in order to only keep normal coverage ones

```{bash Creating a high coverage file excluding those SNPs}
#using awk and bedtools merge, I am using
zcat /data/oziolore/fhet/data/coverage2/coverage_allbases2.txt.gz | \
awk '{OFS="\t"}{s=$2-1}{print $1,s,$2,$3}' | \
awk '{OFS="\t"}{if($4>200){print}}' | \
/data/oziolore/program/bedtools2/bin/bedtools merge -i - -d 10 -c 4 -o count > /data/oziolore/fhet/data/coverage2/hicov.bed

#Downloading data to look at how much of the genome I threw out
scp kodiak:/data/oziolore/fhet/data/coverage2/hicov.bed /home/elias/analysis/data/angsd/
```

```{r looking at size of excluded high coverage regions}
hi<-read.table("~/analysis/data/angsd/hicov.bed",header=FALSE)
sum(hi[,4])

#Threw out 52Mb of data => 5% of the genome
```

### Creating a keepsites file 
* with all bases that have below 200x coverage

```{bash Create the keepsites file and export to computer}
#[cluster]

zcat /data/oziolore/fhet/data/coverage2/coverage_allbases2.txt.gz | \
awk '{OFS="\t"}{s=$2-1}{print $1,s,$2,$3}' | \
awk '{OFS="\t"}{if($4<200){print}}' | \
bedtools merge -i - -d 10 > /data/oziolore/fhet/data/angsd2/keepsites2.bed

#Converting those to a .file format for ANGSD to deal with
cat /data/oziolore/fhet/data/angsd2/keepsites2.bed | \
awk '{OFS="\t"}{s=$2+1}{print $1,s,$3}' > /data/oziolore/fhet/data/angsd2/keepsites2.file

#Downloading the .bed file to make a script with 50Mb randomly selected to create expectation for SFS

scp kodiak:/data/oziolore/fhet/data/angsd2/keepsites2.bed ~/analysis/data/angsd/

```

### Picking random 50Mb
* Script to pick up 50Mb at random from the keepsites file in order to run SAF and SFS on those for bayesian priors

```{r Selecting random 50Mb from it}

orig<-read.table("~/analysis/data/angsd/keepsites2.bed", header=F) #reading in the keepsites file

p<-(orig[,3]-orig[,2])/(sum(orig[,3]-orig[,2])) #creating probability vector so that I don't oversample large chunks

p<-unlist(p) #unlisting the vector

z<-p<0 #removing any negative probabilities for 0 values
p<-p[!z] #applying that to vector

v<-sample(x=length(p),size=11500,prob=p) #sampling 11500 chunks with probability to get out ~50Mb of the genome
v<-sort(v)
sum(orig[v,3]-orig[v,2]) #checking the total size of bases

write.table(orig[v,], file="~/analysis/data/angsd/keep50Mb.bed",row.names=FALSE,col.names=FALSE,quote=FALSE)
```

### putting that data back into [cluster]

```{bash Copy those selections to computer}
scp /home/elias/analysis/data/angsd/keep50Mb.bed kodiak:/data/oziolore/fhet/data/angsd2/

```

### Converting that to a .file

```{bash Convert from bed to file}
cat /data/oziolore/fhet/data/angsd2/keep50Mb.bed | \
awk '{OFS="\t"}{s=$2+1}{print $1,s,$3}' > /data/oziolore//fhet/data/angsd2/keep50Mb.file
```

### indexing all of those files with ANGSD

```{bash Index keepsites}
/data/oziolore/program/angsd/angsd sites index /data/oziolore/fhet/data/angsd2/keepsites2.file
/data/oziolore/program/angsd/angsd sites index /data/oziolore/fhet/data/angsd2/keep50Mb.file
```

### Lists of populations
* fixing up lists of all populations .bam files so they can be plugged into ANGSD

```{bash Fix lists in order to reflect correct directory}
cat BB2.txt | sed 's/home/data/' | sed 's/restoreFromData\///' | uniq > BB2_new.txt
```

### SAF (Site Allele Frequency) estimate
* Starting site allele frequency estimation on a 50Mb subsample for each population (to create SFS)

```{bash Running Site Allele Frequency estimations on the 50Mb chunk}

#!/bin/bash

#PBS -l nodes=1:ppn=8
#PBS -J 1-7

pops=BB\ VB\ PB\ SJ\ BNP\ SP\ GB

one=$(echo $pops | cut -f $PBS_ARRAY_INDEX -d ' ')

#files
list=/data/oziolore/fhet/data/list2/$one\2_new.txt
genome=/data/oziolore/fhet/data/genome2/unsplit_merge.fasta
keep=/data/oziolore/fhet/data/angsd2/keep50Mb.file
outfile=/data/oziolore/fhet/data/angsd2/$one\_small
my_angsd=/data/oziolore/program/angsd/angsd

$my_angsd \
-bam $list \
-doSaf 1 \
-fold 1 \
-anc $genome \
-GL 2 \
-minMapQ 30 \
-minQ 20 \
-minind 10 \
-sites $keep \
-out $outfile

```

### SFS (Site Frequency Spectra) 
* Using the subsampled .saf to create site frequency spectra

```{bash Running Site Frequency Statistic on the 50Mb chunk}


#!/bin/bash

#PBS -l nodes=1:ppn=8
#PBS -J 1-7

pops=BB\ VB\ PB\ SJ\ BNP\ SP\ GB

one=$(echo $pops | cut -f $PBS_ARRAY_INDEX -d ' ')


#program and file
my_sfs=/data/oziolore/program/angsd_norm/misc/realSFS
in_saf=/data/oziolore/fhet/data/angsd2/$one\_small.saf.idx
outdir=/data/oziolore/fhet/data/angsd2
out_sfs=$one\.sfs

#code

$my_sfs $in_saf -maxIter 100 -P 8 -nSites 50000000 > $outdir/$out_sfs


```

### SAF full genome 
* Creating site allele frequencies for full genome of each population

```{bash Full SAF/Not necessary step}
#!/bin/bash

#PBS -l nodes=1:ppn=8
#PBS -J 1-7

pops=BB\ VB\ PB\ SJ\ BNP\ SP\ GB

one=$(echo $pops | cut -f $PBS_ARRAY_INDEX -d ' ')

#files
list=/data/oziolore/fhet/data/list2/$one\2_new.txt
genome=/data/oziolore/fhet/data/genome2/unsplit_merge.fasta
keep=/data/oziolore/fhet/data/angsd2/keepsites2.file
outfile=/data/oziolore/fhet/data/angsd2/$one\_full
my_angsd=/data/oziolore/program/angsd/angsd

$my_angsd \
-bam $list \
-doSaf 1 \
-fold 1 \
-anc $genome \
-GL 2 \
-minMapQ 30 \
-minQ 20 \
-minind 10 \
-sites $keep \
-out $outfile
```

### SFS download for R
* Once saf and sfs are created, take sfs to R to look at distribution

```{bash Copy SFS to computer to plot}
scp kodiak:/data/oziolore/fhet/data/angsd2/*.sfs /home/elias/analysis/data/angsd/raw/
```

### Plot SFS in R
* starting with folded spectra of subsample (24 per population)

```{r Plot subsampled SFS}
sf<-list.files("~/analysis/data/angsd/subsample/","*.sfs",full.names=TRUE)
cols<-c("black","lightpink","cadetblue3","grey80","firebrick2","cadetblue1","grey40")
pop<-list("bb","bnp","gb","pb","sj","sp","vb")

for(i in 1:7){
  pop[[i]]<-scan(sf[[i]])
}

par(mfrow=c(3,3),mar=c(2,2,2,2))
for(i in 1:7){
  plot(log(pop[[i]]),col=cols[i],pch=20,lwd=3)
}
```

* unfolded spectra of subsample (24 per population)

```{r Plot unfolded subsampled SFS}
sf<-list.files("~/analysis/data/angsd/subsample/unfolded/","*.sfs",full.names=TRUE)
cols<-c("black","lightpink","cadetblue3","grey80","firebrick2","cadetblue1","grey40")
pop<-list("bb","bnp","gb","pb","sj","sp","vb")

for(i in 1:7){
  pop[[i]]<-scan(sf[[i]])
}

par(mfrow=c(3,3),mar=c(2,2,2,2))
for(i in 1:7){
  plot(log(pop[[i]]),col=cols[i],pch=20,lwd=3)
}
```

* folded spectra of all individuals

```{r Plot full sample SFS}
sf<-list.files("~/analysis/data/angsd/raw/","*.sfs",full.names=TRUE)
cols<-c("black","lightpink","cadetblue3","grey80","firebrick2","cadetblue1","grey40")
pop<-list("bb","bnp","gb","pb","sj","sp","vb")

for(i in 1:7){
  pop[[i]]<-scan(sf[[i]])
}

par(mfrow=c(3,3),mar=c(2,2,2,2))
for(i in 1:7){
  plot(log(pop[[i]]),col=cols[i],pch=20,lwd=3)
}
```

* unfolded spectra of all individuals

```{r Plot full sample unfolded SFS}
sf<-list.files("~/analysis/data/angsd/raw/unfolded/","*.sfs",full.names=TRUE)
cols<-c("black","lightpink","cadetblue3","grey80","firebrick2","cadetblue1","grey40")
pop<-list("bb","bnp","gb","pb","sj","sp","vb")

for(i in 1:7){
  pop[[i]]<-scan(sf[[i]])
}

par(mfrow=c(3,3),mar=c(2,2,2,2))
for(i in 1:7){
  plot(log(pop[[i]]),col=cols[i],pch=20,lwd=3)
}
```

###!!!! -doThetas seqfault error again
* that has been throwing segfaults left and right for different people.
* fix is to change lines in abcSaf.cpp that have:
r->pLikes[myCounter] =new float[numInds+1]
to
r->pLikes[myCounter] =new float[2*numInds+1]
* will only use for folded frequency spectra estimations. For unfolded, leave original in /program/angsd_norm/angsd

####Everything works fine on -doSaf unfolded spectra

### Re-do of SFS for 1 pop (looks like crap)

```{bash Re-do of crappy SFS}
#!/bin/bash

#program and file
my_sfs=/data/oziolore/program/angsd_norm/misc/realSFS
in_saf=/data/oziolore/fhet/data/angsd2/BB_small.saf.idx
outdir=/data/oziolore/fhet/data/angsd2
out_sfs=BB.sfs

#code

$my_sfs $in_saf -maxIter 100 -P 8 -nSites 50000000 > $outdir/$out_sfs

```

### Converting readable thetas.gz
* Reading thetas.gz file to a readable state: below is command for folded estimate of subsample

```{bash Making the thetas estimates into a readable file}
#!/bin/bash

#PBS -l nodes=1:ppn=8
#PBS -l walltime=24:00:00
#PBS -J 1-7

pops=BB\ VB\ PB\ SJ\ BNP\ SP\ GB

one=$(echo $pops | cut -f $PBS_ARRAY_INDEX -d ' ')


#program/file
my_stat=/data/oziolore/program/angsd_norm/misc/thetaStat
file=/data/oziolore/fhet/data/angsd2/theta/subsample/$one\.theta.thetas.idx
out=/data/oziolore/fhet/data/angsd2/theta/subsample/$one\_readable_theta.gz

$my_stat print $file | gzip > $out
```

* SP has some issues in one of the characters in the compressed readable version. re-doing
    + worked after just repeating script
    
* Breaking them into sliding windows

```{bash Sliding windows from Noah's lift file UPDATE THIS WITH HOW YOU CREATED THE WINDOWS}
#!/bin/bash

#PBS -l nodes=1:ppn=8
#PBS -l walltime=02:00:00
#PBS -J 1-7

pops=BB\ VB\ PB\ SJ\ BNP\ SP\ GB

one=$(echo $pops | cut -f $PBS_ARRAY_INDEX -d ' ')

#programs and files

my_bedtools=/data/oziolore/program/bedtools2/bin/bedtools
thetas=/data/oziolore/fhet/data/angsd2/theta/$one\_readable_theta.gz
window=/data/oziolore/fhet/data/windows2/new_noah.1kb.bed
my_genome=/data/oziolore/fhet/data/genome2/unsplit_merge.fasta.fai
outdir=/data/oziolore/fhet/data/angsd2/theta          
outfile=$one\_neut_1kb.bed

zcat $thetas | \
egrep -v "^#" | \
awk '{OFS="\t"}{w=exp($3)}{pi=exp($4)}{s=$2-1}{print $1,s,$2,w,pi}' | \
$my_bedtools map \
-a $window \
-b stdin \
-g <(cut -f 1-2 $my_genome) \
-c 4,4,5,5 \
-o sum,count,sum,count > $outdir/$outfile

```
    
### Plotting distribution of neutral estimates 

#### Subsample plots

```{bash}
scp kodiak:/data/oziolore/fhet/data/angsd2/theta/subsample/*50kb* /home/elias/analysis/data/angsd/subsample/

```

* Break the file into pi, theta and and calculate tajima's D, starting with 50kb windows for speed

```{r Calculating Taj D; subsetting pi and theta}
###Buffalo Bayou loding pi(column6), theta(column4), and counts(columns 5,7)

bb<-read.table("~/analysis/data/angsd/subsample/BB_neut_50kb10kb.bed",stringsAsFactors=FALSE) #reading in all files
vb<-read.table("~/analysis/data/angsd/subsample/VB_neut_50kb10kb.bed",stringsAsFactors=FALSE)
pb<-read.table("~/analysis/data/angsd/subsample/PB_neut_50kb10kb.bed",stringsAsFactors=FALSE)
sj<-read.table("~/analysis/data/angsd/subsample/SJ_neut_50kb10kb.bed",stringsAsFactors=FALSE)
bnp<-read.table("~/analysis/data/angsd/subsample/BNP_neut_50kb10kb.bed",stringsAsFactors=FALSE)
sp<-read.table("~/analysis/data/angsd/subsample/SP_neut_50kb10kb.bed",stringsAsFactors=FALSE)
gb<-read.table("~/analysis/data/angsd/subsample/GB_neut_50kb10kb.bed",stringsAsFactors=FALSE)

colnam<-c("scaf","Start","End","Theta","Tcount","Pi","Pcount") #giving them column names
colnames(bb)<-colnam
colnames(vb)<-colnam
colnames(pb)<-colnam
colnames(sj)<-colnam
colnames(bnp)<-colnam
colnames(sp)<-colnam
colnames(gb)<-colnam

pops<-list(bb,vb,pb,sj,bnp,sp,gb)
popnames<-c("bb","vb","pb","sj","bnp","sp","gb")
names(pops)<-popnames

for(i in popnames){ #reading in the files as.numeric
  for(j in 4:7){
    pops[[i]][,j]<-as.numeric(pops[[i]][,j])
  }
}

cov<-cbind(bb[1:3],bb[,7],vb[,7],pb[,7],sj[,7],bnp[,7],sp[,7],gb[,7]) #creating a vector of coverage of each statistic call

nsnps<-cov[,4] #creating a vector that sums all calls over each SNP
for (i in 5:10){
  nsnps <- nsnps + cov[,i]
}
nsnps <- nsnps/7 #dividing by number of populations and only using sites that have at least 20 SNPS used over the window per population

subw <- nsnps > 20 #filter to be saved for these windows


#calculating mean and median pi----
pimean<-c() #calculating mean
for(i in popnames){
  pimean[i]<-sum(pops[[i]][subw,6],na.rm=TRUE)/sum(pops[[i]][subw,7],na.rm=TRUE)
}

#converting these to per base estimates
popbase<-list()

for(i in popnames){ #calculating per base estimates rather than averaged estimates over the windows we have
  popbase[[i]]<-cbind(pops[[i]][,1:3],pops[[i]][,4]/pops[[i]][,5],pops[[i]][,6]/pops[[i]][,7])
}

names<-c("scaf", "start","end",'theta/b',"pi/b")

for(i in popnames){ #giving the new list column names
  colnames(popbase[[i]])<-names
}

wt<-matrix(nrow=length(popbase[[1]][,1]),ncol=length(popnames)) #making a matrix of Waterson's theta values
for(i in 1:7){
  wt[,i]<-popbase[[i]][,4]
}
colnames(wt)<-popnames

pi<-matrix(nrow=length(popbase[[1]][,1]),ncol=length(popnames)) #making a matrix of pi values
for(i in 1:7){
  pi[,i]<-popbase[[i]][,5]
}
colnames(pi)<-popnames


source("~/analysis/scripts/angsd/tajimas.r")

taj<-list()

for(i in popnames){ #calculating tajima's D for all populations through a function in r; takes forever
  print(i)
  for(j in 1:dim(pi)[[1]]){
    taj[[i]]<-c(taj[[i]],tajimas(pi[j,i],wt[j,i],24))
  }
}


###

taj<-cbind(popbase[[1]][,1:3],taj[["bb"]],taj[["vb"]],taj[["pb"]],taj[["sj"]],taj[["bnp"]],taj[["sp"]],taj[["gb"]]) #binding into a dataframe

taj<-cbind(taj,keep=as.numeric(subw)) #keeping the filter of low representation bases

tajname<-c("scaf","start","end","bb","vb","pb","sjsp","bnp",
            "sp","gb","keep") #column names
colnames(taj)<-tajname

write.csv(taj,file="~/analysis/data/angsd/taj_sub",quote=FALSE,row.names=FALSE) #writing tajima's d

theta<-cbind(popbase[["bb"]][1:3],wt,keep=as.numeric(subw))

thetname<-c("scaf","start","end","bb","vb","pb","sjsp","bnp",
            "sp","gb","keep")
colnames(theta)<-thetname

write.csv(theta,file="~/analysis/data/angsd/thetas_sub",quote=FALSE,row.names=FALSE)


pi<-cbind(popbase[["bb"]][1:3],pi,keep=as.numeric(subw))

piname<-c("scaf","start","end","bb","vb","pb","sj","bnp","sp","gb","keep")
colnames(pi)<-piname
write.csv(pi,file="~/analysis/data/angsd/pi_sub",quote=FALSE,row.names=FALSE)

write.csv(cov,file="~/analysis/data/angsd/cov_sub",quote=FALSE,row.names = FALSE)

```

```{r Plotting subsampled data}
library('tidyr')
library('tibble')
library('magrittr')
library('dplyr')
library('gridExtra')

#loading neutrality stats----

theta<-read.table("~/fgfh_post/data/angsd/sample_comparison/thetas_sub",header=TRUE, sep=',') #reading in summary statistics
pi<-read.table("~/fgfh_post/data/angsd/sample_comparison/pi_sub", header=TRUE, sep=',')
taj<-read.table("~/fgfh_post/data/angsd/sample_comparison/taj_sub",header=TRUE, sep=',')

subw<-pi[,"keep"]>0 #applying filter of low coverage

##ggplot pi----
library(ggplot2)
library(reshape2)

mpi<-melt(pi[,1:10],id=c("scaf","start","end"))

jpeg(filename="~/Documents/UCD/Projects/Adaptation + Introgression/draft/images/pi.jpg",width=1000,height=600)
ggplot(mpi,
       aes(x=variable,y=value,fill=variable,color=variable))+
  geom_violin(trim=FALSE,draw_quantiles = 0.5,lwd=2)+
  scale_fill_manual(values=c("black","grey40","grey80","firebrick2","lightpink","cadetblue1","cadetblue3"))+
  scale_color_manual(values=c("grey40",rep("black",6)))+
  scale_y_continuous(limits=c(0.001,.012))+
  theme_classic()+
  labs(y="",x="")+
  theme(axis.line.y=element_line(color="black",size=5),axis.line=element_line(color="black",size=5))+
  theme(axis.text.y=element_text(color="black",size=40))
dev.off()

mtaj<-melt(taj[,1:10],id=c("scaf","start","end"))

jpeg(filename="~/Documents/UCD/Projects/Adaptation + Introgression/draft/images/taj.jpg",width=1000,height=600)
ggplot(mtaj,
       aes(x=variable,y=value,fill=variable,color=variable))+
  geom_violin(trim=FALSE,draw_quantiles = 0.5,lwd=2)+
  scale_fill_manual(values=c("black","grey40","grey80","firebrick2","lightpink","cadetblue1","cadetblue3"))+
  scale_color_manual(values=c("grey40",rep("black",6)))+
  scale_y_continuous(limits=c(-.25,.05))+
  theme_classic()+
  labs(y="",x="")+
  theme(axis.line.y=element_line(color="black",size=5),axis.line=element_line(color="black",size=5))+
  theme(axis.text.y=element_text(color="black",size=40))
dev.off()

```

###ANGSD full sample size
* starting with folded samples

```{bash Copy those files into computer}
scp kodiak:/data/oziolore/fhet/data/angsd2/theta/*_1kb* /home/elias/analysis/data/angsd/raw/

```

* Break the file into pi, theta and and calculate tajima's D
* starting with 1kb windows by noah's lift file. Merging them into 20 kb windows

```{r First data wrangling with R}
###Buffalo Bayou loding pi(column6), theta(column4), and counts(columns 5,7)

bb<-read.table("~/analysis/data/angsd/raw/BB_neut_1kb.bed",stringsAsFactors=FALSE) #reading in all files
vb<-read.table("~/analysis/data/angsd/raw/VB_neut_1kb.bed",stringsAsFactors=FALSE)
pb<-read.table("~/analysis/data/angsd/raw/PB_neut_1kb.bed",stringsAsFactors=FALSE)
sj<-read.table("~/analysis/data/angsd/raw/SJ_neut_1kb.bed",stringsAsFactors=FALSE)
bnp<-read.table("~/analysis/data/angsd/raw/BNP_neut_1kb.bed",stringsAsFactors=FALSE)
sp<-read.table("~/analysis/data/angsd/raw/SP_neut_1kb.bed",stringsAsFactors=FALSE)
gb<-read.table("~/analysis/data/angsd/raw/GB_neut_1kb.bed",stringsAsFactors=FALSE)

colnam<-c("scaf","Start","End","Theta","Tcount","Pi","Pcount") #giving them column names
colnames(bb)<-colnam
colnames(vb)<-colnam
colnames(pb)<-colnam
colnames(sj)<-colnam
colnames(bnp)<-colnam
colnames(sp)<-colnam
colnames(gb)<-colnam

#Calculating mean pi from 1kb non-overlapping windows----
pops<-list(bb,vb,pb,sj,bnp,sp,gb)
popnames<-c("bb","vb","pb","sj","bnp","sp","gb")
names(pops)<-popnames

cov<-cbind(bb[1:3],bb[,7],vb[,7],pb[,7],sj[,7],bnp[,7],sp[,7],gb[,7]) #creating a vector of coverage of each statistic call

for(i in popnames){
  for(j in 4:7){
  pops[[i]][,j]<-as.numeric(pops[[i]][,j])
  }
}


###Calculating blocks of certianty
nsnps<-cov[,4] #creating a vector that sums all calls over each SNP
for (i in 5:10){
  nsnps <- nsnps + cov[,i]
}
nsnps <- nsnps/7 #dividing by number of populations and only using sites that have at least 20 SNPS used over the window per population

subw <- nsnps > 50 #filter to be saved for these windows

#calculating mean and median pi----
pimean<-c() #calculating mean/something is wrong here. check
for(i in popnames){
  pimean[i]<-sum(pops[[i]][subw,6],na.rm=TRUE)/sum(pops[[i]][subw,7],na.rm=TRUE)
}

#calculating effective population size
#Theta(pi)=4Ne*u => Ne=theta(pi)/4u

u1<-3.5e-9 #mutation rate from cichlids
u2<-1.5e-9 #mutation rate from flounder
u3<-2.2e-9 #average eukaryotic mutation rate

mut<-c(u1,u2,u3)

Ne<-matrix(nrow=7,ncol=3)
rownames(Ne)<-names(pimean)
colnames(Ne)<-c("cichlid u","flounder u","euk u")
  
for(i in 1:3){
  Ne[,i]<-as.numeric(pimean/(4*mut[i]))
}

write.table(Ne,"~/analysis/data/angsd/Ne_estimates.csv",quote=FALSE)

#Slide function----
#This basically takes width number of windows and takes an average pi of them
slide<-function(x,y,width,slide){
  aver<-c()
  for(i in 1:length(y)){
    count=1
    if(is.na(y[i])){added=0}else{added<-y[i]}
    for(j in 1:(width-1)){
      index<-sum(i,j)
      if(is.na(x[index,1])){next()}
      if(is.na(y[index])){next()}
      if(x[index-1,1]==x[index,1]){
        added=added+y[index]
        count=count+1
      }else{next()}
    }
    aver[i]<-added
  }
  return(aver)
}

#Slidecount function----
slidecount<-function(x,y,width,slide){
  count<-c()
  for(i in 1:length(y)){
    if(is.na(y[i])){added=0}else{added<-y[i]}
    for(j in 1:(width-1)){
      index<-sum(i,j)
      if(is.na(x[index,1])){next()}
      if(is.na(y[index])){next()}
      if(x[index-1,1]==x[index,1]){
        added=added+y[index]
      }else{next()}
    }
    count[i]<-added
  }
  return(count)
}

pops<-list(bb,vb,pb,sj,bnp,sp,gb)
popnames<-c("bb","vb","pb","sj","bnp","sp","gb")
names(pops)<-popnames
pops2<-pops

for(i in popnames){ #converting files into 20kb merged windows
  for(j in c(4,6)){
    print(i)
    pops2[[i]][,j]<-slide(pops[[i]],as.numeric(pops[[i]][,j]),width=20,slide=1)
  }
  for(f in c(5,7)){
    print(i)
    pops2[[i]][,f]<-slidecount(pops[[i]],as.numeric(pops[[i]][,f]),width=20,slide=1)
  }
}


write.table(pops2[["bb"]],"~/analysis/data/angsd/raw/BB_neut2.bed",quote = FALSE,row.names = FALSE,col.names = FALSE,sep=",")
write.table(pops2[["vb"]],"~/analysis/data/angsd/raw/VB_neut2.bed",quote = FALSE,row.names = FALSE,col.names = FALSE,sep=",")
write.table(pops2[["pb"]],"~/analysis/data/angsd/raw/PB_neut2.bed",quote = FALSE,row.names = FALSE,col.names = FALSE,sep=",")
write.table(pops2[["sj"]],"~/analysis/data/angsd/raw/SJ_neut2.bed",quote = FALSE,row.names = FALSE,col.names = FALSE,sep=",")
write.table(pops2[["bnp"]],"~/analysis/data/angsd/raw/BNP_neut2.bed",quote = FALSE,row.names = FALSE,col.names = FALSE,sep=",")
write.table(pops2[["sp"]],"~/analysis/data/angsd/raw/SP_neut2.bed",quote = FALSE,row.names = FALSE,col.names = FALSE,sep=",")
write.table(pops2[["gb"]],"~/analysis/data/angsd/raw/GB_neut2.bed",quote = FALSE,row.names = FALSE,col.names = FALSE,sep=",")

```

*Let's read in the windowed estimates we just created

```{r}

bb<-read.csv("~/analysis/data/angsd/raw/BB_neut2.bed",stringsAsFactors=FALSE) #reading in all files
vb<-read.csv("~/analysis/data/angsd/raw/VB_neut2.bed",stringsAsFactors=FALSE)
pb<-read.csv("~/analysis/data/angsd/raw/PB_neut2.bed",stringsAsFactors=FALSE)
sj<-read.csv("~/analysis/data/angsd/raw/SJ_neut2.bed",stringsAsFactors=FALSE)
bnp<-read.csv("~/analysis/data/angsd/raw/BNP_neut2.bed",stringsAsFactors=FALSE)
sp<-read.csv("~/analysis/data/angsd/raw/SP_neut2.bed",stringsAsFactors=FALSE)
gb<-read.csv("~/analysis/data/angsd/raw/GB_neut2.bed",stringsAsFactors=FALSE)

colnam<-c("scaf","Start","End","Theta","Tcount","Pi","Pcount") #giving them column names
colnames(bb)<-colnam
colnames(vb)<-colnam
colnames(pb)<-colnam
colnames(sj)<-colnam
colnames(bnp)<-colnam
colnames(sp)<-colnam
colnames(gb)<-colnam

pops<-list(bb,vb,pb,sj,bnp,sp,gb)
popnames<-c("bb","vb","pb","sj","bnp","sp","gb")
names(pops)<-popnames

cov<-cbind(bb[1:3],bb[,7],vb[,7],pb[,7],sj[,7],bnp[,7],sp[,7],gb[,7]) #creating a vector of coverage of each statistic call

for(i in popnames){
  for(j in 4:7){
  pops[[i]][,j]<-as.numeric(pops[[i]][,j])
  }
}


###Calculating blocks of certianty
nsnps<-cov[,4] #creating a vector that sums all calls over each SNP
for (i in 5:10){
  nsnps <- nsnps + cov[,i]
}
nsnps <- nsnps/7 #dividing by number of populations and only using sites that have at least 20 SNPS used over the window per population

subw <- nsnps > 50 #filter to be saved for these windows

#calculating mean and median pi----
pimean<-c() #calculating mean/something is wrong here. check
for(i in popnames){
  pimean[i]<-sum(pops[[i]][subw,6],na.rm=TRUE)/sum(pops[[i]][subw,7],na.rm=TRUE)
}

popbase<-list()

for(i in popnames){ #calculating per base estimates rather than averaged estimates over the windows we have
  popbase[[i]]<-cbind(pops[[i]][,1:3],pops[[i]][,4]/pops[[i]][,5],pops[[i]][,6]/pops[[i]][,7])
}

names<-c("scaf", "start","end",'theta/b',"pi/b")

for(i in popnames){ #giving the new list column names
  colnames(popbase[[i]])<-names
}

wt<-matrix(nrow=length(popbase[[1]][,1]),ncol=length(popnames)) #making a matrix of Waterson's theta values
for(i in 1:7){
  wt[,i]<-popbase[[i]][,4]
}
colnames(wt)<-popnames

pi<-matrix(nrow=length(popbase[[1]][,1]),ncol=length(popnames)) #making a matrix of pi values
for(i in 1:7){
  pi[,i]<-popbase[[i]][,5]
}
colnames(pi)<-popnames


source("~/analysis/scripts/angsd/tajimas.r")

###Before calculating statistics I want to merge these into 5kb windows with 1kb slide.

taj<-list()

for(i in popnames){ #calculating tajima's D for all populations through a function in r; takes forever
  print(i)
  for(j in 1:dim(pi)[[1]]){
    taj[[i]]<-c(taj[[i]],tajimas(pi[j,i],wt[j,i],24))
  }
}


taj<-cbind(popbase[[1]][,1:3],taj[["bb"]],taj[["vb"]],taj[["pb"]],taj[["sj"]],taj[["bnp"]],taj[["sp"]],taj[["gb"]]) #binding into a dataframe

taj<-cbind(taj,keep=as.numeric(subw)) #keeping the filter of low representation bases

tajname<-c("scaf","start","end","bb","vb","pb","sjsp","bnp",
            "sp","gb","keep") #column names
colnames(taj)<-tajname

write.csv(taj,file="~/analysis/data/angsd/taj",quote=FALSE,row.names=FALSE) #writing tajima's d

theta<-cbind(popbase[["bb"]][1:3],wt,keep=as.numeric(subw))

thetname<-c("scaf","start","end","bb","vb","pb","sjsp","bnp",
            "sp","gb","keep")
colnames(theta)<-thetname

write.csv(theta,file="~/analysis/data/angsd/thetas",quote=FALSE,row.names=FALSE)


pi<-cbind(popbase[["bb"]][1:3],pi,keep=as.numeric(subw))

piname<-c("scaf","start","end","bb","vb","pb","sj","bnp","sp","gb","keep")
colnames(pi)<-piname
write.csv(pi,file="~/analysis/data/angsd/pi",quote=FALSE,row.names=FALSE)

write.csv(cov,file="~/analysis/data/angsd/cov",quote=FALSE,row.names = FALSE)

```

```{r}
library('tidyr')
library('tibble')
library('magrittr')
library('dplyr')

#loading neutrality stats----

theta<-read.table("~/fgfh_post/data/angsd/thetas",header=TRUE, sep=',') #reading in summary statistics
pi<-read.table("~/fgfh_post/data/angsd/pi", header=TRUE, sep=',')
taj<-read.table("~/fgfh_post//data/angsd/taj",header=TRUE, sep=',')

subw<-pi[,"keep"]>0 #applying filter of low coverage

##ggplot pi----
library(ggplot2)
library(reshape2)

mpi<-melt(pi[,1:10],id=c("scaf","start","end"))

jpeg(filename="/Users/eoziolor/Documents/UCD/Projects/Adaptation + Introgression/draft/images/pi.jpeg",width=1000,height=600)
ggplot(mpi,
       aes(x=variable,y=value,fill=variable,color=variable))+
  geom_violin(trim=FALSE,draw_quantiles = 0.5,lwd=2)+
  scale_fill_manual(values=c("black","grey40","grey80","firebrick2","lightpink","cadetblue1","cadetblue3"))+
  scale_color_manual(values=c("grey40",rep("black",6)))+
  scale_y_continuous(limits=c(0.001,.012))+
  theme_classic()+
  labs(y="",x="")+
  theme(axis.line.y=element_line(color="black",size=5),axis.line=element_line(color="black",size=5))+
  theme(axis.text.y=element_text(color="black",size=40))
dev.off()


mtaj<-melt(taj[,1:10],id=c("scaf","start","end"))

ggplot(mtaj,
       aes(x=variable,y=value,fill=variable,color=variable))+
  geom_violin(trim=FALSE,draw_quantiles = 0.5,lwd=2)+
  scale_fill_manual(values=c("black","grey40","grey80","firebrick2","lightpink","cadetblue1","cadetblue3"))+
  scale_color_manual(values=c("grey40",rep("black",6)))+
  scale_y_continuous(limits=c(-.35,.1))+
  theme_classic()+
  labs(y="",x="")+
  theme(axis.line.y=element_line(color="black",size=5),axis.line=element_line(color="black",size=5))+
  theme(axis.text.y=element_text(color="black",size=40))

#visualizing pi distribution----

bbp<-density(pi[subw,4],na.rm=TRUE)
vbp<-density(pi[subw,5],na.rm=TRUE)
pbp<-density(pi[subw,6],na.rm=TRUE)
sjp<-density(pi[subw,7],na.rm=TRUE)
bnpp<-density(pi[subw,8],na.rm=TRUE)
spp<-density(pi[subw,9],na.rm=TRUE)
gbp<-density(pi[subw,10],na.rm=TRUE)

par(mfrow=c(2,1),mar=c(4,5,2,2),mgp=c(3,2,0))

plot(gbp,xlim=c(0.0001,.025),col="cadetblue3",bty="l",ylim=c(0,450),
     cex.lab=2,xlab="",ylab="",lwd=3,main="",cex.axis=3)
#polygon(gbp,col="cadetblue1",density=100,border=NA)
lines(spp,xlim=c(0.001,.025),col="cadetblue3",lwd=3)
#polygon(spp,col="cadetblue3",density=100,border=NA)
lines(bnpp,xlim=c(0.001,.025),col="firebrick2",lwd=3)
#polygon(bnpp,col="lightpink",density=100,border=NA)
lines(sjp,xlim=c(0.001,.025),col="firebrick2",lwd=3)
#polygon(sjp,col="firebrick2",density=100,border=NA)
lines(pbp,xlim=c(0.001,.025),col="black",lwd=3)
#polygon(pbp,col="grey80",density=100,border=NA)
lines(vbp,xlim=c(0.001,.025),col="black",lwd=3)
#polygon(vbp,col="grey40",density=100,border=NA)
lines(bbp,xlim=c(0.001,.025),col="black",lwd=3)
#polygon(bbp,col="black",density=100,border=NA)

box(lwd=7,bty="l")

#visualizing tajima's D distribution----

bbtaj<-density(taj[subw,4],na.rm=TRUE)
vbtaj<-density(taj[subw,5],na.rm=TRUE)
pbtaj<-density(taj[subw,6],na.rm=TRUE)
sjtaj<-density(taj[subw,7],na.rm=TRUE)
bnptaj<-density(taj[subw,8],na.rm=TRUE)
sptaj<-density(taj[subw,9],na.rm=TRUE)
gbtaj<-density(taj[subw,10],na.rm=TRUE)

#par(mfrow=c(1,1),mgp=c(3,2,0))
plot(bnptaj,xlim=c(-.3,.3),col="firebrick2",bty="l",
     ylim=c(0,50),xlab="",ylab="",main="",lwd=3,cex.axis=4)
#polygon(bnptaj,col="lightpink",density=100,border=NA)
lines(sjtaj,xlim=c(-.15,.3),col="firebrick2",lwd=3)
#polygon(sjtaj,col="red",density=100,border=NA)
lines(pbtaj,xlim=c(-.15,.3),col="black",lwd=3)
#polygon(pbtaj,col="grey80",density=100,border=NA)
lines(vbtaj,xlim=c(-.15,.3),col="black",lwd=3)
#polygon(vbtaj,col="grey40",density=100,border=NA)
lines(bbtaj,xlim=c(-.15,.3),col="black",lwd=3)
#polygon(bbtaj,col="black",density=100,border=NA)
#polygon(sptaj,col="cadetblue3",density=100,border=NA)
lines(sptaj,xlim=c(-.15,.3),col="cadetblue3",lwd=3)
lines(gbtaj,xlim=c(-.15,.3),col="cadetblue3",lwd=3)
#polygon(gbtaj,col="cadetblue1",density=100,border=NA)

box(lwd=7,bty="l")

# 
# #####Plotting theta vs pi----
# 
# par(mfrow=c(3,3))
# plot(theta[,4],pi[,4],pch=20,cex=.5,col="black")
# abline(a=0,b=1,col="red")
# plot(theta[,5],pi[,5],pch=20,cex=.5,col="grey")
# abline(a=0,b=1,col="red")
# plot(theta[,6],pi[,6],pch=20,cex=.5,col="red")
# abline(a=0,b=1,col="black")
# plot(theta[,7],pi[,7],pch=20,cex=.5,col="orange")
# abline(a=0,b=1,col="red")
# plot(theta[,8],pi[,8],pch=20,cex=.5,col="yellow")
# abline(a=0,b=1,col="red")
# plot(theta[,9],pi[,9],pch=20,cex=.5,col="green")
# abline(a=0,b=1,col="red")
# plot(theta[,10],pi[,10],pch=20,cex=.5,col="blue")
# abline(a=0,b=1,col="red")
```


# Divergence statistics #2
### Genome-wide Fst plot from Hudson's Fst
* Calculating genome wide Hudson statistic

```{r}
library(XML)
library(magrittr)
library(stringr)
library(dplyr)
library(gtools)
library(naturalsort)
library(stringr)
library(dplyr)
library(gtools)
library(RColorBrewer)
library(lattice)
library(gplots)

load("~/analysis/data/comparison/noah_stats.RData")
subw<-val[,4]>0
neutsum<-colSums(fst[subw,4:94],na.rm=TRUE) #summing up columns of pi and dxy statistics
snpsum<-sum(val[subw,4])
neutbase<-neutsum/snpsum

pops<-c("BB","VB","PB","SJSP","BNP","SP","GB")

fsth<-matrix(nrow = 7,ncol=7) #creating matrix to hold fst data
rownames(fsth)<- pops
colnames(fsth)<- pops

for(i in pops){
  for(j in pops){
    if(i==j){next()}
    fsth[i,j]<-1-((neutbase[i]+neutbase[j])/2)/neutbase[paste(sort(unique(c(i,j))),collapse=".")]
  }
}

jpeg(filename="~/backup/UCD/Projects/Adaptation + Introgression/draft/images/fstgenomewide.jpeg",width=600,height=600)
levelplot(fsth,aspect="iso",col.regions=brewer.pal(9,"YlOrRd"),scale=list(x=list(rot=45)),cuts=8,
          pretty=FALSE,cex=2) #Better plot than above
dev.off()

#Including Fh Pops

pops2<-c("BB","VB","PB","SJSP","BNP","SP","GB","ER","KC","NYC","F")

fsth2<-matrix(nrow = 11,ncol=11) #creating matrix to hold fst data
rownames(fsth2)<- pops2
colnames(fsth2)<- pops2

for(i in pops2){
  for(j in pops2){
    if(i==j){next()}
    fsth2[i,j]<-1-((neutbase[i]+neutbase[j])/2)/neutbase[paste(sort(unique(c(i,j))),collapse=".")]
  }
}

levelplot(fsth2,aspect="iso",col.regions=brewer.pal(9,"YlOrRd"),scale=list(x=list(rot=45)),cuts=8,
          pretty=FALSE,cex=2) #Better plot than above

write.csv(fsth2,"~/analysis/data/fst/fhet_gran_fst.csv")
```

###Script to calculate dxy by site

```{r}
library(dplyr)
library(stringr)

cname <- c(
	"CHROM",
	"POS",
	"ID",
	"REF",
	"ALT",
	"QUAL",
	"FILTER",
	"INFO",
	"FORMAT",
	"BP-10",
	"BP-11",
	"BP-12",
	"BP-13",
	"BP-14",
	"BP-15",
	"BP-16",
	"BP-17",
	"BP-18",
	"BP-19",
	"BP-1",
	"BP-20",
	"BP-21",
	"BP-22",
	"BP-23",
	"BP-24",
	"BP-25",
	"BP-26",
	"BP-27",
	"BP-28",
	"BP-29",
	"BP-2",
	"BP-30",
	"BP-31",
	"BP-32",
	"BP-33",
	"BP-34",
	"BP-38",
	"BP-39",
	"BP-3",
	"BP-40",
	"BP-41",
	"BP-42",
	"BP-43",
	"BP-44",
	"BP-45",
	"BP-46",
	"BP-47",
	"BP-48",
	"BP-49",
	"BP-4",
	"BP-50",
	"BP-51",
	"BP-52",
	"BP-53",
	"BP-5",
	"BP-6",
	"BP-7",
	"BP-8",
	"BP-9",
	"ER-11",
	"ER-12",
	"ER-13",
	"ER-14",
	"ER-15",
	"ER-16",
	"ER-17",
	"ER-18",
	"ER-19",
	"ER-20",
	"ER-21",
	"ER-22",
	"ER-23",
	"ER-24",
	"ER-25",
	"ER-26",
	"ER-27",
	"ER-28",
	"ER-29",
	"ER-30",
	"ER-31",
	"ER-32",
	"ER-33",
	"ER-34",
	"ER-35",
	"ER-36",
	"ER-38",
	"ER-39",
	"ER-40",
	"ER-41",
	"ER-42",
	"ER-43",
	"ER-44",
	"ER-45",
	"ER-46",
	"ER-47",
	"ER-48",
	"ER-49",
	"ER-50",
	"ER-51",
	"ER-52",
	"ER-53",
	"ER-54",
	"ER-55",
	"ER-56",
	"ER-57",
	"ER-58",
	"ER-59",
	"ER-60",
	"F-10",
	"F-11",
	"F-12",
	"F-13",
	"F-14",
	"F-15",
	"F-16",
	"F-17",
	"F-18",
	"F-19",
	"F-1",
	"F-20",
	"F-21",
	"F-22",
	"F-23",
	"F-24",
	"F-25",
	"F-26",
	"F-27",
	"F-28",
	"F-29",
	"F-2",
	"F-30",
	"F-31",
	"F-32",
	"F-33",
	"F-34",
	"F-35",
	"F-39",
	"F-40",
	"F-41",
	"F-42",
	"F-43",
	"F-44",
	"F-45",
	"F-46",
	"F-47",
	"F-49",
	"F-4",
	"F-50",
	"F-51",
	"F-52",
	"F-53",
	"F-54",
	"F-5",
	"F-6",
	"F-7",
	"F-8",
	"F-9",
	"KC-11",
	"KC-13",
	"KC-14",
	"KC-15",
	"KC-16",
	"KC-18",
	"KC-19",
	"KC-1",
	"KC-20",
	"KC-22",
	"KC-23",
	"KC-26",
	"KC-27",
	"KC-28",
	"KC-29",
	"KC-2",
	"KC-30",
	"KC-32",
	"KC-33",
	"KC-34",
	"KC-35",
	"KC-36",
	"KC-37",
	"KC-38",
	"KC-39",
	"KC-3",
	"KC-40",
	"KC-41",
	"KC-42",
	"KC-43",
	"KC-44",
	"KC-45",
	"KC-46",
	"KC-47",
	"KC-48",
	"KC-49",
	"KC-4",
	"KC-50",
	"KC-51",
	"KC-52",
	"KC-54",
	"KC-55",
	"KC-56",
	"KC-5",
	"KC-6",
	"KC-7",
	"KC-9",
	"NYC-10",
	"NYC-11",
	"NYC-12",
	"NYC-13",
	"NYC-14",
	"NYC-15",
	"NYC-16",
	"NYC-17",
	"NYC-18",
	"NYC-19",
	"NYC-20",
	"NYC-21",
	"NYC-22",
	"NYC-23",
	"NYC-24",
	"NYC-25",
	"NYC-26",
	"NYC-27",
	"NYC-28",
	"NYC-29",
	"NYC-30",
	"NYC-31",
	"NYC-32",
	"NYC-33",
	"NYC-34",
	"NYC-40",
	"NYC-41",
	"NYC-42",
	"NYC-43",
	"NYC-44",
	"NYC-45",
	"NYC-46",
	"NYC-47",
	"NYC-48",
	"NYC-49",
	"NYC-50",
	"NYC-51",
	"NYC-52",
	"NYC-53",
	"NYC-54",
	"NYC-55",
	"NYC-8",
	"NYC-9",
	"SH-14",
	"SH-15",
	"SH-16",
	"SH-17",
	"SH-18",
	"SH-19",
	"SH-1",
	"SH-201",
	"SH-202",
	"SH-203",
	"SH-204",
	"SH-205",
	"SH-206",
	"SH-207",
	"SH-208",
	"SH-209",
	"SH-20",
	"SH-210",
	"SH-211",
	"SH-212",
	"SH-213",
	"SH-21",
	"SH-22",
	"SH-23",
	"SH-24",
	"SH-25",
	"SH-26",
	"SH-27",
	"SH-28",
	"SH-29",
	"SH-2",
	"SH-30",
	"SH-31",
	"SH-32",
	"SH-33",
	"SH-34",
	"SH-35",
	"SH-36",
	"SH-37",
	"SH-38",
	"SH-39",
	"SH-3",
	"SH-40",
	"SH-41",
	"SH-42",
	"SH-4",
	"SH-5",
	"SH-6",
	"SH-7",
	"SH-8",
	"BU000004.VB_B",
	"BU000005.VB_B",
	"BU000006.VB_B",
	"BU000007.VB_B",
	"BU000008.VB_B",
	"BU000012.SP",
	"BU000014.SP",
	"BU000017.SP",
	"BU000018.SP",
	"BU000023.SP",
	"BU000024.SP",
	"BU000025.SP",
	"BU000031.SP",
	"BU000032.SP",
	"BU000033.SP",
	"BU000035.SP",
	"BU000036.SP",
	"BU000037.SP",
	"BU000039.SP",
	"BU000041.SP",
	"BU000046.SP",
	"BU000048.SP",
	"BU000049.SP",
	"BU000052.SP",
	"BU000053.SP",
	"BU000054.SP",
	"BU000055.SP",
	"BU000056.SP",
	"BU000057.SP",
	"BU000062.GB",
	"BU000063.GB",
	"BU000064.GB",
	"BU000065.GB",
	"BU000066.GB",
	"BU000067.GB",
	"BU000068.GB",
	"BU000069.GB",
	"BU000070.GB",
	"BU000071.GB",
	"BU000072.GB",
	"BU000073.GB",
	"BU000074.GB",
	"BU000075.GB",
	"BU000076.GB",
	"BU000077.GB",
	"BU000078.GB",
	"BU000081.GB",
	"BU000082.GB",
	"BU000083.GB",
	"BU000084.GB",
	"BU000085.GB",
	"BU000086.GB",
	"BU000087.GB",
	"BU000088.GB",
	"BU000089.GB",
	"BU000090.GB",
	"BU000092.GB",
	"BU000093.GB",
	"BU000094.GB",
	"BU000095.GB",
	"BU000097.GB",
	"BU000100.GB",
	"BU000101.GB",
	"BU000102.GB",
	"BU000103.GB",
	"BU000104.GB",
	"BU000105.GB",
	"BU000106.GB",
	"BU000110.GB",
	"BU000116.GB",
	"BU000120.GB",
	"BU000121.GB",
	"BU000123.GB",
	"BU000124.GB",
	"BU000125.GB",
	"BU000126.GB",
	"BU000127.GB",
	"BU000129.VB_A",
	"BU000130.VB_A",
	"BU000131.VB_A",
	"BU000132.VB_A",
	"BU000133.VB_A",
	"BU000134.VB_A",
	"BU000135.VB_A",
	"BU000136.VB_A",
	"BU000137.VB_A",
	"BU000138.VB_A",
	"BU000139.VB_A",
	"BU000140.VB_A",
	"BU000141.VB_A",
	"BU000142.VB_A",
	"BU000144.VB_A",
	"BU000145.VB_A",
	"BU000148.VB_A",
	"BU000149.VB_A",
	"BU000150.VB_A",
	"BU000151.VB_A",
	"BU000152.VB_A",
	"BU000153.VB_A",
	"BU000155.VB_A",
	"BU000157.VB_A",
	"BU000158.VB_A",
	"BU000160.VB_A",
	"BU000161.VB_A",
	"BU000164.VB_A",
	"BU000165.VB_A",
	"BU000166.VB_A",
	"BU000167.VB_A",
	"BU000168.VB_B",
	"BU000169.VB_B",
	"BU000170.VB_B",
	"BU000171.VB_B",
	"BU000172.VB_B",
	"BU000173.VB_B",
	"BU000174.VB_B",
	"BU000175.VB_B",
	"BU000176.VB_B",
	"BU000177.VB_B",
	"BU000178.VB_B",
	"BU000179.VB_B",
	"BU000180.VB_B",
	"BU000182.PB_A",
	"BU000183.PB_A",
	"BU000184.PB_A",
	"BU000185.PB_A",
	"BU000186.PB_A",
	"BU000187.PB_A",
	"BU000188.PB_A",
	"BU000190.PB_A",
	"BU000191.PB_A",
	"BU000192.PB_A",
	"BU000193.PB_A",
	"BU000194.PB_A",
	"BU000195.PB_A",
	"BU000196.PB_A",
	"BU000197.PB_A",
	"BU000198.PB_A",
	"BU000199.PB_A",
	"BU000200.PB_A",
	"BU000201.PB_A",
	"BU000202.PB_A",
	"BU000203.PB_A",
	"BU000204.PB_A",
	"BU000205.PB_A",
	"BU000206.PB_A",
	"BU000207.PB_B",
	"BU000209.PB_B",
	"BU000210.PB_B",
	"BU000211.PB_B",
	"BU000212.PB_B",
	"BU000213.PB_B",
	"BU000214.PB_B",
	"BU000215.PB_B",
	"BU000217.PB_B",
	"BU000219.PB_B",
	"BU000223.PB_B",
	"BU000225.PB_B",
	"BU000226.PB_B",
	"BU000227.PB_B",
	"BU000228.PB_B",
	"BU000229.PB_B",
	"BU000230.PB_B",
	"BU000231.PB_B",
	"BU000233.PB_B",
	"BU000234.PB_B",
	"BU000235.PB_B",
	"BU000237.PB_B",
	"BU000242.PB_B",
	"BU000244.SP",
	"BU000245.SP",
	"BU000246.SP",
	"BU000248.SP",
	"BU000249.SP",
	"BU000250.SP",
	"BU000252.SP",
	"BU000253.SP",
	"BU000254.SP",
	"BU000255.SP",
	"BU000256.SP",
	"BU000257.SP",
	"BU000259.SP",
	"BU000260.SP",
	"BU000261.SP",
	"BU000262.SP",
	"BU000263.SP",
	"BU000264.SP",
	"BU000265.SP",
	"BU000266.SP",
	"BU000269.SP",
	"BU000270.SP",
	"BU000271.SP",
	"BU000272.SP",
	"BU000318.BNP",
	"BU000319.BNP",
	"BU000320.BNP",
	"BU000321.BNP",
	"BU000322.BNP",
	"BU000323.BNP",
	"BU000324.BNP",
	"BU000325.BNP",
	"BU000326.BNP",
	"BU000327.BNP",
	"BU000328.BNP",
	"BU000329.BNP",
	"BU000330.BNP",
	"BU000331.BNP",
	"BU000332.BNP",
	"BU000333.BNP",
	"BU000334.BNP",
	"BU000335.BNP",
	"BU000336.BNP",
	"BU000337.BNP",
	"BU000338.BNP",
	"BU000339.BNP",
	"BU000340.BNP",
	"BU000341.BNP",
	"BU000343.BNP",
	"BU000344.BNP",
	"BU000345.BNP",
	"BU000346.BNP",
	"BU000347.BNP",
	"BU000348.BNP",
	"BU000349.BNP",
	"BU000350.BNP",
	"BU000351.BNP",
	"BU000352.BNP",
	"BU000354.BNP",
	"BU000355.BNP",
	"BU000356.BNP",
	"BU000357.BNP",
	"BU000358.BNP",
	"BU000359.BNP",
	"BU000361.BNP",
	"BU000362.BNP",
	"BU000364.BNP",
	"BU000366.BNP",
	"BU000367.BNP",
	"BU000372.BNP",
	"BU000375.BNP",
	"BU000382.BB",
	"BU000383.BB",
	"BU000384.BB",
	"BU000386.BB",
	"BU000390.BB",
	"BU000391.BB",
	"BU000392.BB",
	"BU000393.BNP",
	"BU000397.BB",
	"BU000398.BB",
	"BU000400.BB",
	"BU000402.BB",
	"BU000403.BB",
	"BU000405.BB",
	"BU000406.BB",
	"BU000407.BB",
	"BU000408.BB",
	"BU000409.BB",
	"BU000410.BB",
	"BU000411.BB",
	"BU000413.BB",
	"BU000414.BB",
	"BU000415.BB",
	"BU000416.BB",
	"BU000417.BB",
	"BU000418.SJSP",
	"BU000419.SJSP",
	"BU000420.SJSP",
	"BU000421.SJSP",
	"BU000424.SJSP",
	"BU000425.SJSP",
	"BU000426.SJSP",
	"BU000427.SJSP",
	"BU000431.SJSP",
	"BU000432.SJSP",
	"BU000433.SJSP",
	"BU000439.SJSP",
	"BU000441.SJSP",
	"BU000442.SJSP",
	"BU000443.SJSP",
	"BU000444.SJSP",
	"BU000446.SJSP",
	"BU000449.SJSP",
	"BU000451.SJSP",
	"BU000454.SJSP",
	"BU000458.SJSP",
	"BU000460.SJSP",
	"BU000463.SJSP",
	"BU000464.SJSP")


options(scipen=99)
# get vector of sample population names
pop <- cname[10:585] %>% gsub("-.*","",.) %>% gsub(".*\\.","",.) %>% gsub("_.*","",.)
popu <- unique(pop)

# get vector of north,admixed,south,grandis designations
sss <- pop
sss[grep("BP|F",sss)] <- "North"
sss[grep("NYC|SH",sss)] <- "Admix"
sss[grep("ER|KC",sss)] <- "South"
sss[grep("GB|BB|SJSP|SP|BNP|PB|VB",sss)] <- "Grand"
sssu <- unique(sss)

slist <- list(
	North=which(sss=="North"),
	South=which(sss=="South"),
	Admix=which(sss=="Admix"),
	Grand=which(sss=="Grand")
	)


# need to calculate pi from short haplotypes. 
# function "adist" can calculate ins,del,subs in pairwise fashion
# another option is to use CIGAR strings to reconstruct alignment,tossing out insertions
# third option is to actually align the sequences using, e.g biostrings?

# going to just use "adist". it's not correct, but good enough I hope. 
	# only going to count "substitutions" found by adist, equal cost for ins, del, sub

# calculate allele substitution distance matrix. 
	# alseq is a vector of allele sequences
	# for compatibility downstream, must contain ALL allele sequences from VCF record
ad <- function(alseq){

	# distance between alleles
	ad <- adist(alseq,counts=TRUE,costs=c(ins=2,del=2,subs=1))

	# inferred substitutions only, excluding indels
	d <- attr(ad,"counts")[,,3]

	return(d)

	}


# calculate pi 
	# for a matrix of allele distances (d)
	# and a vector of genotypes (alvec, coded 1..n, NOT 0..n) 
piw <- function(d,alvec){

	# counts of alleles
	ac <- alvec %>% factor(.,levels=1:dim(d)[1]) %>% table()

	if(length(ac)==1){return(0)}

	# counts of pairwise comparisons among alleles
	fc <- (ac %>% combn(.,2) %>% apply(.,MAR=2,FUN=prod))

	p <- sum(fc * d[lower.tri(d)])/choose(length(alvec),2)

	return(p)

	}

# calculate pi between two sets of alleles, as above. 
pib <- function(d,alvec1,alvec2){

	nal <- dim(d)[1]
	# counts of alleles
	ac <- c(alvec1,alvec2) %>% factor(.,levels=1:nal) %>% table()
	# bail out if no variation
	if(length(ac)==1){return(0)}

	# allele counts per population
	ac1 <- alvec1 %>% factor(.,levels=1:nal) %>% table()
	ac2 <- alvec2 %>% factor(.,levels=1:nal) %>% table()

	# counts of pairwise combinations
	fc <- cbind(ac1) %*% rbind(ac2)

	# calculate pi
	p <- sum(fc * d)/(length(alvec1) * length(alvec2))
	return(p)
	}


pis <- c()
pibs <- c()

f <- file("stdin")
open(f)
ind <- 1

while(length(line <- readLines(f,n=1)) > 0) {

	# skip comment lines
	if(grepl("^#",line)){next()}
	line <- str_split(line,"\\t") %>% unlist()

	ind <- ind + 1

	# genotype vector
	gt <- as.numeric(line[10:585])+1
	
	# list of vectors of haploid genotypes per population
	sgt <- lapply(slist,FUN=function(x,v){x <- v[x]; x[!is.na(x)]},v=gt)

	# if sample size doesn't equal at least vector, skip
	minsam <- c(10,10,10,20)
	if(!all(sapply(sgt,length)>=minsam)){next()}

	# vector of alleles
	alleles <- c(line[4],unlist(str_split(line[5],",")))
	
	# # distance between alleles
	d <- ad(alleles)
	
	# caculate pi within
	pis <- sapply(sgt,piw,d=d) %>% round(.,digits=5)
	pibs <- apply(t(combn(sgt,2)),MAR=1,FUN=function(x){pib(d=d,x[[1]],x[[2]])})  %>% round(.,digits=5)
	p <- c(line[1],line[2],pis,pibs)

	cat(paste(p,collapse="\t",sep=""),"\n",sep="")

	if((ind %% 1000) == 0){write(ind,stderr())}

}

```

###Calculating Hudson's Fst from pi and dxy

```{r}
load("~/analysis/data/comparison/noah_stats.RData") #loading data produced from individual SNP call pi and dxy calculations

pops<-c("BB","VB","PB","SJSP","BNP","GB","SP") #creating a vector of names for our populations

fsth<-as.data.frame(fst2[,1:21])#creating matrix to hold fst data

f=0
for(i in pops){
  for(j in pops){
    if(i==j){next()}
    if(i>j){next()}
    f<-f+1
    print(f)
    colnames(fsth)[f]<-paste(sort(unique(c(i,j))),collapse=".")
    print(colnames(fsth)[f])
    fsth[,f]<-1-((fst2[,i]+fst2[,j])/2)/fst2[,paste(sort(unique(c(i,j))),collapse=".")]
  }
}

#write.table(fsth,"~/analysis/data/fst/fsth_20",col.names = FALSE,quote = FALSE,row.names = FALSE) #to save it for later

#fsth<-read.table("~/analysis/data/fst/fsth",header=FALSE) #loading fsth values
```

## Intermediate PBS
* Dependent on running the one above first

```{r}
pbs <- function(t1,t2,c12){
  
  t1 <- -log(1-t1)
  t2 <- -log(1-t2)
  c12 <- -log(1-c12)
  
  stat <- (t1 + t2 - c12)/2
  return(stat)
}

sjpbs <- pbs(fsth["BB.SJSP"],fsth["GB.SJSP"],fsth["BB.GB"])

bnppbs <- pbs(fsth["BB.BNP"],fsth["BNP.GB"],fsth["BB.GB"])

allpbs <- cbind(
  lift,
  SJ = sjpbs[],
  BNP = bnppbs[])

write.table(allpbs,
            file="~/analysis/data/fst/intermpbs20kb.bed",
            sep = "\t", 
            quote = FALSE,
            row.names = FALSE,
            col.names = FALSE)

sjc<-quantile(sjpbs[],prob=.99,na.rm=TRUE)
bnpc<-quantile(bnppbs[],prob=.99,na.rm=TRUE)

all<-sjpbs[]>sjc & bnppbs[]>bnpc
write.table(na.omit(allpbs[all,1:3]),"~/analysis/data/fst/interm_pbs_shared.bed",row.names = FALSE,col.names = FALSE,quote = FALSE,sep='\t')
#source("http://bioconductor.org/biocLite.R")
#biocLite()
library("rtracklayer")

bed1=import("~/analysis/data/fst/intermpbs20kb.bed")

bedall=import("~/analysis/data/fst/interm_pbs_shared.bed")
bed1overlall=bed1[bed1 %over% bedall]
hitsall<-findOverlaps(bedall,bed1)
allhit<-subjectHits(hitsall)

allpbs<-cbind(allpbs,0)
newn<-c("Chr","start","end","sj","bnp","all")
colnames(allpbs)<-newn
allpbs[allhit,"all"]<-allpbs[allhit,"all"]+1

allpbsc<-allpbs %>% 
  filter(str_detect(Chr,"chr"))

jpeg(filename="~/backup/UCD/Projects/Adaptation + Introgression/draft/images/intermediates.jpeg",width=1000,height=800)
palette(c("grey50","grey90"))
par(mfrow=c(2,1),mar=c(0,3,0,0))
plot(allpbsc[,"sj"],pch=20,cex=.5,col=ifelse(allpbs[,"all"]>0,"red",sort(as.factor(allpbs[,1]))),ylim=c(-1,1),xaxt='n')
plot(allpbsc[,"bnp"],pch=20,cex=.5,col=ifelse(allpbs[,"all"]>0,"red",sort(as.factor(allpbs[,1]))),ylim=c(-1,1),xaxt='n')
dev.off()
```

# Combined Z statistics
##Caclulating Z statistic from the fst values

```{r}
#Dependent on having loaded fsth into RAM from above chunk
# install.packages('matrixStats')
library(matrixStats)

fsth[!is.finite(as.matrix(fsth))]<-NA #making all inifite values into NA

fstmeans<-colMeans(fsth,na.rm=TRUE) #calculating average fst
fstmeans<-as.matrix(fstmeans) #putting it into a matrix

fststdev<-colSds(as.matrix(fsth),na.rm=TRUE) #calculating standard deviation overall
fststdev<-as.matrix(fststdev)
row.names(fststdev)<-row.names(fstmeans) #making sure the rows are correctly assigned

zfst<-matrix(nrow=dim(fsth)[1],ncol=dim(fsth)[2]) #creating a matrix that will hold z values
colnames(zfst)<-colnames(fsth)

#running a loop that calculates z values
for (i in 1:21){
    zfst[,i]<-(fsth[,i]-fstmeans[i])/fststdev[i]
}

#write.table(zfst,"~/analysis/data/fst/zfst_hud_1kb",row.names=FALSE,col.names=FALSE,quote=FALSE,sep="\t")
#zfst<-read.table("~/analysis/data/fst/zfst_hud_1kb",header=FALSE)
```

##Pi subtraction and Z statistic

```{r}
pi<-read.csv("~/analysis/data/angsd/pi",stringsAsFactors=TRUE) #taking only pi values for F. grandis from dataframe
pops<-c("bb","vb","pb","sj","bnp","sp","gb") #creating a vector of names for our populations

head(val) # vector of # of SNPs evaluated to come to a summary statistic per window

fsth2<-cbind(lift,fsth) #getting the coordinates onto the fsth matrix

pidiff<-as.data.frame(fst[-1,1:21]) #creating data frame that would hold pidiff values; my calculated pi values have 1 less row (first row of chr1 from 0-1000); don't know why, but oh well. suck it row 0-1000

#looping over variables to calculate the difference in pi
f=0
for(i in pops){
  for(j in pops){
    if(i==j){next()}
    if(i>j){next()}
    f<-f+1
    print(f)
    colnames(pidiff)[f]<-paste(sort(unique(c(i,j))),collapse=".")
    print(colnames(pidiff)[f])
    pidiff[,f]<-pi[,i]-pi[,j]
  }
}

pidiff[!is.finite(as.matrix(pidiff))]<-NA #removing all infinite values and replacing with NA
pimeans<-colMeans(as.matrix(pidiff),na.rm=TRUE) #calculating means of columns of pi difference
pimeans<-as.matrix(pimeans) #converting into a matrix so I can use numeric values out of it

library(matrixStats)
pistdev<-colSds(as.matrix(pidiff),na.rm=TRUE) #calculating standard deviation from columns
pistdev<-as.matrix(pistdev)

zpi<-matrix(nrow=dim(pidiff)[[1]],ncol = dim(pidiff)[[2]])

for (i in 1:21){
    zpi[,i]<-(pidiff[,i]-pimeans[i])/pistdev[i]
}
colnames(zpi)<-colnames(pidiff)

#write.table(zpi,"~/analysis/data/angsd/zpi_20kb",row.names = FALSE,col.names = FALSE,quote = FALSE,sep='\t')
```

##Plotting pi

```{r}
library('reshape')
library(ggplot2)

mpi<-melt(pi[,4:10])

ggplot(mpi,
       aes(x=variable,y=value,fill=variable,color=variable))+
  geom_violin(trim=FALSE,draw_quantiles = 0.5,lwd=2)+
  scale_fill_manual(values=c("black","grey40","grey80","firebrick2","lightpink","cadetblue1","cadetblue3"))+
  scale_color_manual(values=c("grey40",rep("black",6)))+
  scale_y_continuous(limits=c(0,.017))+
  theme_classic()+
  labs(y="",x="")+
  theme(axis.line.y=element_line(color="black",size=5),axis.line=element_line(color="black",size=5))+
  theme(axis.text.y=element_text(color="black",size=40))


```

## Merging z statistics 
* into a common one (high z would mean high fst and low pi)

```{r}
#zfst<-read.table("~/analysis/data/fst/zfst_hud_1kb",sep='\t')
#zpi<-read.table("~/analysis/data/angsd/zpi_1kb",sep="\t")
colnames(zfst)<-colnames(fsth) #naming columns
colnames(zpi)<-colnames(fsth)

zfst<-as.data.frame(zfst)
zpi<-as.data.frame(zpi)

zfst2<-zfst %>% mutate(seq=seq(1:dim(zfst)[[1]])) #adding sequence, basically a way to match the rows to each other
zpi2<-zpi %>% mutate(seq=seq(1:dim(zpi)[[1]])) #same

colnam<-colnames(zfst2[,1:21]) #saving colnames as a vector so we can match columns
zmerge_temp<-cbind(zfst2[colnam]-zpi2[match(zfst2$seq,zpi2$seq),colnam]) #subtracting zpi from zfst for a zmerge

subw<-val[,4]>5 #filtering values that didn't have very many supportive snps

zmerge<-zmerge_temp %>% mutate(keep=as.numeric(subw)) #Adds that filter column as 0s and 1s

#write.table(zmerge,"~/analysis/data/dfst/zmerge_1kb",row.names = FALSE,col.names = FALSE,quote = FALSE)

```

## PBS analysis with Z statistics

```{r}
#zmerge<-read.table("~/analysis/data/dfst/zmerge_1kb",header=FALSE)

znames<-c(names(fsth),"keep")
colnames(zmerge)<-znames

names(zmerge)<-gsub("SJSP","SJ",names(zmerge))

distgb<-zmerge %>% 
  select(contains("GB")) #only selecting GB columns
sub1<-gsub("GB.","",names(distgb)) #removing GB from names
sub2<-gsub(".GB","",sub1)
names(distgb)<-sub2

distsp<-zmerge %>% 
  select(contains("SP")) #only selecting SP columns
sub3<-gsub("SP.","",names(distsp))
sub4<-gsub(".SP","",sub3)
names(distsp)<-sub4

pops<-c("BB","VB","PB","SJ","BNP")

distgb2<-distgb %>% 
  select(pops) #rearranging columns

distsp2<-distsp %>% 
  select(pops)

colnam<-colnames(distgb2) #assigning a vector
distsp3<-distsp2 %>% mutate(seq=seq(1:dim(distsp)[[1]])) #adding sequence as before
distgb3<-distgb2 %>% mutate(seq=seq(1:dim(distgb)[[1]]))

total_dist<-cbind(distsp3[colnam]+distgb3[match(distsp3$seq,distgb3$seq),colnam]) #matching the two and adding them to each

pbsz<-matrix(nrow=dim(total_dist)[[1]],ncol=dim(total_dist)[[2]]) #creating matriz to hold 

for(i in 1:5){ #calculating the z pbs value
  pbsz[,i]<-(total_dist[,i]-distgb[,"SP"])/2
}
colnames(pbsz)<-colnames(total_dist)#naming

subw<-val[,4]>20 #filter

plot(pbsz[subw,"PB"],pch=20,cex=.2,ylim=c(-10,30))

zpbs<-cbind(lift,pbsz) #plugging in location values

ord<-mixedorder(zpbs$V1) #Data imported is ordered alphabetically (ex. chr1, chr10...); this reorders it to alphanumeric (chr1, chr2...)
zpbsn<-zpbs[ord,] #applying sorted order to our dataset

write.table(zpbsn,"~/analysis/data/dfst/zpbs_20kb",row.names = FALSE,col.names = FALSE,quote = FALSE,sep="\t") #writing

```

## Looking at 1% outlier regions

```{r}
col<-c() #figuring outliers
for (i in 1:5){
  col[i]<-quantile(zpbs[,i+3],prob=.99,na.rm=TRUE)
}
names(col)<-names(total_dist)
#1% thresholds
print(col)

```

## Creating outlier regions of interest

```{bash}
cat ~/analysis/data/dfst/zpbs_20kb | grep -v NA | \
awk '$4>3.231165 || $5>2.609672  || $6>3.752385 || $7>3.139116 || $8>2.731015' | \
~/program/bedtools2/bin/bedtools merge -i stdin -d 50000 \
-c 4,4,5,5,6,6,7,7,8,8 \
-o max,count,max,count,max,count,max,count,max,count \
-g <(cut -f 1-2 ~/analysis/data/genome/unsplit_merge.fasta.fai) > ~/analysis/data/dfst/zregions_max_20kb.bed
```

## Now let's plot up some figures with the merged z statistics

```{r}
zpbsn<-read.table("~/analysis/data/dfst/zpbs_20kb",sep='\t',header=FALSE)
zpbs<-zpbsn %>% 
  filter(str_detect(V1,"chr")) #filtering only chromosome mapped regions

#using data from the outlier regions in order to select regions of interest that are shared, res unique or interm unique
pbs_out_temp<-read.table("~/analysis/data/dfst/zregions_max_20kb.bed",stringsAsFactors = FALSE) #loads a pbs vector with windows merged within 50kb of each other and with max and windows count statistics
names<-c("Scaf","start","end","BBmax","BBcount","VBmax","VBcount","PBmax","PBcount","SJmax","SJcount","BNPmax","BNPcount") #naming columns
colnames(pbs_out_temp)<-names

pbs_out<-pbs_out_temp %>% filter(str_detect(Scaf,"chr")) #filtering to only select chromosome mapped scaffolds

all<-pbs_out[,4]>col[1] & pbs_out[,6]>col[2] & pbs_out[,8]>col[3] & pbs_out[,10]>col[4] & pbs_out[,12]>col[5] # vector wiht T/F of shared outliers
res<-pbs_out[,4]>col[1] & pbs_out[,6]>col[2] & pbs_out[,8]>col[3] & pbs_out[,10]<col[4] & pbs_out[,12]<col[5]
interm<-pbs_out[,4]<col[1] & pbs_out[,6]<col[2] & pbs_out[,8]<col[3] & pbs_out[,10]>col[4] & pbs_out[,12]>col[5]

write.table(zpbs[,1:3],"~/analysis/data/dfst/zpbs.bed",row.names = FALSE,col.names = FALSE,quote=FALSE, sep="\t") #saving background genomic regions in bed format
write.table(pbs_out[all,1:3],"~/analysis/data/dfst/pbs_regions_sharedall.bed",row.names = FALSE,col.names = FALSE,quote = FALSE,sep="\t") #saving shared regions to look at overlap with the 1kb regions
write.table(pbs_out[res,1:3],"~/analysis/data/dfst/pbs_regions_sharedres.bed",row.names = FALSE,col.names = FALSE,quote = FALSE,sep="\t")
write.table(pbs_out[interm,1:3],"~/analysis/data/dfst/pbs_regions_sharedinterm.bed",row.names = FALSE,col.names = FALSE,quote = FALSE,sep="\t")

#only run source() and biocLite() if you don't have them installed
# source("http://bioconductor.org/biocLite.R")
# biocLite()
library("rtracklayer")

bed1=import("~/analysis/data/dfst/zpbs.bed")

bedall=import("~/analysis/data/dfst/pbs_regions_sharedall.bed")
bed1overlall=bed1[bed1 %over% bedall]
hitsall<-findOverlaps(bedall,bed1)
allhit<-subjectHits(hitsall)

bedres=import("~/analysis/data/dfst/pbs_regions_sharedres.bed")
bed1overlres=bed1[bed1 %over% bedres]
hitsres<-findOverlaps(bedres,bed1)
reshit<-subjectHits(hitsres)

bedinterm=import("~/analysis/data/dfst/pbs_regions_sharedinterm.bed")
bed1overlinterm=bed1[bed1 %over% bedinterm]
hitsinterm<-findOverlaps(bedinterm,bed1)
intermhit<-subjectHits(hitsinterm)

zpbs<-cbind(zpbs,0,0,0)
newn<-c("Scaf","start","end","BB","VB","PB","SJ","BNP","all","res","interm")
colnames(zpbs)<-newn
zpbs[allhit,"all"]<-zpbs[allhit,"all"]+1
zpbs[reshit,"res"]<-zpbs[reshit,"res"]+1
zpbs[intermhit,"interm"]<-zpbs[intermhit,"interm"]+1

zpbs$Scaf<-factor(zpbs$Scaf,levels=c("chr1","chr2","chr3","chr4","chr5","chr6","chr7","chr8","chr9","chr10",
                                     "chr11","chr12","chr13","chr14","chr15","chr16","chr17","chr18","chr19",
                                     "chr20","chr21","chr22","chr23","chr24")) #factors are sometimes not sorted together with it, so sorting them separately
tiff(filename="~/backup/UCD/Projects/Adaptation + Introgression/draft/images/zpbs.jpeg",width=1200,height=800)

palette(c("grey50","grey90"))
par(mfrow=c(5,1),mar=c(0,3,0,0))
plot(zpbs[,4],pch=20,cex=1.2,
     col=ifelse(zpbs[,"all"]>0,"purple",
                ifelse(zpbs[,"res"]>0,"black",
                       ifelse(zpbs[,"interm"]>0,"firebrick2",sort(as.factor(zpbs[,1]))))),
     xlab="",xaxt='n',cex.lab=1,cex.axis=2.2,bty="n",ylim=c(-40,40),yaxs="i")

plot(zpbs[,5],pch=20,cex=1.2,
     col=ifelse(zpbs[,"all"]>0,"purple",
                ifelse(zpbs[,"res"]>0,"black",
                       ifelse(zpbs[,"interm"]>0,"firebrick2",sort(as.factor(zpbs[,1]))))),
     xlab="",xaxt='n',cex.lab=1,cex.axis=2.2,bty="n",ylim=c(-40,40),yaxs="i")

plot(zpbs[,6],pch=20,cex=1.2,
     col=ifelse(zpbs[,"all"]>0,"purple",
                ifelse(zpbs[,"res"]>0,"black",
                       ifelse(zpbs[,"interm"]>0,"firebrick2",sort(as.factor(zpbs[,1]))))),
     xlab="",xaxt='n',cex.lab=1,cex.axis=2.2,bty="n",ylim=c(-40,40),yaxs="i")

plot(zpbs[,7],pch=20,cex=1.2,
     col=ifelse(zpbs[,"all"]>0,"purple",
                ifelse(zpbs[,"res"]>0,"black",
                       ifelse(zpbs[,"interm"]>0,"firebrick2",sort(as.factor(zpbs[,1]))))),
     xlab="",xaxt='n',cex.lab=1,cex.axis=2.2,bty="n",ylim=c(-40,40),yaxs="i")

plot(zpbs[,8],pch=20,cex=1.2,
     col=ifelse(zpbs[,"all"]>0,"purple",
                ifelse(zpbs[,"res"]>0,"black",
                       ifelse(zpbs[,"interm"]>0,"firebrick2",sort(as.factor(zpbs[,1]))))),
     xlab="",xaxt='n',cex.lab=1,cex.axis=2.2,bty="n",ylim=c(-40,40),yaxs="i")

dev.off()

```

#Combined fst and pi
##Plotting FST vs PI

```{r}
library('ggplot2')
library("RColorBrewer")
require('gridExtra')

#loading fst and finding representative windows----
load("~/fgfh_post/data/comparison/noah_stats.RData") #loading data produced from individual SNP call pi and dxy calculations

pops<-c("BB","VB","PB","SJSP","BNP","GB","SP") #creating a vector of names for our populations

fsth<-as.data.frame(fst2[,1:21])#creating matrix to hold fst data

f=0
for(i in pops){
  for(j in pops){
    if(i==j){next()}
    if(i>j){next()}
    f<-f+1
    print(f)
    colnames(fsth)[f]<-paste(sort(unique(c(i,j))),collapse=".")
    print(colnames(fsth)[f])
    fsth[,f]<-1-((fst2[,i]+fst2[,j])/2)/fst2[,paste(sort(unique(c(i,j))),collapse=".")]
  }
}

fsth<-fsth[-1,]

fsth_temp<-fsth>0 & fsth<1

#loading pi and theta and finding their rep windows----
theta<-read.table("~/fgfh_post/data/angsd/thetas",header=TRUE, sep=',') #reading in summary statistics
pi<-read.table("~/fgfh_post/data/angsd/pi", header=TRUE, sep=',')

subz<-pi[,"keep"]>0 & fsth>0 & fsth<1

#plotting them all in ggplot
a<-ggplot(pi[subz,],
       aes(x=bb,y=gb)) +
  geom_point(size=fsth[subz,"BB.GB"]*2,
    aes(colour=fsth[subz,"BB.GB"])) +
  scale_color_gradient(name="Fst",low="gold2",high="firebrick2",limits=c(0,0.2),oob = scales::squish) +
  theme_classic()+
  scale_x_continuous(limits=c(0,0.1))+
  scale_y_continuous(limits=c(0,0.1))+
  geom_abline(slope=1,lty=2)

b<-ggplot(pi[subz,],
       aes(x=vb,y=gb)) +
  geom_point(size=fsth[subz,"GB.VB"],
    aes(colour=fsth[subz,"GB.VB"])) +
  scale_color_gradient(name="Fst",low="gold2",high="firebrick2",limits=c(0,0.2),oob = scales::squish) +
  theme_classic()+
  scale_x_continuous(limits=c(0,0.1))+
  scale_y_continuous(limits=c(0,0.1))+
  geom_abline(slope=1,lty=2)

c<-ggplot(pi[subz,],
       aes(x=pb,y=gb)) +
  geom_point(size=fsth[subz,"GB.PB"],
    aes(colour=fsth[subz,"GB.PB"])) +
  scale_color_gradient(name="Fst",low="gold2",high="firebrick2",limits=c(0,0.2),oob = scales::squish) +
  theme_classic()+
  scale_x_continuous(limits=c(0,0.1))+
  scale_y_continuous(limits=c(0,0.1))+
  geom_abline(slope=1,lty=2)

d<-ggplot(pi[subz,],
       aes(x=sj,y=gb)) +
  geom_point(size=fsth[subz,"GB.SJSP"],
    aes(colour=fsth[subz,"GB.SJSP"])) +
  scale_color_gradient(name="Fst",low="gold2",high="firebrick2",limits=c(0,0.2),oob = scales::squish) +
  theme_classic()+
  scale_x_continuous(limits=c(0,0.1))+
  scale_y_continuous(limits=c(0,0.1))+
  geom_abline(slope=1,lty=2)

e<-ggplot(pi[subz,],
       aes(x=bnp,y=gb)) +
  geom_point(size=fsth[subz,"BNP.GB"],
    aes(colour=fsth[subz,"BNP.GB"])) +
  scale_color_gradient(name="Fst",low="gold2",high="firebrick2",limits=c(0,0.2),oob = scales::squish) +
  theme_classic()+
  scale_x_continuous(limits=c(0,0.1))+
  scale_y_continuous(limits=c(0,0.1))+
  geom_abline(slope=1,lty=2)

f<-ggplot(pi[subz,],
       aes(x=sp,y=gb)) +
  geom_point(size=fsth[subz,"GB.SP"],
    aes(colour=fsth[subz,"GB.SP"])) +
  scale_color_gradient(name="Fst",low="gold2",high="firebrick2",limits=c(0,0.2),oob = scales::squish) +
  theme_classic()+
  scale_x_continuous(limits=c(0,0.1))+
  scale_y_continuous(limits=c(0,0.1))+
  geom_abline(slope=1,lty=2)

a2<-ggplot(pi[subz,],
       aes(x=bb,y=sp)) +
  geom_point(size=fsth[subz,"BB.SP"],
    aes(colour=fsth[subz,"BB.SP"])) +
  scale_color_gradient(name="Fst",low="gold2",high="firebrick2",limits=c(0,0.2),oob = scales::squish) +
  theme_classic()+
  scale_x_continuous(limits=c(0,0.1))+
  scale_y_continuous(limits=c(0,0.1))+
  geom_abline(slope=1,lty=2)

b2<-ggplot(pi[subz,],
       aes(x=vb,y=sp)) +
  geom_point(size=fsth[subz,"SP.VB"],
    aes(colour=fsth[subz,"SP.VB"])) +
  scale_color_gradient(name="Fst",low="gold2",high="firebrick2",limits=c(0,0.2),oob = scales::squish) +
  theme_classic()+
  scale_x_continuous(limits=c(0,0.1))+
  scale_y_continuous(limits=c(0,0.1))+
  geom_abline(slope=1,lty=2)

c2<-ggplot(pi[subz,],
       aes(x=pb,y=sp)) +
  geom_point(size=fsth[subz,"PB.SP"],
    aes(colour=fsth[subz,"PB.SP"])) +
  scale_color_gradient(name="Fst",low="gold2",high="firebrick2",limits=c(0,0.2),oob = scales::squish) +
  theme_classic()+
  scale_x_continuous(limits=c(0,0.1))+
  scale_y_continuous(limits=c(0,0.1))+
  geom_abline(slope=1,lty=2)

d2<-ggplot(pi[subz,],
       aes(x=sj,y=sp)) +
  geom_point(size=fsth[subz,"SJSP.SP"],
    aes(colour=fsth[subz,"SJSP.SP"])) +
  scale_color_gradient(name="Fst",low="gold2",high="firebrick2",limits=c(0,0.2),oob = scales::squish) +
  theme_classic()+
  scale_x_continuous(limits=c(0,0.1))+
  scale_y_continuous(limits=c(0,0.1))+
  geom_abline(slope=1,lty=2)

e2<-ggplot(pi[subz,],
       aes(x=bnp,y=sp)) +
  geom_point(size=fsth[subz,"BNP.SP"],
    aes(colour=fsth[subz,"BNP.SP"])) +
  scale_color_gradient(name="Fst",low="gold2",high="firebrick2",limits=c(0,0.2),oob = scales::squish) +
  theme_classic()+
  scale_x_continuous(limits=c(0,0.1))+
  scale_y_continuous(limits=c(0,0.1))+
  geom_abline(slope=1,lty=2)


tiff(filename="~/Documents/UCD/Projects/Adaptation + Introgression/draft/images/fst_pi.tiff",width=1000,height=1400,units="px")
grid.arrange(grobs=list(a,b,c,d,e,f,a2,b2,c2,d2,e2),ncol=2)
dev.off()

```

# Decisions

* I think we ahve decided at this point to thoroughly go with PBS statistics for the paper, so I will use outliers from the PBS statistic to look at haplotype comparisons.

# Divergence #3: Outliers
## PBS outlier plots

```{r}

library(XML)
library(tidyr)
library(stringr)
library(dplyr)
library(gtools)
library(naturalsort)
library(RCurl)
library(ggplot2)
library(reshape2)

load("~/analysis/data/comparison/noah_stats.RData") #loading data produced from individual SNP call pi and dxy calculations
pbstat2<-cbind(lift[,1:3],pbstat[,4:6],pbstat[,8],pbstat[,7]) #Binding pbs statistics for populations of interest, in this case F. grandis 

#Only run if you haven't created an ordered table of chromosomes
#r=ordering them by chromosome
# ord<-mixedorder(pbstat2$V1) #Data imported is ordered alphabetically (ex. chr1, chr10...); this reorders it to alphanumeric (chr1, chr2...)
# pbsn<-pbstat2[ord,] #applying sorted order to our dataset
# 
# pbsn$V1<-factor(pbsn$V1,levels=c("chr1","chr2","chr3","chr4","chr5","chr6","chr7","chr8","chr9","chr10",
#                                      "chr11","chr12","chr13","chr14","chr15","chr16","chr17","chr18","chr19",
#                                      "chr20","chr21","chr22","chr23","chr24")) #factors are sometimes not sorted together with it, so sorting them separately
# 
# #writing table to be used in further analysis
# write.table(pbsn[,1:8],"~/analysis/data/fst/hudsonpbs_1kb.bed",row.names = FALSE,col.names = FALSE,quote=FALSE,sep='\t') #Not really necessary, but subsetting the data, so that you don't have to reorder every time

#reading in pbs table to find outlier regions
pbs<-read.table("~/analysis/data/fst/hudsonpbs_1kb.bed",header=FALSE) #loading in ordered table of pbs values for populations of interest
pbsname<-c("Scaf","start","end","BBpbs","VBpbs","PBpbs","SJpbs","BNPpbs") #naming them according to their belonging
colnames(pbs)<-pbsname #applying naming scheme

quantiles<-c() #calculating quantiles in order to apply outlier thresholds
for(i in 1:5){
  quantiles[i]<-quantile(pbs[,i+3],probs=.99,na.rm=TRUE)
}


# Quantile info
# BBpbs - 0.18202835
# VBpbs - 0.14889788 
# PBpbs - 0.22912063 
# SJpbs - 0.08587848
# BNP - 0.04271162


```

## Merging PBS outliers
* Using bedtools to merge outliers of these pbs statistics; removing non-mapped regions (noise for the most part)

```{bash}
#grabbing the table file (remember that it needs to be in bed format);
cat ~/analysis/data/fst/hudsonpbs_1kb.bed | \
#removing all NA
grep -v NA | \
#using awk to remove all values below outlier
awk '$4>0.18202835 || $5>0.14889788  || $6>0.22912063 || $7>0.08587848 || $8>0.04271162' | \
#piping into bedtools and merging into outlier windows within 50000 of each other
~/program/bedtools2/bin/bedtools merge -i stdin -d 50000 \
#which columns do you want summary statistics printed for
-c 4,4,5,5,6,6,7,7,8,8 \
#what statistics do you want printed
-o sum,count,sum,count,sum,count,sum,count,sum,count \
#using fai file to map those regions back to genomic regions and saving as bed file
-g <(cut -f 1-2 ~/analysis/data/genome/unsplit_merge.fasta.fai) > ~/analysis/data/fst/hudson_pbsmergeoutliers.bed

#doing the same but instead with summed statistic, with highest peak outliers
cat ~/analysis/data/fst/hudsonpbs_1kb.bed | \
grep -v NA | \
awk '$4>0.18202835 || $5>0.14889788  || $6>0.22912063 || $7>0.08587848 || $8>0.04271162' | \
~/program/bedtools2/bin/bedtools merge -i stdin -d 50000 \
-c 4,4,5,5,6,6,7,7,8,8 \
-o max,count,max,count,max,count,max,count,max,count \
-g <(cut -f 1-2 ~/analysis/data/genome/unsplit_merge.fasta.fai) > ~/analysis/data/fst/hudson_pbsmergeoutliers_max.bed

```

## Common outliers PBS

### First for summed regions

```{r}
PBSout<-read.table("~/analysis/data/fst/hudson_pbsmergeoutliers.bed",stringsAsFactors=FALSE) # Reading in the maximum outlier regions of interest
colnames(PBSout)<- c("Scaf","start","end","BBsum", "BBcount","VBsum","VBcount","PBsum","PBcount","SJsum","SJcount","BNPsum","BNPcount") #assigning them column names (we chose columns to be printed earlier)

BBtot<-sum(PBSout[,4]) #summing total level of divergence in these regions
VBtot<-sum(PBSout[,6])
PBtot<-sum(PBSout[,8])
SJtot<-sum(PBSout[,10])
BNPtot<-sum(PBSout[,12])

interest2<-c() #creating a vector of interest to weigh in the level of divergence by population, so that ones in most divergent populations don't get outweighed
for (i in 1:dim(PBSout)[[1]]){
  interest2<-(PBSout[,4]/BBtot)*100+(PBSout[,6]/VBtot)*100+(PBSout[,8]/PBtot)*100+(PBSout[,10]/SJtot)*100+(PBSout[,12]/BNPtot)*100
}

ord<-order(interest2,decreasing=TRUE) #order that vector
ord2<-ord[1:10] #show top10 regions

par(mar=c(4.2,5,4,4)) #plotting these outliers
plot(PBSout[ord2,"BBsum"],col='black',pch=20,cex=3,ylim=c(0,4000),ylab="Level of divergence",xlab="Region number",
     cex.lab=2,cex.axis=2)
points(PBSout[ord2,"VBsum"],col='grey',pch=20,cex=3)
points(PBSout[ord2,"PBsum"],col='red',pch=20,cex=3)
points(PBSout[ord2,"SJsum"],col='darkorange',pch=20,cex=3)
points(PBSout[ord2,"BNPsum"],col="gold",pch=20,cex=3)

legend('topright',legend=c("BB","VB","PB","SJ","BNP"),col=c("black","grey","red","darkorange2","gold"),
       pch=20,cex=2,bty="n",y.intersp=1,x.intersp=.5)


# #Ordering them by interest in BB only
# 
# ord<-order(PBSout[,"BBsum"],decreasing=TRUE)
# ord2<-ord[1:10] #show top10 regions
# 
# par(mar=c(4.2,5,4,4)) #plotting these outliers
# plot(PBSout[ord2,"BBsum"],col='black',pch=20,cex=3,ylim=c(0,4000),ylab="Level of divergence",xlab="Region number",
#      cex.lab=2,cex.axis=2)
# points(PBSout[ord2,"VBsum"],col='grey',pch=20,cex=3)
# points(PBSout[ord2,"PBsum"],col='red',pch=20,cex=3)
# points(PBSout[ord2,"SJsum"],col='darkorange',pch=20,cex=3)
# points(PBSout[ord2,"BNPsum"],col="gold",pch=20,cex=3)
# 
# legend('topright',legend=c("BB","VB","PB","SJ","BNP"),col=c("black","grey","red","darkorange2","gold"),
#        pch=20,cex=2,bty="n",y.intersp=1,x.intersp=.5)


```

### Second for max regions

```{r}
PBSout<-read.table("~/analysis/data/fst/hudson_pbsmergeoutliers_max.bed",stringsAsFactors=FALSE) # Reading in the maximum outlier regions of interest
colnames(PBSout)<- c("Scaf","start","end","BBsum", "BBcount","VBsum","VBcount","PBsum","PBcount","SJsum","SJcount","BNPsum","BNPcount") #assigning them column names (we chose columns to be printed earlier)

BBtot<-sum(PBSout[,4]) #summing total level of divergence in these regions
VBtot<-sum(PBSout[,6])
PBtot<-sum(PBSout[,8])
SJtot<-sum(PBSout[,10])
BNPtot<-sum(PBSout[,12])

interest2<-c() #creating a vector of interest to weigh in the level of divergence by population, so that ones in most divergent populations don't get outweighed
for (i in 1:dim(PBSout)[[1]]){
  interest2<-(PBSout[,4]/BBtot)*100+(PBSout[,6]/VBtot)*100+(PBSout[,8]/PBtot)*100+(PBSout[,10]/SJtot)*100+(PBSout[,12]/BNPtot)*100
}

ord<-order(interest2,decreasing=TRUE) #order that vector
ord2<-ord[1:10] #show top10 regions

par(mar=c(4.2,5,4,4)) #plotting these outliers
plot(PBSout[ord2,"BBsum"],col='black',pch=20,cex=3,ylim=c(0,4),ylab="Level of divergence",xlab="Region number",
     cex.lab=2,cex.axis=2)
points(PBSout[ord2,"VBsum"],col='grey',pch=20,cex=3)
points(PBSout[ord2,"PBsum"],col='red',pch=20,cex=3)
points(PBSout[ord2,"SJsum"],col='darkorange',pch=20,cex=3)
points(PBSout[ord2,"BNPsum"],col="gold",pch=20,cex=3)

legend('topright',legend=c("BB","VB","PB","SJ","BNP"),col=c("black","grey","red","darkorange2","gold"),
       pch=20,cex=2,bty="n",y.intersp=1,x.intersp=.5)


```

## Sum regions: plotting
```{r}
pbs<-read.table("~/fgfh_post/data/fst/hudsonpbs_1kb.bed",header=FALSE,stringsAsFactors = FALSE) #reading in the windowed pbs estimates
pbsname<-c("Scaf","start","end","BBpbs","VBpbs","PBpbs","SJpbs","BNPpbs") #naming columns
colnames(pbs)<-pbsname

col<-c()# finding 1% outliers
for (i in 1:5){
  col[i]<-quantile(pbs[,i+3],prob=.99,na.rm=TRUE)
}

pbsc<-pbs %>% filter(str_detect(Scaf,"chr")) #only selecting chromosomes

#removing the crappy scaffold that has the first 141 windows of chromosome 16 (mismapped from chr1); this is discovered in dxy.r script in introgression folder
chr16<-str_detect(pbsc$Scaf,"chr16") #grab chr16
ord<-order(pbsc[chr16,"BBpbs"],decreasing=TRUE) #pick highest value of chr16
pbsc16<-pbsc[chr16,] #make an object
chr16rows<-as.numeric(rownames(pbsc[chr16,])) #grab rownames for it
crappyrows<-chr16rows[1:300] #get the first 141 rows which contain scaffold "crappy"
pbsct<-pbsc[-c(crappyrows),] #remove thos rows from total
chr16.2<-str_detect(pbsc$Scaf,"chr16") #do it again
head(pbsct[chr16,])
pbsc<-pbsct
head(pbsc[chr16,])

#Grabbing regions that are put together pretty well/widely----
pbs_out_temp<-read.table("~/fgfh_post/data/fst/hudson_pbsmergeoutliers.bed",stringsAsFactors = FALSE) #loads a pbs vector with windows merged within 50kb of each other and with max and windows count statistics
names<-c("Scaf","start","end","BBmax","BBcount","VBmax","VBcount","PBmax","PBcount","SJmax","SJcount","BNPmax","BNPcount")
colnames(pbs_out_temp)<-names

pbs_out<-pbs_out_temp %>% filter(str_detect(Scaf,"chr")) #selecting only chromosome mapped scaffolds

#checking for whether those are outliers in different groups--------
all<-pbs_out[,4]>col[1] & pbs_out[,6]>col[2] & pbs_out[,8]>col[3] & pbs_out[,10]>col[4] & pbs_out[,12]>col[5]
res<-pbs_out[,4]>col[1] & pbs_out[,6]>col[2] & pbs_out[,8]>col[3] & pbs_out[,10]<col[4] & pbs_out[,12]<col[5]
interm<-pbs_out[,4]<col[1] & pbs_out[,6]<col[2] & pbs_out[,8]<col[3] & pbs_out[,10]>col[4] & pbs_out[,12]>col[5]
bbu<-pbs_out[,4]>col[1] & pbs_out[,6]<col[2] & pbs_out[,8]<col[3] & pbs_out[,10]<col[4] & pbs_out[,12]<col[5]
vbu<-pbs_out[,4]<col[1] & pbs_out[,6]>col[2] & pbs_out[,8]<col[3] & pbs_out[,10]<col[4] & pbs_out[,12]<col[5]
pbu<-pbs_out[,4]<col[1] & pbs_out[,6]<col[2] & pbs_out[,8]>col[3] & pbs_out[,10]<col[4] & pbs_out[,12]<col[5]
sju<-pbs_out[,4]<col[1] & pbs_out[,6]<col[2] & pbs_out[,8]<col[3] & pbs_out[,10]>col[4] & pbs_out[,12]<col[5]
bnpu<-pbs_out[,4]<col[1] & pbs_out[,6]<col[2] & pbs_out[,8]<col[3] & pbs_out[,10]<col[4] & pbs_out[,12]>col[5]

write.table(pbsc[,1:3],"~/fgfh_post/data/fst/PBS_keep_1kb.bed",
            row.names = FALSE,col.names = FALSE,quote=FALSE,sep="\t")
write.table(pbs_out[all,1:3],"~/fgfh_post/data/fst/pbs_regions_sharedall.bed",
            row.names = FALSE,col.names = FALSE,quote = FALSE, sep="\t")
write.table(pbs_out[res,1:3],"~/fgfh_post/data/fst/pbs_regions_sharedres.bed",
            row.names = FALSE,col.names = FALSE,quote = FALSE, sep="\t")
write.table(pbs_out[interm,1:3],"~/fgfh_post/data/fst/pbs_regions_sharedinterm.bed",
            row.names = FALSE,col.names = FALSE,quote = FALSE, sep="\t")
write.table(pbs_out[bbu,1:3],"~/fgfh_post/data/fst/pbs_regions_sharedbbu.bed",
            row.names = FALSE,col.names = FALSE,quote = FALSE, sep="\t")
write.table(pbs_out[vbu,1:3],"~/fgfh_post/data/fst/pbs_regions_sharedvbu.bed",
            row.names = FALSE,col.names = FALSE,quote = FALSE, sep="\t")
write.table(pbs_out[pbu,1:3],"~/fgfh_post/data/fst/pbs_regions_sharedpbu.bed",
            row.names = FALSE,col.names = FALSE,quote = FALSE, sep="\t")
write.table(pbs_out[sju,1:3],"~/fgfh_post/data/fst/pbs_regions_sharedsju.bed",
            row.names = FALSE,col.names = FALSE,quote = FALSE, sep="\t")
write.table(pbs_out[bnpu,1:3],"~/fgfh_post/data/fst/pbs_regions_sharedbnpu.bed",
            row.names = FALSE,col.names = FALSE,quote = FALSE, sep="\t")


#source("http://bioconductor.org/biocLite.R")
#biocLite()
#biocLite('rtracklayer')

#Finding the overlaps in full data---------
library("rtracklayer")

bed1=import("~/fgfh_post/data/fst/PBS_keep_1kb.bed") #importing the windows in which we are searching

bedall=import("~/fgfh_post/data/fst/pbs_regions_sharedall.bed") #importing shared outliers
bed1overlall=bed1[bed1 %over% bedall] #Making overlapping regions into genome file
hitsall<-findOverlaps(bedall,bed1) #finding overlaps as hits
allhit<-subjectHits(hitsall) #making them into a true false vector

#same for the rest of the comparisons
bedres=import("~/fgfh_post/data/fst/pbs_regions_sharedres.bed")
bed1overlres=bed1[bed1 %over% bedres]
hitsres<-findOverlaps(bedres,bed1)
reshit<-subjectHits(hitsres)

bedinterm=import("~/fgfh_post/data/fst/pbs_regions_sharedinterm.bed")
bed1overlinterm=bed1[bed1 %over% bedinterm]
hitsinterm<-findOverlaps(bedinterm,bed1)
intermhit<-subjectHits(hitsinterm)

bedbbu=import("~/fgfh_post/data/fst/pbs_regions_sharedbbu.bed")
bed1overlbbu=bed1[bed1 %over% bedbbu]
hitsbbu<-findOverlaps(bedbbu,bed1)
bbuhit<-subjectHits(hitsbbu)

bedvbu=import("~/fgfh_post/data/fst/pbs_regions_sharedvbu.bed")
bed1overlvbu=bed1[bed1 %over% bedvbu]
hitsvbu<-findOverlaps(bedvbu,bed1)
vbuhit<-subjectHits(hitsvbu)

bedpbu=import("~/fgfh_post/data/fst/pbs_regions_sharedpbu.bed")
bed1overlpbu=bed1[bed1 %over% bedpbu]
hitspbu<-findOverlaps(bedpbu,bed1)
pbuhit<-subjectHits(hitspbu)

bedsju=import("~/fgfh_post/data/fst/pbs_regions_sharedsju.bed")
bed1overlsju=bed1[bed1 %over% bedsju]
hitssju<-findOverlaps(bedsju,bed1)
sjuhit<-subjectHits(hitssju)

bedbnpu=import("~/fgfh_post/data/fst/pbs_regions_sharedbnpu.bed")
bed1overlbnpu=bed1[bed1 %over% bedbnpu]
hitsbnpu<-findOverlaps(bedbnpu,bed1)
bnpuhit<-subjectHits(hitsbnpu)

pbsc<-cbind(pbsc,0,0,0,0,0,0,0,0) #adding columns to the dataframe of pbs values
newn<-c("Scaf","start","end","BB","VB","PB","SJ","BNP","all","res","interm","bbu","vbu","pbu","sju","bnpu") #giving them names
colnames(pbsc)<-newn
pbsc[allhit,"all"]<-pbsc[allhit,"all"]+1 #adding 1s for true values in hits parameter
pbsc[reshit,"res"]<-pbsc[reshit,"res"]+1
pbsc[intermhit,"interm"]<-pbsc[intermhit,"interm"]+1
pbsc[bbuhit,"bbu"]<-pbsc[bbuhit,"bbu"]+1
pbsc[vbuhit,"vbu"]<-pbsc[vbuhit,"vbu"]+1
pbsc[pbuhit,"pbu"]<-pbsc[pbuhit,"pbu"]+1
pbsc[sjuhit,"sju"]<-pbsc[sjuhit,"sju"]+1
pbsc[bnpuhit,"bnpu"]<-pbsc[bnpuhit,"bnpu"]+1

#Simplified to fewer outliers----

jpeg(filename="~/Documents/UCD/Projects/Adaptation + Introgression/draft/images/pbs_sum.jpg",width=1000,height=800)
pbsc$Scaf<-factor(pbsc$Scaf,levels=c("chr1","chr2","chr3","chr4","chr5","chr6","chr7","chr8","chr9","chr10",
                                     "chr11","chr12","chr13","chr14","chr15","chr16","chr17","chr18","chr19",
                                     "chr20","chr21","chr22","chr23","chr24"))
palette(c("grey90","grey50"))
par(mfrow=c(5,1),mar=c(0,3,0,0))
plot(pbsc[,4],pch=20,cex=2,
     col=ifelse(pbsc[,"all"]>0,"purple",
                ifelse(pbsc[,"res"]>0,"black",
                       ifelse(pbsc[,"interm"]>0,"firebrick2",
                              as.factor(pbsc[,1])))),
     xlab="",xaxt='n',cex.lab=1,cex.axis=3,bty="n",ylim=c(-.5,3.8),yaxs="i")

plot(pbsc[,5],pch=20,cex=2,
     col=ifelse(pbsc[,"all"]>0,"purple",
                ifelse(pbsc[,"res"]>0,"black",
                       ifelse(pbsc[,"interm"]>0,"firebrick2",
                            as.factor(pbsc[,1])))),
     xlab="",xaxt='n',cex.lab=1,cex.axis=3,bty="n",ylim=c(-.5,3.8),yaxs="i")

plot(pbsc[,6],pch=20,cex=2,
     col=ifelse(pbsc[,"all"]>0,"purple",
                ifelse(pbsc[,"res"]>0,"black",
                       ifelse(pbsc[,"interm"]>0,"firebrick2",
                              as.factor(pbsc[,1])))),
     xlab="",xaxt='n',cex.lab=1,cex.axis=3,bty="n",ylim=c(-.5,3.8),yaxs="i")

plot(pbsc[,7],pch=20,cex=2,
     col=ifelse(pbsc[,"all"]>0,"purple",
                ifelse(pbsc[,"res"]>0,"black",
                       ifelse(pbsc[,"interm"]>0,"firebrick2",
                              as.factor(pbsc[,1])))),
     xlab="",xaxt='n',cex.lab=1,cex.axis=3,bty="n",ylim=c(-.5,3.8),yaxs="i")

plot(pbsc[,8],pch=20,cex=2,
     col=ifelse(pbsc[,"all"]>0,"purple",
                ifelse(pbsc[,"res"]>0,"black",
                       ifelse(pbsc[,"interm"]>0,"firebrick2",
                              as.factor(pbsc[,1])))),
     xlab="",xaxt='n',cex.lab=1,cex.axis=3,bty="n",ylim=c(-.5,3.8),yaxs="i")
dev.off()
```

## Unique for Intermediates?
* Breaking these up into 1kb windows and observing whether they are unique

```{r}
###Plotting outliers vs each other-----------
pbsct<-pbs %>% filter(str_detect(Scaf,"chr")) #getting only scaffolds mapped onto chromosomes here

pbsc<-na.omit(pbsc[,1:8]) #removing NA values from them

#checking for whether those are outliers in different groups
all<-pbsc[,4]>col[1] & pbsc[,5]>col[2] & pbsc[,6]>col[3] & pbsc[,7]>col[4] & pbsc[,8]>col[5]
res<-pbsc[,4]>col[1] & pbsc[,5]>col[2] & pbsc[,6]>col[3] & pbsc[,7]<col[4] & pbsc[,8]<col[5]
interm<-pbsc[,4]<col[1] & pbsc[,5]<col[2] & pbsc[,6]<col[3] & pbsc[,7]>col[4] & pbsc[,8]>col[5]
bbu<-pbsc[,4]>col[1] & pbsc[,5]<col[2] & pbsc[,6]<col[3] & pbsc[,7]<col[4] & pbsc[,8]<col[5]
vbu<-pbsc[,4]<col[1] & pbsc[,5]>col[2] & pbsc[,6]<col[3] & pbsc[,7]<col[4] & pbsc[,8]<col[5]
pbu<-pbsc[,4]<col[1] & pbsc[,5]<col[2] & pbsc[,6]>col[3] & pbsc[,7]<col[4] & pbsc[,8]<col[5]
sju<-pbsc[,4]<col[1] & pbsc[,5]<col[2] & pbsc[,6]<col[3] & pbsc[,7]>col[4] & pbsc[,8]<col[5]
bnpu<-pbsc[,4]<col[1] & pbsc[,5]<col[2] & pbsc[,6]<col[3] & pbsc[,7]<col[4] & pbsc[,8]>col[5]

#as before, checking which of those regions of divergence maps to specific windows of divergence
write.table(pbsc[,1:3],"~/analysis/data/fst/PBS_keep_1kb.bed",row.names = FALSE,col.names = FALSE,quote=FALSE,sep='\t')
write.table(na.omit(pbsc[all,1:3]),"~/analysis/data/fst/pbs_regions_sharedall.bed",row.names = FALSE,col.names = FALSE,quote = FALSE,sep='\t')
write.table(na.omit(pbsc[res,1:3]),"~/analysis/data/fst/pbs_regions_sharedres.bed",row.names = FALSE,col.names = FALSE,quote = FALSE,sep='\t')
write.table(na.omit(pbsc[interm,1:3]),"~/analysis/data/fst/pbs_regions_sharedinterm.bed",row.names = FALSE,col.names = FALSE,quote = FALSE,sep='\t')
write.table(na.omit(pbsc[bbu,1:3]),"~/analysis/data/fst/pbs_regions_sharedbbu.bed",row.names = FALSE,col.names = FALSE,quote = FALSE,sep='\t')
write.table(na.omit(pbsc[vbu,1:3]),"~/analysis/data/fst/pbs_regions_sharedvbu.bed",row.names = FALSE,col.names = FALSE,quote = FALSE,sep='\t')
write.table(na.omit(pbsc[pbu,1:3]),"~/analysis/data/fst/pbs_regions_sharedpbu.bed",row.names = FALSE,col.names = FALSE,quote = FALSE,sep='\t')
write.table(na.omit(pbsc[sju,1:3]),"~/analysis/data/fst/pbs_regions_sharedsju.bed",row.names = FALSE,col.names = FALSE,quote = FALSE,sep='\t')
write.table(na.omit(pbsc[bnpu,1:3]),"~/analysis/data/fst/pbs_regions_sharedbnpu.bed",row.names = FALSE,col.names = FALSE,quote = FALSE,sep='\t')


#source("http://bioconductor.org/biocLite.R")
#biocLite()
#biocLite('rtracklayer')

#Finding the overlaps in full data---------
library("rtracklayer")

#summarizing these outlier windows, instead of by regions, by 1kb windows - look behind if confused about script (previous chunk)
bed1=import("~/analysis/data/fst/PBS_keep_1kb.bed")

bedall=import("~/analysis/data/fst/pbs_regions_sharedall.bed")
bed1overlall=bed1[bed1 %over% bedall]
hitsall<-findOverlaps(bedall,bed1)
allhit<-subjectHits(hitsall)

bedres=import("~/analysis/data/fst/pbs_regions_sharedres.bed")
bed1overlres=bed1[bed1 %over% bedres]
hitsres<-findOverlaps(bedres,bed1)
reshit<-subjectHits(hitsres)

bedinterm=import("~/analysis/data/fst/pbs_regions_sharedinterm.bed")
bed1overlinterm=bed1[bed1 %over% bedinterm]
hitsinterm<-findOverlaps(bedinterm,bed1)
intermhit<-subjectHits(hitsinterm)

bedbbu=import("~/analysis/data/fst/pbs_regions_sharedbbu.bed")
bed1overlbbu=bed1[bed1 %over% bedbbu]
hitsbbu<-findOverlaps(bedbbu,bed1)
bbuhit<-subjectHits(hitsbbu)

bedvbu=import("~/analysis/data/fst/pbs_regions_sharedvbu.bed")
bed1overlvbu=bed1[bed1 %over% bedvbu]
hitsvbu<-findOverlaps(bedvbu,bed1)
vbuhit<-subjectHits(hitsvbu)

bedpbu=import("~/analysis/data/fst/pbs_regions_sharedpbu.bed")
bed1overlpbu=bed1[bed1 %over% bedpbu]
hitspbu<-findOverlaps(bedpbu,bed1)
pbuhit<-subjectHits(hitspbu)

bedsju=import("~/analysis/data/fst/pbs_regions_sharedsju.bed")
bed1overlsju=bed1[bed1 %over% bedsju]
hitssju<-findOverlaps(bedsju,bed1)
sjuhit<-subjectHits(hitssju)

bedbnpu=import("~/analysis/data/fst/pbs_regions_sharedbnpu.bed")
bed1overlbnpu=bed1[bed1 %over% bedbnpu]
hitsbnpu<-findOverlaps(bedbnpu,bed1)
bnpuhit<-subjectHits(hitsbnpu)

pbsc<-cbind(pbsc,0,0,0,0,0,0,0,0) #adding these to the 1kb windows we've separated the genome into
newn<-c("Scaf","start","end","BB","VB","PB","SJ","BNP","all","res","interm","bbu","vbu","pbu","sju","bnpu")
colnames(pbsc)<-newn
pbsc[allhit,"all"]<-pbsc[allhit,"all"]+1 #naming adding +1 to each of those windows that is shared
pbsc[reshit,"res"]<-pbsc[reshit,"res"]+1
pbsc[intermhit,"interm"]<-pbsc[intermhit,"interm"]+1
pbsc[bbuhit,"bbu"]<-pbsc[bbuhit,"bbu"]+1
pbsc[vbuhit,"vbu"]<-pbsc[vbuhit,"vbu"]+1
pbsc[pbuhit,"pbu"]<-pbsc[pbuhit,"pbu"]+1
pbsc[sjuhit,"sju"]<-pbsc[sjuhit,"sju"]+1
pbsc[bnpuhit,"bnpu"]<-pbsc[bnpuhit,"bnpu"]+1

par(mfrow=c(2,3),mar=c(4,4,0,0)) #plotting these outlier windows vs each other for each population to see how they are distributed among resistant and intermediate populations
plot(pbsc[,"BB"],pbsc[,"VB"],pch=20,cex=.7,
     col=ifelse(pbsc[,"all"]>0,"purple",
                ifelse(pbsc[,"interm"]>0,"red",
                       ifelse(pbsc[,"res"],"black",NA))),bty='l',
     xlab="VB z values",ylab="BB z values")
abline(h=0,v=0)

plot(pbsc[,"BB"],pbsc[,"PB"],pch=20,cex=.7,
     col=ifelse(pbsc[,"all"]>0,"purple",
                ifelse(pbsc[,"interm"]>0,"red",
                       ifelse(pbsc[,"res"],"black",NA))),bty='l',
     xlab="PB z values",ylab="BB z values")
abline(h=0,v=0)

plot(pbsc[,"VB"],pbsc[,"PB"],pch=20,cex=.7,
     col=ifelse(pbsc[,"all"]>0,"purple",
                ifelse(pbsc[,"interm"]>0,"red",
                       ifelse(pbsc[,"res"],"black",NA))),bty='l',
     xlab="PB z values",ylab="VB z values")
abline(h=0,v=0)

plot(pbsc[,"SJ"],pbsc[,"PB"],pch=20,cex=.7,
     col=ifelse(pbsc[,"all"]>0,"purple",
                ifelse(pbsc[,"interm"]>0,"red",
                       ifelse(pbsc[,"res"],"black",NA))),bty='l',
     xlab="PB z values",ylab="SJ z values")
abline(h=0,v=0)

plot(pbsc[,"BNP"],pbsc[,"PB"],pch=20,cex=.7,
     col=ifelse(pbsc[,"all"]>0,"purple",
                ifelse(pbsc[,"interm"]>0,"red",
                       ifelse(pbsc[,"res"],"black",NA))),bty='l',
     xlab="PB z values",ylab="BNP z values")
abline(h=0,v=0)

plot(pbsc[,"BNP"],pbsc[,"SJ"],pch=20,cex=.7,
     col=ifelse(pbsc[,"all"]>0,"purple",
                ifelse(pbsc[,"interm"]>0,"red",
                       ifelse(pbsc[,"res"],"black",NA))),bty='l',
     xlab="SJ z values",ylab="BNP z values")
abline(h=0,v=0)
```

## Simulation with 1000 iterations
* Test for finding if they are truly different by simulating 1000 random regions of the same size from the genome

```{r}

intermeans<-c()
for(i in 1:5){
  intermeans[i]<-mean(pbsc[interm,i+3],na.rm=TRUE)
}

resmeans<-c()
for(i in 1:5){
  resmeans[i]<-mean(pbsc[res,i+3],na.rm=TRUE)
}

allmeans<-c()
for(i in 1:5){
  allmeans[i]<-mean(pbsc[all,i+3],na.rm=TRUE)
}

#plotting histogram for intermediate regions----
rimeans<-c()
b<-c()
for(i in 1:5){
  for(j in 1:1000){
    b[j]<-mean(sample(pbsc[,i+3],size=765,replace=FALSE))
  }
  rimeans<-cbind(rimeans,b)
}

nam<-c("BB","VB","PB","SJ","BNP")
colnames(rimeans)<-nam
cols<-c("black","black","black","firebrick2","firebrick2")

jpeg(filename="~/backup/UCD/Projects/Adaptation + Introgression/draft/images/pbs_interm_random.jpg",width=1000,height=800)
par(mfrow=c(2,3),mar=c(4,4,2,2))
for(i in 1:length(nam)){
  hist(rimeans[,i],main='',breaks=30,xlim=c(range(rimeans[,i]-.1,na.rm=TRUE)[[1]],intermeans[i]+.5),
       bty='l',col=cols[i],border=cols[i],xlab=nam[i],cex.axis=3,ylab='')
  abline(v=intermeans[i],lwd=3,col="green")
  box(bty='l',lwd=3)
}
dev.off()

#plotting histogram for resistant only regions----

rrmeans<-c()
b<-c()
for(i in 1:5){
  for(j in 1:1000){
    b[j]<-mean(sample(pbsc[,i+3],size=2549,replace=FALSE))
  }
  rrmeans<-cbind(rrmeans,b)
}

nam<-c("BB","VB","PB","SJ","BNP")
colnames(rrmeans)<-nam
cols<-c("black","black","black","firebrick2","firebrick2")

par(mfrow=c(2,3))
for(i in 1:length(nam)){
  hist(rrmeans[,i],main='',breaks=30,xlim=c(range(rrmeans[,i]-.1,na.rm=TRUE)[[1]],resmeans[i]+.5),
       bty='l',col=cols[i],border=cols[i],xlab=nam[i])
  abline(v=resmeans[i],lwd=3,col="green")
}

###plotting histogram for shared regions----

rameans<-c()
b<-c()
for(i in 1:5){
  for(j in 1:1000){
    b[j]<-mean(sample(pbsc[,i+3],size=259,replace=FALSE))
  }
  rameans<-cbind(rameans,b)
}

nam<-c("BB","VB","PB","SJ","BNP")
colnames(rameans)<-nam
cols<-c("black","black","black","firebrick2","firebrick2")

par(mfrow=c(2,3))
for(i in 1:length(nam)){
  hist(rameans[,i],main='',breaks=30,xlim=c(range(rameans[,i]-.1,na.rm=TRUE)[[1]],allmeans[i]+.5),
       bty='l',col=cols[i],border=cols[i],xlab=nam[i])
  abline(v=allmeans[i],lwd=3,col="green")
}

```


## Plotting specific regions of the genome  - messed up for now, will have to re-do

###Regions used

```{r}
      Scaf    start      end
1     chr1        0  2903297
321   chr8 16458074 17415074
436  chr10 23911854 26893527
1057 chr24 26047741 26157741
72    chr2 26988885 27613885
```
###AHR1a/2a Introgressed region
```{r}
pbs<-read.table("~/analysis/data/fst/hudsonpbs_1kb.bed",header=FALSE,stringsAsFactors = FALSE) #reading in the windowed pbs estimates
pbsname<-c("Scaf","start","end","BBpbs","VBpbs","PBpbs","SJpbs","BNPpbs") #naming columns
colnames(pbs)<-pbsname

col<-c()# finding 1% outliers
for (i in 1:5){
  col[i]<-quantile(pbs[,i+3],prob=.99,na.rm=TRUE)
}

pbsc<-pbs %>% filter(str_detect(Scaf,"chr")) #only selecting chromosomes

#smoothing funciton----
subsmooth <- function(vec,by=10,width=11){
  
  len <- length(vec)
  subl <- seq(from=by,to=len,by=by)
  submax <- length(subl)
  width <- width/2
  test <- vec[subl]
  
  for(i in 1:submax){
    
    j <- i - width
    k <- i + width
    if(j < 1) {j <- 1}
    if(k > submax) {k <- submax}
    test[i] <- mean(test[j:k],na.rm=TRUE)
  }
  
  return(test)
  
}


###Plotting CHR1/AHR region------------
pbsc1<-pbsc %>% filter(str_detect(Scaf,"\\bchr1\\b"))

jpeg(filename="~/backup/UCD/Projects/Adaptation + Introgression/draft/images/Ahr1a2a.jpg",width=1000,height=800)
par(mfrow=c(5,1),mar=c(3,3,0,0),mgp=c(1,1,0))
for(i in 1:5){
  plot(subsmooth(pbsc1[1:5000,i+3]),pch=20,cex=.8,ylim=c(0,1.8),bty='l',cex.axis=2,ylab='',xlab='')
  box(bty='l',lwd=3)
  abline(v=c(50,60),col="red",lty=2,lwd=1.5)
}
dev.off()
```

```{bash}
#!/bin/bash

#PBS -l nodes=1:ppn=8
#PBS -l walltime=01:00:00

#programs & files
my_tabix=/data/oziolore/program/htslib/tabix
my_bgz=/data/oziolore/program/htslib/bgzip

my_vcf=/data/oziolore/fhet/data/varcall/filtered_chr.vcf.bgz
my_list=/data/oziolore/fhet/data/outliers/ahr1a2a.txt
my_out=/data/oziolore/fhet/data/outliers/ahr1a2a.vcf.bgz

$my_tabix -fh $my_vcf chr1:0-1 | $my_bgz > $my_out
xargs -a $my_list -I {} $my_tabix -f $my_vcf {} | $my_bgz >> $my_out
```

```{bash}
scp kodiak:/data/oziolore/fhet/data/outliers/ahr1a2a.vcf.bgz /home/elias/analysis/data/fst/
```

```{bash}
zcat ~/analysis/data/fst/ahr1a2a.vcf.bgz | ~/analysis/scripts/haplo/haploidize_gran_mine.r | gzip > ~/analysis/data/fst/ahr1a2a_haplo.vcf.gz
```

```{r}
#install.packages("Rphylip")
library(viridis)
library(dplyr)
library(magrittr)
library(Rphylip)
library(ape)
library(stringr)
vcf<-read.table("~/analysis/data/fst/ahr1a2a_haplo.vcf.gz",stringsAsFactors = FALSE) #vcf that has been filtered out to only present one allele call per site per individual
sexscore<-read.table("~/analysis/scripts/depth/sexscore",header=TRUE)
cname<-c(seq(1:9),as.character(sexscore[,1])) # colnames for the vcf
colnames(vcf)<-cname

#toss sites that happen to have more than one allele
keep<-!grepl(",",vcf[,5]) #none because of the way I've called haplotypes table to check that

gt<-as.matrix(vcf[,10:297])
class(gt)<-"numeric"

#toss individuals with greater than 90% missing data
keep<-colMeans(is.na(gt))<0.9
gt<-gt[,keep]

#population identifiers
pop<-ifelse(grepl("BB",sexscore[,1]),"BB",
            ifelse(grepl("VB",sexscore[,1]),"VB",
                   ifelse(grepl("PB",sexscore[,1]),"PB",
                          ifelse(grepl("SJ",sexscore[,1]),"SJ",
                                 ifelse(grepl("BNP",sexscore[,1]),"BNP",
                                        ifelse(grepl("SP",sexscore[,1]),"SP",
                                               ifelse(grepl("GB",sexscore[,1]),"GB","WRONG")))))))
popcol<-ifelse(grepl("BB",sexscore[,1]),"black",
            ifelse(grepl("VB",sexscore[,1]),"black",
                   ifelse(grepl("PB",sexscore[,1]),"black",
                          ifelse(grepl("SJ",sexscore[,1]),"firebrick2",
                                 ifelse(grepl("BNP",sexscore[,1]),"firebrick2",
                                        ifelse(grepl("SP",sexscore[,1]),"cadetblue3",
                                               ifelse(grepl("GB",sexscore[,1]),"cadetblue3","WRONG")))))))
popfill<-ifelse(grepl("BB",sexscore[,1]),"black",
               ifelse(grepl("VB",sexscore[,1]),"grey40",
                      ifelse(grepl("PB",sexscore[,1]),"grey80",
                             ifelse(grepl("SJ",sexscore[,1]),"red",
                                    ifelse(grepl("BNP",sexscore[,1]),"lightpink",
                                           ifelse(grepl("SP",sexscore[,1]),"cadetblue3",
                                                  ifelse(grepl("GB",sexscore[,1]),"cadetblue1","WRONG")))))))

pop2<-pop[keep]
popcol2<-popcol[keep]
popfill2<-popfill[keep]

popname<-c("BB","VB","PB","SJ","BNP","SP","GB")
popnamec<-c("black","black","black","firebrick1","firebrick1","cadetblue3","cadetblue3")
#distance matrix and nj tree
d <- t(gt) %>% dist()
#dd<-as.dist(ultrametric(d)) #imputing data for missing values using ultrametric procedure
mds <- cmdscale(d)
tr <- nj(d)

#plotting tree
jpeg(filename="~/backup/UCD/Projects/Adaptation + Introgression/draft/images/ahr1a2a_NJ.jpg",width=400,height=1000)
plot(tr,"unrooted",show.tip.label=FALSE)
tiplabels(pch=21,col=popcol2,bg=popfill2,cex=1.2)
legend("topright",pch=20,cex=1.2,legend=popname,col=popnamec)
dev.off()

#plotting mds
jpeg(filename="~/backup/UCD/Projects/Adaptation + Introgression/draft/images/ahr1a2a_MDS.jpg",width=1000,height=600)
par(mfrow=c(1,1),mar=c(3,3,0,0))
plot(mds,col=popcol2,cex=2,cex.axis=2,pch=21,
     bg=popfill2,bty='l')
box(bty='l',lwd=5)
dev.off()

#Plotting both
par(mfrow=c(1,2))
plot(tr,"unrooted",show.tip.label=FALSE)
tiplabels(pch=20,col=popcol2,bg="white",cex=1.2)
plot(mds,pch=20,col=popcol2)
legend("topleft",pch=20,cex=.8,legend=popname,col=popnamec,y.intersp=.7)

```

###ARNT Chr10/ introgressed region

```{r}
pbsc10<-pbsc %>% filter(str_detect(Scaf,"\\bchr10\\b"))

par(mfrow=c(3,1),mar=c(3,3,0,0),mgp=c(1,1,0))

for(i in 1:3){
  plot(pbsc10[23000:25000,i+3],pch=20,cex=.5,ylim=c(0,1.8),bty='l',cex.axis=2,ylab='',xlab='',
       col=ifelse(pbsc10[23000:25000,2]>23926932 & pbsc10[23000:25000,2]<23951650,"red","black"))
  box(bty='l',lwd=3)
  abline(h=0,v=c(941,964),col="red",lty=2,lwd=1.5)
}

```

```{bash}
#!/bin/bash

#PBS -l nodes=1:ppn=8
#PBS -l walltime=01:00:00

#programs & files
my_tabix=/data/oziolore/program/htslib/tabix
my_bgz=/data/oziolore/program/htslib/bgzip

my_vcf=/data/oziolore/fhet/data/varcall/filtered_chr.vcf.bgz
my_list=/data/oziolore/fhet/data/outliers/arnt_chr10.txt
my_out=/data/oziolore/fhet/data/outliers/arnt_chr10.vcf.bgz

$my_tabix -fh $my_vcf chr1:0-1 | $my_bgz > $my_out
xargs -a $my_list -I {} $my_tabix -f $my_vcf {} | $my_bgz >> $my_out

```

```{bash}
scp kodiak:/data/oziolore/fhet/data/outliers/arnt_chr10.vcf.bgz ~/analysis/data/fst/
```

```{bash}
zcat ~/analysis/data/fst/arnt_chr10.vcf.bgz | ~/analysis/scripts/haplo/haploidize_gran_mine.r | gzip > ~/analysis/data/fst/arnt_chr10_haplo.vcf.gz
```

```{r}
#install.packages("Rphylip")
library(viridis)
library(dplyr)
library(magrittr)
library(Rphylip)
library(ape)
library(stringr)
vcf<-read.table("~/analysis/data/fst/arnt_chr10_haplo.vcf.gz",stringsAsFactors = FALSE) #vcf that has been filtered out to only present one allele call per site per individual
sexscore<-read.table("~/analysis/scripts/depth/sexscore",header=TRUE)
cname<-c(seq(1:9),as.character(sexscore[,1])) # colnames for the vcf
colnames(vcf)<-cname

#toss sites that happen to have more than one allele
keep<-!grepl(",",vcf[,5]) #none because of the way I've called haplotypes table to check that

gt<-as.matrix(vcf[,10:297])
class(gt)<-"numeric"

#toss individuals with greater than 90% missing data
keep<-colMeans(is.na(gt))<0.9
gt<-gt[,keep]

#population identifiers
pop<-ifelse(grepl("BB",sexscore[,1]),"BB",
            ifelse(grepl("VB",sexscore[,1]),"VB",
                   ifelse(grepl("PB",sexscore[,1]),"PB",
                          ifelse(grepl("SJ",sexscore[,1]),"SJ",
                                 ifelse(grepl("BNP",sexscore[,1]),"BNP",
                                        ifelse(grepl("SP",sexscore[,1]),"SP",
                                               ifelse(grepl("GB",sexscore[,1]),"GB","WRONG")))))))
popcol<-ifelse(grepl("BB",sexscore[,1]),"black",
            ifelse(grepl("VB",sexscore[,1]),"black",
                   ifelse(grepl("PB",sexscore[,1]),"black",
                          ifelse(grepl("SJ",sexscore[,1]),"firebrick2",
                                 ifelse(grepl("BNP",sexscore[,1]),"firebrick2",
                                        ifelse(grepl("SP",sexscore[,1]),"cadetblue3",
                                               ifelse(grepl("GB",sexscore[,1]),"cadetblue3","WRONG")))))))
popfill<-ifelse(grepl("BB",sexscore[,1]),"black",
               ifelse(grepl("VB",sexscore[,1]),"grey40",
                      ifelse(grepl("PB",sexscore[,1]),"grey80",
                             ifelse(grepl("SJ",sexscore[,1]),"red",
                                    ifelse(grepl("BNP",sexscore[,1]),"lightpink",
                                           ifelse(grepl("SP",sexscore[,1]),"cadetblue3",
                                                  ifelse(grepl("GB",sexscore[,1]),"cadetblue1","WRONG")))))))

pop2<-pop[keep]
popcol2<-popcol[keep]
popfill2<-popfill[keep]

popname<-c("BB","VB","PB","SJ","BNP","SP","GB")
popnamec<-c("black","black","black","firebrick1","firebrick1","cadetblue3","cadetblue3")
#distance matrix and nj tree
d <- t(gt) %>% dist()
#dd<-as.dist(ultrametric(d)) #imputing data for missing values using ultrametric procedure
mds <- cmdscale(d)
tr <- nj(d)

#plotting tree
plot(tr,"unrooted",show.tip.label=FALSE)
tiplabels(pch=20,col=popcol2,bg="white",cex=1.2)
legend("topright",pch=20,cex=1.2,legend=popname,col=popnamec)

#plotting mds
par(mfrow=c(1,1),mar=c(3,3,0,0))
plot(mds,col=popcol2,cex=2,cex.axis=2,pch=21,
     bg=popfill2,bty='l')
box(bty='l',lwd=5)

legend("topright",legend=c("BB","VB","PB","SJ","BNP","SP","GB"),col=c("black","black","black","firebrick1","firebrick1","cadetblue3","cadetblue3"),
       pch=21,cex=2,y.intersp=.5,bty='n',bg=c("black","grey40","grey80","firebrick1","lightpink","cadetblue1","cadetblue3"))

#Plotting both
par(mfrow=c(1,2))
plot(tr,"unrooted",show.tip.label=FALSE)
tiplabels(pch=20,col=popcol2,bg="white",cex=1.2)
plot(mds,pch=20,col=popcol2)
legend("topleft",pch=20,cex=.8,legend=popname,col=popnamec,y.intersp=.7)

```
###ARNT Chr8 outlier
```{r}
#plotting ARNT chr8----
pbsc8<-pbsc %>% filter(str_detect(Scaf,"\\bchr8\\b"))

par(mfrow=c(5,1),mar=c(3,3,0,0),mgp=c(1,1,0))

for(i in 1:5){
  plot(subsmooth(pbsc8[14000:18000,i+3]),pch=20,cex=.5,ylim=c(0,.5),bty='l',cex.axis=2,ylab='',xlab='')
  box(bty='l',lwd=3)
  abline(v=c(170,173),col="red",lty=2,lwd=1.5)
}

```

```{bash}
#!/bin/bash

#PBS -l nodes=1:ppn=8
#PBS -l walltime=01:00:00

#programs & files
my_tabix=/data/oziolore/program/htslib/tabix
my_bgz=/data/oziolore/program/htslib/bgzip

my_vcf=/data/oziolore/fhet/data/varcall/filtered_chr.vcf.bgz
my_list=/data/oziolore/fhet/data/outliers/arnt_chr8.txt
my_out=/data/oziolore/fhet/data/outliers/arnt_chr8.vcf.bgz

$my_tabix -fh $my_vcf chr1:0-1 | $my_bgz > $my_out
xargs -a $my_list -I {} $my_tabix -f $my_vcf {} | $my_bgz >> $my_out
```

```{bash}
scp kodiak:/data/oziolore/fhet/data/outliers/arnt_chr8.vcf.bgz ~/analysis/data/fst/
```

```{bash}
zcat ~/analysis/data/fst/arnt_chr8.vcf.bgz | ~/analysis/scripts/haplo/haploidize_gran_mine.r | gzip > ~/analysis/data/fst/arnt_chr8_haplo.vcf.gz
```

```{r}
#install.packages("Rphylip")
library(viridis)
library(dplyr)
library(magrittr)
library(Rphylip)
library(ape)
library(stringr)
vcf<-read.table("~/analysis/data/fst/arnt_chr8_haplo.vcf.gz",stringsAsFactors = FALSE) #vcf that has been filtered out to only present one allele call per site per individual
sexscore<-read.table("~/analysis/scripts/depth/sexscore",header=TRUE)
cname<-c(seq(1:9),as.character(sexscore[,1])) # colnames for the vcf
colnames(vcf)<-cname

#toss sites that happen to have more than one allele
keep<-!grepl(",",vcf[,5]) #none because of the way I've called haplotypes table to check that

gt<-as.matrix(vcf[,10:297])
class(gt)<-"numeric"

#toss individuals with greater than 90% missing data
keep<-colMeans(is.na(gt))<0.9
gt<-gt[,keep]

#population identifiers
pop<-ifelse(grepl("BB",sexscore[,1]),"BB",
            ifelse(grepl("VB",sexscore[,1]),"VB",
                   ifelse(grepl("PB",sexscore[,1]),"PB",
                          ifelse(grepl("SJ",sexscore[,1]),"SJ",
                                 ifelse(grepl("BNP",sexscore[,1]),"BNP",
                                        ifelse(grepl("SP",sexscore[,1]),"SP",
                                               ifelse(grepl("GB",sexscore[,1]),"GB","WRONG")))))))
popcol<-ifelse(grepl("BB",sexscore[,1]),"black",
            ifelse(grepl("VB",sexscore[,1]),"black",
                   ifelse(grepl("PB",sexscore[,1]),"black",
                          ifelse(grepl("SJ",sexscore[,1]),"firebrick2",
                                 ifelse(grepl("BNP",sexscore[,1]),"firebrick2",
                                        ifelse(grepl("SP",sexscore[,1]),"cadetblue3",
                                               ifelse(grepl("GB",sexscore[,1]),"cadetblue3","WRONG")))))))
popfill<-ifelse(grepl("BB",sexscore[,1]),"black",
               ifelse(grepl("VB",sexscore[,1]),"grey40",
                      ifelse(grepl("PB",sexscore[,1]),"grey80",
                             ifelse(grepl("SJ",sexscore[,1]),"red",
                                    ifelse(grepl("BNP",sexscore[,1]),"lightpink",
                                           ifelse(grepl("SP",sexscore[,1]),"cadetblue3",
                                                  ifelse(grepl("GB",sexscore[,1]),"cadetblue1","WRONG")))))))

pop2<-pop[keep]
popcol2<-popcol[keep]
popfill2<-popfill[keep]

popname<-c("BB","VB","PB","SJ","BNP","SP","GB")
popnamec<-c("black","black","black","firebrick1","firebrick1","cadetblue3","cadetblue3")
#distance matrix and nj tree
d <- t(gt) %>% dist()
#dd<-as.dist(ultrametric(d)) #imputing data for missing values using ultrametric procedure
mds <- cmdscale(d)
tr <- nj(d)

#plotting tree
jpeg(filename="~/backup/UCD/Projects/Adaptation + Introgression/draft/images/arnt_chr8_NJ.jpg",width=400,height=1000)
plot(tr,"unrooted",show.tip.label=FALSE)
tiplabels(pch=21,col=popcol2,bg=popfill2,cex=1.2)
legend("topright",pch=20,cex=1.2,legend=popname,col=popnamec)
dev.off()

#plotting mds
jpeg(filename="~/backup/UCD/Projects/Adaptation + Introgression/draft/images/arnt_chr8_MDS.jpg",width=1000,height=600)
par(mfrow=c(1,1),mar=c(3,3,0,0))
plot(mds,col=popcol2,cex=2,cex.axis=2,pch=21,
     bg=popfill2,bty='l')
box(bty='l',lwd=5)
dev.off()

#Plotting both
par(mfrow=c(1,2))
plot(tr,"unrooted",show.tip.label=FALSE)
tiplabels(pch=20,col=popcol2,bg="white",cex=1.2)
plot(mds,pch=20,col=popcol2)
legend("topleft",pch=20,cex=.8,legend=popname,col=popnamec,y.intersp=.7)

```


### AIP chr2
```{r}
#plotting AIP chr2----
pbsc2<-pbsc %>% filter(str_detect(Scaf,"\\bchr2\\b"))

par(mfrow=c(5,1),mar=c(3,3,0,0),mgp=c(1,1,0))

for(i in 1:5){
  plot(subsmooth(pbsc2[23000:26000,i+3]),pch=20,cex=.5,ylim=c(0,.4),bty='l',cex.axis=2,ylab='',xlab='')
  box(bty='l',lwd=3)
  abline(v=c(140,142),col="red",lty=2,lwd=1.5)
}

```

```{bash}
#!/bin/bash

#PBS -l nodes=1:ppn=8
#PBS -l walltime=01:00:00

#programs & files
my_tabix=/data/oziolore/program/htslib/tabix
my_bgz=/data/oziolore/program/htslib/bgzip

my_vcf=/data/oziolore/fhet/data/varcall/filtered_chr.vcf.bgz
my_list=/data/oziolore/fhet/data/outliers/aip_chr2.txt
my_out=/data/oziolore/fhet/data/outliers/aip_chr2.vcf.bgz

$my_tabix -fh $my_vcf chr1:0-1 | $my_bgz > $my_out
xargs -a $my_list -I {} $my_tabix -f $my_vcf {} | $my_bgz >> $my_out
```

```{bash}
scp kodiak:/data/oziolore/fhet/data/outliers/aip_chr2.vcf.bgz ~/analysis/data/fst/
```

```{bash}
zcat ~/analysis/data/fst/aip_chr2.vcf.bgz | ~/analysis/scripts/haplo/haploidize_gran_mine.r | gzip > ~/analysis/data/fst/aip_chr2_haplo.vcf.gz
```

```{r}
#install.packages("Rphylip")
library(viridis)
library(dplyr)
library(magrittr)
library(Rphylip)
library(ape)
library(stringr)
vcf<-read.table("~/analysis/data/fst/aip_chr2_haplo.vcf.gz",stringsAsFactors = FALSE) #vcf that has been filtered out to only present one allele call per site per individual
sexscore<-read.table("~/analysis/scripts/depth/sexscore",header=TRUE)
cname<-c(seq(1:9),as.character(sexscore[,1])) # colnames for the vcf
colnames(vcf)<-cname

#toss sites that happen to have more than one allele
keep<-!grepl(",",vcf[,5]) #none because of the way I've called haplotypes table to check that

gt<-as.matrix(vcf[,10:297])
class(gt)<-"numeric"

#toss individuals with greater than 90% missing data
keep<-colMeans(is.na(gt))<0.9
gt<-gt[,keep]

#population identifiers
pop<-ifelse(grepl("BB",sexscore[,1]),"BB",
            ifelse(grepl("VB",sexscore[,1]),"VB",
                   ifelse(grepl("PB",sexscore[,1]),"PB",
                          ifelse(grepl("SJ",sexscore[,1]),"SJ",
                                 ifelse(grepl("BNP",sexscore[,1]),"BNP",
                                        ifelse(grepl("SP",sexscore[,1]),"SP",
                                               ifelse(grepl("GB",sexscore[,1]),"GB","WRONG")))))))
popcol<-ifelse(grepl("BB",sexscore[,1]),"black",
            ifelse(grepl("VB",sexscore[,1]),"black",
                   ifelse(grepl("PB",sexscore[,1]),"black",
                          ifelse(grepl("SJ",sexscore[,1]),"firebrick2",
                                 ifelse(grepl("BNP",sexscore[,1]),"firebrick2",
                                        ifelse(grepl("SP",sexscore[,1]),"cadetblue3",
                                               ifelse(grepl("GB",sexscore[,1]),"cadetblue3","WRONG")))))))
popfill<-ifelse(grepl("BB",sexscore[,1]),"black",
               ifelse(grepl("VB",sexscore[,1]),"grey40",
                      ifelse(grepl("PB",sexscore[,1]),"grey80",
                             ifelse(grepl("SJ",sexscore[,1]),"red",
                                    ifelse(grepl("BNP",sexscore[,1]),"lightpink",
                                           ifelse(grepl("SP",sexscore[,1]),"cadetblue3",
                                                  ifelse(grepl("GB",sexscore[,1]),"cadetblue1","WRONG")))))))

pop2<-pop[keep]
popcol2<-popcol[keep]
popfill2<-popfill[keep]

popname<-c("BB","VB","PB","SJ","BNP","SP","GB")
popnamec<-c("black","black","black","firebrick1","firebrick1","cadetblue3","cadetblue3")
#distance matrix and nj tree
d <- t(gt) %>% dist()
#dd<-as.dist(ultrametric(d)) #imputing data for missing values using ultrametric procedure
mds <- cmdscale(d)
tr <- nj(d)

#plotting tree
jpeg(filename="~/backup/UCD/Projects/Adaptation + Introgression/draft/images/aip_chr2_NJ.jpg",width=400,height=1000)
plot(tr,"unrooted",show.tip.label=FALSE)
tiplabels(pch=21,col=popcol2,bg=popfill2,cex=1.2)
legend("topright",pch=20,cex=1.2,legend=popname,col=popnamec)
dev.off()

#plotting mds
jpeg(filename="~/backup/UCD/Projects/Adaptation + Introgression/draft/images/aip_chr2_MDS.jpg",width=1000,height=600)
par(mfrow=c(1,1),mar=c(3,3,0,0))
plot(mds,col=popcol2,cex=2,cex.axis=2,pch=21,
     bg=popfill2,bty='l')
box(bty='l',lwd=5)
dev.off()

#Plotting both
par(mfrow=c(1,2))
plot(tr,"unrooted",show.tip.label=FALSE)
tiplabels(pch=20,col=popcol2,bg="white",cex=1.2)
plot(mds,pch=20,col=popcol2)
legend("topleft",pch=20,cex=.8,legend=popname,col=popnamec,y.intersp=.7)

```

###AQP chr 24
```{r}
#plotting AQP3

pbsc24<-pbsc %>% filter(str_detect(Scaf,"\\bchr24\\b"))

par(mfrow=c(5,1),mar=c(3,3,0,0),mgp=c(1,1,0))

for(i in 1:5){
  plot(subsmooth(pbsc24[22000:26000,i+3]),pch=20,cex=.5,ylim=c(0,.5),bty='l',cex.axis=2,ylab='',xlab='')
  box(bty='l',lwd=3)
  abline(v=c(159,162),col="red",lty=2,lwd=1.5)
}

```    


```{bash}
#!/bin/bash

#PBS -l nodes=1:ppn=8
#PBS -l walltime=01:00:00

#programs & files
my_tabix=/data/oziolore/program/htslib/tabix
my_bgz=/data/oziolore/program/htslib/bgzip

my_vcf=/data/oziolore/fhet/data/varcall/filtered_chr.vcf.bgz
my_list=/data/oziolore/fhet/data/outliers/aqp3_chr24.txt
my_out=/data/oziolore/fhet/data/outliers/aqp3_chr24.vcf.bgz

$my_tabix -fh $my_vcf chr1:0-1 | $my_bgz > $my_out
xargs -a $my_list -I {} $my_tabix -f $my_vcf {} | $my_bgz >> $my_out
```

```{bash}
scp kodiak:/data/oziolore/fhet/data/outliers/aqp3_chr24.vcf.bgz ~/analysis/data/fst/
```

```{bash{}
zcat ~/analysis/data/fst/aqp3_chr24.vcf.bgz | ~/analysis/scripts/haplo/haploidize_gran_mine.r | gzip > ~/analysis/data/fst/aqp3_chr24_haplo.vcf.gz
```

```{r}
#install.packages("Rphylip")
library(viridis)
library(dplyr)
library(magrittr)
library(Rphylip)
library(ape)
library(stringr)
vcf<-read.table("~/analysis/data/fst/aqp3_chr24_haplo.vcf.gz",stringsAsFactors = FALSE) #vcf that has been filtered out to only present one allele call per site per individual
sexscore<-read.table("~/analysis/scripts/depth/sexscore",header=TRUE)
cname<-c(seq(1:9),as.character(sexscore[,1])) # colnames for the vcf
colnames(vcf)<-cname

#toss sites that happen to have more than one allele
keep<-!grepl(",",vcf[,5]) #none because of the way I've called haplotypes table to check that

gt<-as.matrix(vcf[,10:297])
class(gt)<-"numeric"

#toss individuals with greater than 90% missing data
keep<-colMeans(is.na(gt))<0.9
gt<-gt[,keep]

#population identifiers
pop<-ifelse(grepl("BB",sexscore[,1]),"BB",
            ifelse(grepl("VB",sexscore[,1]),"VB",
                   ifelse(grepl("PB",sexscore[,1]),"PB",
                          ifelse(grepl("SJ",sexscore[,1]),"SJ",
                                 ifelse(grepl("BNP",sexscore[,1]),"BNP",
                                        ifelse(grepl("SP",sexscore[,1]),"SP",
                                               ifelse(grepl("GB",sexscore[,1]),"GB","WRONG")))))))
popcol<-ifelse(grepl("BB",sexscore[,1]),"black",
            ifelse(grepl("VB",sexscore[,1]),"black",
                   ifelse(grepl("PB",sexscore[,1]),"black",
                          ifelse(grepl("SJ",sexscore[,1]),"firebrick2",
                                 ifelse(grepl("BNP",sexscore[,1]),"firebrick2",
                                        ifelse(grepl("SP",sexscore[,1]),"cadetblue3",
                                               ifelse(grepl("GB",sexscore[,1]),"cadetblue3","WRONG")))))))
popfill<-ifelse(grepl("BB",sexscore[,1]),"black",
               ifelse(grepl("VB",sexscore[,1]),"grey40",
                      ifelse(grepl("PB",sexscore[,1]),"grey80",
                             ifelse(grepl("SJ",sexscore[,1]),"red",
                                    ifelse(grepl("BNP",sexscore[,1]),"lightpink",
                                           ifelse(grepl("SP",sexscore[,1]),"cadetblue3",
                                                  ifelse(grepl("GB",sexscore[,1]),"cadetblue1","WRONG")))))))

pop2<-pop[keep]
popcol2<-popcol[keep]
popfill2<-popfill[keep]

popname<-c("BB","VB","PB","SJ","BNP","SP","GB")
popnamec<-c("black","black","black","firebrick1","firebrick1","cadetblue3","cadetblue3")
#distance matrix and nj tree
d <- t(gt) %>% dist()
#dd<-as.dist(ultrametric(d)) #imputing data for missing values using ultrametric procedure
mds <- cmdscale(d)
tr <- nj(d)

#plotting tree
plot(tr,"unrooted",show.tip.label=FALSE)
tiplabels(pch=20,col=popcol2,bg="white",cex=1.2)
legend("topright",pch=20,cex=1.2,legend=popname,col=popnamec)

#plotting mds
par(mfrow=c(1,1),mar=c(3,3,0,0))
plot(mds,col=popcol2,cex=2,cex.axis=2,pch=21,
     bg=popfill2,bty='l')
box(bty='l',lwd=5)

legend("topright",legend=c("BB","VB","PB","SJ","BNP","SP","GB"),col=c("black","black","black","firebrick1","firebrick1","cadetblue3","cadetblue3"),
       pch=21,cex=2,y.intersp=.5,bty='n',bg=c("black","grey40","grey80","firebrick1","lightpink","cadetblue1","cadetblue3"))

#Plotting both
par(mfrow=c(1,2))
plot(tr,"unrooted",show.tip.label=FALSE)
tiplabels(pch=20,col=popcol2,bg="white",cex=1.2)
plot(mds,pch=20,col=popcol2)
legend("topleft",pch=20,cex=.8,legend=popname,col=popnamec,y.intersp=.7)

```

## Looking at MDS of haplotypes

### Formatting outlier lists
* removing regions of introgression from considered regions (Chr 1 and 10) and converting to tabix readable format

```{bash}
cat ~/fgfh_post/data/fst/pbs_regions_sharedall.bed | grep -v -w "chr1" | grep -v "chr10" |\
awk '{OFS=""}{b=":"}{s="-"}{print $1,b,$2,s,$3}' > ~/fgfh_post/data/fst/hudson_out_all.txt

#will use the one with introgressed regions for expectations
cat ~/fgfh_post/data/fst/pbs_regions_sharedall.bed | \
awk '{OFS=""}{b=":"}{s="-"}{print $1,b,$2,s,$3}' > ~/fgfh_post/data/fst/hudson_out_all_intr.txt

cat ~/fgfh_post/data/fst/pbs_regions_sharedres.bed | grep -v -w "chr1" | grep -v "chr10" |\
awk '{OFS=""}{b=":"}{s="-"}{print $1,b,$2,s,$3}' > ~/fgfh_post/data/fst/hudson_out_res.txt

cat ~/fgfh_post/data/fst/pbs_regions_sharedinterm.bed | grep -v -w "chr1" | grep -v "chr10" |\
awk '{OFS=""}{b=":"}{s="-"}{print $1,b,$2,s,$3}' > ~/fgfh_post/data/fst/hudson_out_interm.txt

```

### Creating VCF of those regions
* Then I grab all those regions from the vcf file in order to haploidize the genotype likelihoods

```{bash}
#shared sites

#!/bin/bash

#PBS -l nodes=1:ppn=8
#PBS -l walltime=01:00:00

#programs & files
my_tabix=/data/oziolore/program/htslib/tabix
my_bgz=/data/oziolore/program/htslib/bgzip

my_vcf=/data/oziolore/fhet/data/varcall/filtered_chr.vcf.bgz
my_list=/data/oziolore/fhet/data/outliers/hudson_out_all.txt
my_out=/data/oziolore/fhet/data/outliers/hudson_out_all.vcf.bgz

$my_tabix -fh $my_vcf chr1:0-1 | $my_bgz > $my_out
xargs -a $my_list -I {} $my_tabix -f $my_vcf {} | $my_bgz >> $my_out

#shared with introgressed
#!/bin/bash

#PBS -l nodes=1:ppn=8
#PBS -l walltime=01:00:00

#programs & files
my_tabix=/data/oziolore/program/htslib/tabix
my_bgz=/data/oziolore/program/htslib/bgzip

my_vcf=/data/oziolore/fhet/data/varcall/filtered_chr.vcf.bgz
my_list=/data/oziolore/fhet/data/outliers/hudson_out_all_intr.txt
my_out=/data/oziolore/fhet/data/outliers/hudson_out_all_intr.vcf.bgz

$my_tabix -fh $my_vcf chr1:0-1 | $my_bgz > $my_out
xargs -a $my_list -I {} $my_tabix -f $my_vcf {} | $my_bgz >> $my_out

#resistant only
#!/bin/bash

#PBS -l nodes=1:ppn=8
#PBS -l walltime=01:00:00

#programs & files
my_tabix=/data/oziolore/program/htslib/tabix
my_bgz=/data/oziolore/program/htslib/bgzip

my_vcf=/data/oziolore/fhet/data/varcall/filtered_chr.vcf.bgz
my_list=/data/oziolore/fhet/data/outliers/hudson_out_res.txt
my_out=/data/oziolore/fhet/data/outliers/hudson_out_res.vcf.bgz

$my_tabix -fh $my_vcf chr1:0-1 | $my_bgz > $my_out
xargs -a $my_list -I {} $my_tabix -f $my_vcf {} | $my_bgz >> $my_out

#intermediate only
#!/bin/bash

#PBS -l nodes=1:ppn=8
#PBS -l walltime=01:00:00

#programs & files
my_tabix=/data/oziolore/program/htslib/tabix
my_bgz=/data/oziolore/program/htslib/bgzip

my_vcf=/data/oziolore/fhet/data/varcall/filtered_chr.vcf.bgz
my_list=/data/oziolore/fhet/data/outliers/hudson_out_interm.txt
my_out=/data/oziolore/fhet/data/outliers/hudson_out_interm.vcf.bgz

$my_tabix -fh $my_vcf chr1:0-1 | $my_bgz > $my_out
xargs -a $my_list -I {} $my_tabix -f $my_vcf {} | $my_bgz >> $my_out

#downloading to personal computer

scp kodiak:/data/oziolore/fhet/data/outliers/hudson*.vcf.bgz /home/elias/analysis/data/fst/

```

### Haploidizing function
* I used a script (based on Noah Reid's script) that haploidizes genotypes based of low coverage data and just pass each file through them. Script below is called haploidize_gran_mine.r

```{r}
#!/usr/bin/env Rscript

library(stringr)
library(magrittr)

sam<-function(x){
      y <- str_split(x,":")[[1]][1] %>% 
    			 str_split(.,"\\/") %>% 
    			 unlist() %>% 
    			 as.numeric() # pull genotypes
      if(is.na(y)){
        return(".")
      } else {
          z<-str_split(x,":")[[1]][3] %>% 
             str_split(.,",") %>% 
             unlist() %>% 
             as.numeric() # pull allele coverage
          if(y[1]==y[2]){
            h<-y[1]
          } else {
            if(z[1]>z[2]){
              h<-y[1]
            } else {
              h<-sample(y,size=1)
            }
          }
        return(h)
      }
}

f <- file("stdin")
#f<-file("~/analysis/data/dfst/outliers/zshared.vcf.bgz")
open(f)
while(length(line <- readLines(f,n=1)) > 0) {
  if(grepl("^#",line)){write(line,stdout());next()}

  line <- str_split(line,"\\t") %>% unlist()
  line[10:297] <- sapply(line[10:297],sam)
  line <- paste(line,collapse="\t")
  write(line,stdout())
  # write(line, stderr())
  # process line
}
```

### Haploidizing all of those regions
* using bash to haploidize each vcf file

```{bash}
zcat < ~/fgfh_post/data/fst/hudson_out_all.vcf.bgz | ~/fgfh_post/scripts/haplo/haploidize_gran_mine.r | gzip > ~/fgfh_post/data/fst/hudson_out_all_haplo.vcf.bgz

zcat < ~/fgfh_post/data/fst/hudson_out_res.vcf.bgz | ~/fgfh_post/scripts/haplo/haploidize_gran_mine.r | gzip > ~/fgfh_post/data/fst/hudson_out_res_haplo.vcf.bgz

zcat < ~/fgfh_post/data/fst/hudson_out_interm.vcf.bgz | ~/fgfh_post/scripts/haplo/haploidize_gran_mine.r | gzip > ~/fgfh_post/data/fst/hudson_out_interm_haplo.vcf.bgz

zcat < ~/fgfh_post/data/fst/hudson_out_all_intr.vcf.bgz | ~/fgfh_post/scripts/haplo/haploidize_gran_mine.r | gzip > ~/fgfh_post/data/fst/hudson_out_all_intr_haplo.vcf.bgz
```

## Plotting haplotypes
  + starting with resistant only haplotypes (because they finished first)
```{r}
#install.packages("Rphylip")
library(viridis)
library(dplyr)
library(magrittr)
library(Rphylip)
library(ape)
library(stringr)
vcf<-read.table("~/analysis/data/fst/hudson_out_res_haplo.vcf.bgz",stringsAsFactors = FALSE) #vcf that has been filtered out to only present one allele call per site per individual
sexscore<-read.table("~/analysis/scripts/depth/sexscore",header=TRUE)
cname<-c(seq(1:9),as.character(sexscore[,1])) # colnames for the vcf
colnames(vcf)<-cname

#toss sites that happen to have more than one allele
keep<-!grepl(",",vcf[,5]) #none because of the way I've called haplotypes table to check that

gt<-as.matrix(vcf[,10:297])
class(gt)<-"numeric"

#toss individuals with greater than 90% missing data
keep<-colMeans(is.na(gt))<0.9
gt<-gt[,keep]

#population identifiers
pop<-ifelse(grepl("BB",sexscore[,1]),"BB",
            ifelse(grepl("VB",sexscore[,1]),"VB",
                   ifelse(grepl("PB",sexscore[,1]),"PB",
                          ifelse(grepl("SJ",sexscore[,1]),"SJ",
                                 ifelse(grepl("BNP",sexscore[,1]),"BNP",
                                        ifelse(grepl("SP",sexscore[,1]),"SP",
                                               ifelse(grepl("GB",sexscore[,1]),"GB","WRONG")))))))
popcol<-ifelse(grepl("BB",sexscore[,1]),"black",
            ifelse(grepl("VB",sexscore[,1]),"black",
                   ifelse(grepl("PB",sexscore[,1]),"black",
                          ifelse(grepl("SJ",sexscore[,1]),"firebrick2",
                                 ifelse(grepl("BNP",sexscore[,1]),"firebrick2",
                                        ifelse(grepl("SP",sexscore[,1]),"cadetblue3",
                                               ifelse(grepl("GB",sexscore[,1]),"cadetblue3","WRONG")))))))
popfill<-ifelse(grepl("BB",sexscore[,1]),"black",
               ifelse(grepl("VB",sexscore[,1]),"grey40",
                      ifelse(grepl("PB",sexscore[,1]),"grey80",
                             ifelse(grepl("SJ",sexscore[,1]),"red",
                                    ifelse(grepl("BNP",sexscore[,1]),"lightpink",
                                           ifelse(grepl("SP",sexscore[,1]),"cadetblue3",
                                                  ifelse(grepl("GB",sexscore[,1]),"cadetblue1","WRONG")))))))

pop2<-pop[keep]
popcol2<-popcol[keep]
popfill2<-popfill[keep]

popname<-c("BB","VB","PB","SJ","BNP","SP","GB")
popnamec<-c("black","black","black","firebrick1","firebrick1","cadetblue3","cadetblue3")
#distance matrix and nj tree
d <- t(gt) %>% dist()
dd<-as.dist(ultrametric(d)) #imputing data for missing values using ultrametric procedure
mds <- cmdscale(dd)
tr <- nj(dd)

#plotting tree
plot(tr,"unrooted",show.tip.label=FALSE)
tiplabels(pch=20,col=popcol2,bg="white",cex=1.2)
legend("topright",pch=20,cex=1.2,legend=popname,col=popnamec)

#plotting mds
par(mfrow=c(1,1),mar=c(3,3,0,0))
plot(mds,col=popcol2,cex=2,cex.axis=2,pch=21,
     bg=popfill2,bty='l')
box(bty='l',lwd=5)

legend("topright",legend=c("BB","VB","PB","SJ","BNP","SP","GB"),col=c("black","black","black","firebrick1","firebrick1","cadetblue3","cadetblue3"),
       pch=21,cex=2,y.intersp=.5,bty='n',bg=c("black","grey40","grey80","firebrick1","lightpink","cadetblue1","cadetblue3"))

#Plotting both
par(mfrow=c(1,2))
plot(tr,"unrooted",show.tip.label=FALSE)
tiplabels(pch=20,col=popcol2,bg="white",cex=1.2)
plot(mds,pch=20,col=popcol2)
legend("topleft",pch=20,cex=.8,legend=popname,col=popnamec,y.intersp=.7)

```

* repeating with shared haplotypes

```{r}
#install.packages("Rphylip")
library(viridis)
library(dplyr)
library(magrittr)
library(Rphylip)
library(ape)
library(stringr)
vcf<-read.table("~/analysis/data/fst/hudson_out_all_haplo.vcf.bgz",stringsAsFactors = FALSE) #vcf that has been filtered out to only present one allele call per site per individual
sexscore<-read.table("~/analysis/scripts/depth/sexscore",header=TRUE)
cname<-c(seq(1:9),as.character(sexscore[,1])) # colnames for the vcf
colnames(vcf)<-cname

#toss sites that happen to have more than one allele
keep<-!grepl(",",vcf[,5]) #none because of the way I've called haplotypes table to check that

gt<-as.matrix(vcf[,10:297])
class(gt)<-"numeric"

#toss individuals with greater than 90% missing data
keep<-colMeans(is.na(gt))<0.9
gt<-gt[,keep]

#population identifiers
pop<-ifelse(grepl("BB",sexscore[,1]),"BB",
            ifelse(grepl("VB",sexscore[,1]),"VB",
                   ifelse(grepl("PB",sexscore[,1]),"PB",
                          ifelse(grepl("SJ",sexscore[,1]),"SJ",
                                 ifelse(grepl("BNP",sexscore[,1]),"BNP",
                                        ifelse(grepl("SP",sexscore[,1]),"SP",
                                               ifelse(grepl("GB",sexscore[,1]),"GB","WRONG")))))))
popcol<-ifelse(grepl("BB",sexscore[,1]),"black",
            ifelse(grepl("VB",sexscore[,1]),"black",
                   ifelse(grepl("PB",sexscore[,1]),"black",
                          ifelse(grepl("SJ",sexscore[,1]),"firebrick2",
                                 ifelse(grepl("BNP",sexscore[,1]),"firebrick2",
                                        ifelse(grepl("SP",sexscore[,1]),"cadetblue3",
                                               ifelse(grepl("GB",sexscore[,1]),"cadetblue3","WRONG")))))))
popfill<-ifelse(grepl("BB",sexscore[,1]),"black",
               ifelse(grepl("VB",sexscore[,1]),"grey40",
                      ifelse(grepl("PB",sexscore[,1]),"grey80",
                             ifelse(grepl("SJ",sexscore[,1]),"red",
                                    ifelse(grepl("BNP",sexscore[,1]),"lightpink",
                                           ifelse(grepl("SP",sexscore[,1]),"cadetblue3",
                                                  ifelse(grepl("GB",sexscore[,1]),"cadetblue1","WRONG")))))))

pop2<-pop[keep]
popcol2<-popcol[keep]
popfill2<-popfill[keep]

popname<-c("BB","VB","PB","SJ","BNP","SP","GB")
popnamec<-c("black","black","black","firebrick1","firebrick1","cadetblue3","cadetblue3")
#distance matrix and nj tree
d <- t(gt) %>% dist()
#dd<-as.dist(ultrametric(d)) #imputing data for missing values using ultrametric procedure
#do not need to impute here because there are no missing values
mds <- cmdscale(d)
tr <- nj(d)

#plotting tree
plot(tr,"unrooted",show.tip.label=FALSE)
tiplabels(pch=20,col=popcol2,bg="white",cex=1.2)
legend("topright",pch=20,cex=1.2,legend=popname,col=popnamec)

#plotting mds
jpeg(filename="~/backup/UCD/Projects/Adaptation + Introgression/draft/images/pbs_sharedout.jpg",width=1000,height=400)
par(mfrow=c(1,1),mar=c(3,3,0,0))
plot(mds,col=popcol2,cex=2,cex.axis=2,pch=21,
     bg=popfill2,bty='l')
box(bty='l',lwd=5)
dev.off()
#legend("topright",legend=c("BB","VB","PB","SJ","BNP","SP","GB"),col=c("black","black","black","firebrick1","firebrick1","cadetblue3","cadetblue3"),pch=21,cex=2,y.intersp=.5,bty='n',bg=c("black","grey40","grey80","firebrick1","lightpink","cadetblue1","cadetblue3"))

#Plotting both
par(mfrow=c(1,2))
plot(tr,"unrooted",show.tip.label=FALSE)
tiplabels(pch=20,col=popcol2,bg="white",cex=1.2)
plot(mds,pch=20,col=popcol2)
legend("topleft",pch=20,cex=.8,legend=popname,col=popnamec,y.intersp=.7)

```

* finally intermediate haplotypes

```{r}
#install.packages("Rphylip")
library(viridis)
library(dplyr)
library(magrittr)
library(Rphylip)
library(ape)
library(stringr)
vcf<-read.table("~/fgfh_post/data/fst/hudson_out_interm_haplo.vcf.bgz",stringsAsFactors = FALSE) #vcf that has been filtered out to only present one allele call per site per individual
sexscore<-read.table("~/fgfh_post/scripts/depth/sexscore",header=TRUE)
cname<-c(seq(1:9),as.character(sexscore[,1])) # colnames for the vcf
colnames(vcf)<-cname

#toss sites that happen to have more than one allele
keep<-!grepl(",",vcf[,5]) #none because of the way I've called haplotypes table to check that

gt<-as.matrix(vcf[,10:297])
class(gt)<-"numeric"

#toss individuals with greater than 90% missing data
keep<-colMeans(is.na(gt))<0.9
gt<-gt[,keep]

#population identifiers
pop<-ifelse(grepl("BB",sexscore[,1]),"BB",
            ifelse(grepl("VB",sexscore[,1]),"VB",
                   ifelse(grepl("PB",sexscore[,1]),"PB",
                          ifelse(grepl("SJ",sexscore[,1]),"SJ",
                                 ifelse(grepl("BNP",sexscore[,1]),"BNP",
                                        ifelse(grepl("SP",sexscore[,1]),"SP",
                                               ifelse(grepl("GB",sexscore[,1]),"GB","WRONG")))))))
popcol<-ifelse(grepl("BB",sexscore[,1]),"black",
            ifelse(grepl("VB",sexscore[,1]),"black",
                   ifelse(grepl("PB",sexscore[,1]),"black",
                          ifelse(grepl("SJ",sexscore[,1]),"firebrick2",
                                 ifelse(grepl("BNP",sexscore[,1]),"firebrick2",
                                        ifelse(grepl("SP",sexscore[,1]),"cadetblue3",
                                               ifelse(grepl("GB",sexscore[,1]),"cadetblue3","WRONG")))))))
popfill<-ifelse(grepl("BB",sexscore[,1]),"black",
               ifelse(grepl("VB",sexscore[,1]),"grey40",
                      ifelse(grepl("PB",sexscore[,1]),"grey80",
                             ifelse(grepl("SJ",sexscore[,1]),"red",
                                    ifelse(grepl("BNP",sexscore[,1]),"lightpink",
                                           ifelse(grepl("SP",sexscore[,1]),"cadetblue3",
                                                  ifelse(grepl("GB",sexscore[,1]),"cadetblue1","WRONG")))))))

pop2<-pop[keep]
popcol2<-popcol[keep]
popfill2<-popfill[keep]

popname<-c("BB","VB","PB","SJ","BNP","SP","GB")
popnamec<-c("black","black","black","firebrick1","firebrick1","cadetblue3","cadetblue3")
#distance matrix and nj tree
d <- t(gt) %>% dist()
#dd<-as.dist(ultrametric(d)) #imputing data for missing values using ultrametric procedure
#do not need to impute here because there are no missing values
mds <- cmdscale(d)
tr <- nj(d)

#plotting tree
plot(tr,"unrooted",show.tip.label=FALSE)
tiplabels(pch=20,col=popcol2,bg="white",cex=1.2)
legend("topright",pch=20,cex=1.2,legend=popname,col=popnamec)

#plotting mds
jpeg(filename="~/Documents/UCD/Projects/Adaptation + Introgression/draft/images/pbs_intermout.jpg",width=1000,height=400)
par(mfrow=c(1,1),mar=c(3,3,0,0))
plot(mds,col=popcol2,cex=2,cex.axis=2,pch=21,
     bg=popfill2,bty='l')
box(bty='l',lwd=5)
dev.off()

#legend("topright",legend=c("BB","VB","PB","SJ","BNP","SP","GB"),col=c("black","black","black","firebrick1","firebrick1","cadetblue3","cadetblue3"),pch=21,cex=2,y.intersp=.5,bty='n',bg=c("black","grey40","grey80","firebrick1","lightpink","cadetblue1","cadetblue3"))

#Plotting both
par(mfrow=c(1,2))
plot(tr,"unrooted",show.tip.label=FALSE)
tiplabels(pch=20,col=popcol2,bg="white",cex=1.2)
plot(mds,pch=20,col=popcol2)
legend("topleft",pch=20,cex=.8,legend=popname,col=popnamec,y.intersp=.7)

```

# Admixture 
##Running admixture on the data

```{bash}
#starting by converting vcf to bed file through plink
#!/bin/bash

#PBS -l nodes=1:ppn=8
#PBS -l walltime=02:00:00

#programs and files
my_plink=/data/oziolore/program/plink/plink
my_vcf=/data/oziolore/fhet/data/varcall/filtered_chr.vcf.bgz
my_tabix=/data/oziolore/program/htslib/tabix
my_out=/data/oziolore/fhet/data/admixture/allscaf/allscaf

$my_plink \
-vcf $my_vcf \
--allow-extra-chr \
--make-bed \
-out $my_out

#continue by removing NW from file because it messes up with total number of chromosomes allowed
#!/bin/bash

#PBS -l nodes=1:ppn=8
#PBS -l walltime=01:00:00

#files
start_bim=/data/oziolore/fhet/data/admixture/allscaf/allscaf.bim
end_bim=/data/oziolore/fhet/data/admixture/allscaf/allscaf2.bim

cat $start_bim | awk '{gsub("NW_","");print}' > $end_bim

#running admixture for k 1-7 because we sampled 7 total populations
#!/bin/bash

#PBS -l nodes=1:ppn=16
#PBS -J 1-7
#PBS -l walltime=48:00:00

#programs
admix=/data/oziolore/program/admixture/admixture
allscaf=/data/oziolore/fhet/data/admixture/allscaf/allscaf.bed
out=/data/oziolore/fhet/data/admixture/allscaf

$admix --cv -j16 $allscaf $PBS_ARRAY_INDEX | tee $out/log${PBS_ARRAY_INDEX}.out

```

###Plotting admixture proportions

```{r}
ord_temp<-read.table("~/analysis/data/admixture/seqlist.txt",header=FALSE)
ord<-unlist(ord_temp)

k2<-read.table("~/analysis/data/admixture/all/allscaf.2.Q")
k2ord<-k2[ord,]
barplot(t(as.matrix(k2ord)),col=c("deepskyblue2","black"), ylab="Ancestry",border=NA, xaxt="n",space=0,
        cex.lab=1.5,cex.axis=1.5)

abline(b=0,v=c(0,48,96,144,168,215,264,288),col="grey",lwd=3,lty=5)
abline(a=0,b=0,col="black",lwd=3)

ax<-c(24,72,124,156,192,240,276)
axnames<-c("SP","GB","BNP", "SJ","PB","VB","BB")
axis(side=1,at= ax, labels = axnames,tck=-.03)

gb<-k2ord[0:48,]
gbord<-order(gb[,2],decreasing=TRUE)

sp<-k2ord[49:96,]
spord<-order(sp[,2],decreasing=TRUE)

bnp<-k2ord[97:144,]
bnpord<-order(bnp[,2],decreasing=TRUE)

sj<-k2ord[145:168,]
sjord<-order(sj[,2],decreasing=TRUE)

pb<-k2ord[168:215,]
pbord<-order(pb[,2],decreasing=TRUE)

vb<-k2ord[215:264,]
vbord<-order(vb[,2],decreasing=TRUE)

bb<-k2ord[265:288,]
bbord<-order(bb[,2],decreasing=TRUE)

kall<-rbind(bb[bbord,],vb[vbord,],pb[pbord,],sj[sjord,],bnp[bnpord,],gb[gbord,],sp[spord,])

kall<-na.omit(kall)

par(mfrow=c(1,1),mar=c(3,3,1,1))
barplot(t(as.matrix(kall)),col=c("cadetblue2","black"), border=NA, xaxt="n",space=0,
        cex.lab=2,cex.axis=1.9)

ax<-c(12,48,96,132,168,216,264)
ax2<-c(0,121,122,193,194,288)
vert<-c(24,74,122,146,194,242)
axnames<-c("BB","VB","PB", "SJ","BNP","SP","GB")
axcol<-c("black","firebrick2","cadetblue3")
axis(side=1,at= ax[1:3], labels = axnames[1:3],tck=-.02,lwd=0,
     col.axis=axcol[1],col=axcol[1],cex.axis=1.6)
axis(side=1,at= ax[4:5], labels = axnames[4:5],tck=-.02,lwd=0,
     col.axis=axcol[2],col=axcol[2],cex.axis=1.6)
axis(side=1,at= ax[6:7], labels = axnames[6:7],tck=-.02,lwd=0,
     col.axis=axcol[3],col=axcol[3],cex.axis=1.6)
#Just the lines
axis(side=1,at= ax2[1:2], labels=c("",""), tck=0,lwd=4,
     col.axis=axcol[1],col=axcol[1],cex.axis=1.4)
axis(side=1,at= ax2[3:4], labels = c("",""),tck=0,lwd=4,
     col.axis=axcol[2],col=axcol[2],cex.axis=1.4)
axis(side=1,at= ax2[5:6], labels = c("",""),tck=-0,lwd=4,
     col.axis=axcol[3],col=axcol[3],cex.axis=1.4)
abline(v=vert,col="khaki2",lty=1,lwd=2.5)

########################################################
k3<-read.table("~/analysis/data/admixture/all/allscaf.3.Q")
k3ord<-k3[ord,]
barplot(t(as.matrix(k3ord)),col=c("black","deepskyblue2","red"), ylab="Ancestry",border=NA, xaxt="n",space=0)

abline(b=0,v=c(0,48,96,144,168,215,264,288),col="grey",lwd=3,lty=5)

ax<-c(24,72,124,156,192,240,276)
axnames<-c("SP","GB","BNP", "SJ","PB","VB","BB")
axis(side=1,at= ax, labels = axnames,tck=-.03)

##########################################################
k4<-read.table("~/analysis/data/admixture/all/allscaf.4.Q")
k4ord<-k4[ord,]

gb<-k4ord[0:48,]
gbord<-order(gb[,2],decreasing=TRUE)

sp<-k4ord[49:96,]
spord<-order(sp[,2],decreasing=TRUE)

bnp<-k4ord[97:144,]
bnpord<-order(bnp[,3],decreasing=TRUE)

sj<-k4ord[145:168,]
sjord<-order(sj[,3],decreasing=TRUE)

pb<-k4ord[168:215,]
pbord<-order(pb[,3],decreasing=TRUE)

vb<-k4ord[215:264,]
vbord<-order(vb[,3],decreasing=TRUE)

bb<-k4ord[265:288,]
bbord<-order(bb[,3],decreasing=TRUE)

kall<-rbind(bb[bbord,],vb[vbord,],pb[pbord,],sj[sjord,],bnp[bnpord,],gb[gbord,],sp[spord,])

kall<-na.omit(kall)
barplot(t(as.matrix(kall)),col=c("red","deepskyblue2","black","darkorange"), ylab="Ancestry",border=NA, xaxt="n",space=0,
        cex.lab=1.5,cex.axis = 1.5)

ax<-c(12,48,96,132,168,216,264)
ax2<-c(0,121,122,193,194,288)
vert<-c(24,74,122,146,194,242)
axnames<-c("BB","VB","PB", "SJ","BNP","SP","GB")
axcol<-c("black","firebrick2","cadetblue3")
axis(side=1,at= ax[1:3], labels = axnames[1:3],tck=-.02,lwd=0,
     col.axis=axcol[1],col=axcol[1],cex.axis=1.6)
axis(side=1,at= ax[4:5], labels = axnames[4:5],tck=-.02,lwd=0,
     col.axis=axcol[2],col=axcol[2],cex.axis=1.6)
axis(side=1,at= ax[6:7], labels = axnames[6:7],tck=-.02,lwd=0,
     col.axis=axcol[3],col=axcol[3],cex.axis=1.6)
#Just the lines
axis(side=1,at= ax2[1:2], labels=c("",""), tck=0,lwd=4,
     col.axis=axcol[1],col=axcol[1],cex.axis=1.4)
axis(side=1,at= ax2[3:4], labels = c("",""),tck=0,lwd=4,
     col.axis=axcol[2],col=axcol[2],cex.axis=1.4)
axis(side=1,at= ax2[5:6], labels = c("",""),tck=-0,lwd=4,
     col.axis=axcol[3],col=axcol[3],cex.axis=1.4)
abline(v=vert,col="khaki2",lty=1,lwd=2.5)
```

## NGSadmix
* Decided to run NGS admix to figure out proportion that came from BB and GB (most fst divergent populations)

```{bash}
#start by creating a reference panel for ngs admix (two most highly divergent fst pops)
#!/bin/bash

#PBS -l nodes=1:ppn=8
#PBS -l walltime=00:30:00

#programs and files
my_plink=/data/oziolore/program/plink/plink
my_vcf=/data/oziolore/fhet/data/varcall/filtered_chr.vcf.bgz
my_tabix=/data/oziolore/program/htslib/tabix
my_out=/data/oziolore/fhet/data/fastngs/reference_panel_all
my_keep=/data/oziolore/fhet/data/list2/fastngs_reference_all.txt

$my_plink \
-vcf $my_vcf \
--allow-extra-chr \
--keep $my_keep \
--make-bed \
--chr 1-24 \
-out $my_out

#run admixture on the reference panel of 2 populations

#!/bin/bash

#PBS -l nodes=1:ppn=16
#PBS -l walltime=05:00:00

my_admix=/data/oziolore/program/admixture/admixture
my_ref=/data/oziolore/fhet/data/fastngs/reference_panel.bed
my_out=/data/oziolore/fhet/data/fastngs

$my_admix --cv -j16 $my_ref 2 | tee $my_out/log2

#create the panel by re-modeling the output of admixture

echo "id chr pos name A0_freq A1 K1 K2" > refPanel_BBGB.2.P.txt
 paste -d" " <( awk -F " " ' { print $1"_"$4, $1, $4, $2, $6, $5 } ' /data/oziolore/fhet/data/fastngs/reference_panel.bim ) reference_panel.2.P >> refPanel_BBGB.2.P.txt
 echo "K1 K2" > nInd_BBGB.2.Q.txt
 paste -d" " <(cut -f1 -d" " /data/oziolore/fhet/data/fastngs/reference_panel.2.Q | paste -sd+ | bc) <(cut -f2 -d" " /data/oziolore/fhet/data/fastngs/reference_panel.2.Q | paste -sd+ | bc) >> nInd_BBGB.2.Q.txt

#create a beagle file for ngsadmix to use

#!/bin/bash

#PBS -l nodes=1:ppn=1
#PBS -l walltime=24:00:00
#PBS -J 1-288

list=/data/oziolore/fhet/data/list2/pop_files.txt
f=$(echo $PBS_ARRAY_INDEX)
ind=$(cat $list | sed "${f}q;d")
name=$(cat $list | sed "${f}q;d" | grep -o "BU.*")
sites=/data/oziolore/fhet/data/fastngs/refPanel_BBGB.sites
my_angsd=/data/oziolore/program/angsd/angsd
my_out=/data/oziolore/fhet/data/fastngs/beagle_big/$name\

$my_angsd \
-i $ind \
-GL 2 \
-sites $sites \
-doGlf 2 \
-doMajorMinor 3 \
-minMapQ 30 \
-minQ 20 \
-doDepth 1 \
-doCounts 1 \
-out $my_out

#Run fastngsadmix with the reference panel on the populations you want to know the proportions of admixture
#!/bin/bash

#PBS -l nodes=1:ppn=1
#PBS -l walltime=24:00:00
#PBS -J 1-288

list=/data/oziolore/fhet/data/list2/pop_files.txt
f=$(echo $PBS_ARRAY_INDEX)
name=$(cat $list | sed "${f}q;d" | grep -o "BU.*")
my_fastngs=/data/oziolore/program/fastNGSadmix/fastNGSadmix
my_GL=/data/oziolore/fhet/data/fastngs/beagle_big/$name\.beagle\.gz
my_out=/data/oziolore/fhet/data/fastngs/probs_big/$name
ref=/data/oziolore/fhet/data/fastngs/refPanel_BBGB_big_new.2.P.txt
numb=/data/oziolore/fhet/data/fastngs/nInd_BBGB_big.2.Q.txt

$my_fastngs \
-likes $my_GL \
-fname $ref \
-Nname $numb \
-whichPops all \
-seed 1 \
-boot 100 \
-out $my_out

#combine probabilities from all files
for i in {004..464}; do cat BU000$i*.qopt | head -n2 | grep -v "K1" >> combined_probs.txt

```

### Plotting NGSadmix
* take this out into r and plot the probabilities

```{r}
ord_temp<-read.table("~/analysis/data/fastngs/order.txt",header=FALSE)
ord<-unlist(ord_temp)

k2<-read.table("~/analysis/data/fastngs/combined_probs.txt")
k2ord<-k2[ord,]
barplot(t(as.matrix(k2ord)),col=c("deepskyblue2","black"), ylab="Ancestry",border=NA, xaxt="n",space=0,
        cex.lab=1.5,cex.axis=1.5)

abline(b=0,v=c(0,48,96,144,168,215,264,288),col="grey",lwd=3,lty=5)
abline(a=0,b=0,col="black",lwd=3)

ax<-c(24,72,124,156,192,240,276)
axnames<-c("GB","SP","BNP", "SJ","PB","VB","BB")
axis(side=1,at= ax, labels = axnames,tck=-.03)

gb<-k2ord[1:48,]
gbord<-order(gb[,2],decreasing=TRUE)

sp<-k2ord[49:96,]
spord<-order(sp[,2],decreasing=TRUE)

bnp<-k2ord[97:144,]
bnpord<-order(bnp[,2],decreasing=TRUE)

sj<-k2ord[145:168,]
sjord<-order(sj[,2],decreasing=TRUE)

pb<-k2ord[169:215,]
pbord<-order(pb[,2],decreasing=TRUE)

vb<-k2ord[216:264,]
vbord<-order(vb[,2],decreasing=TRUE)

bb<-k2ord[265:288,]
bbord<-order(bb[,2],decreasing=TRUE)

kall<-rbind(bb[bbord,],vb[vbord,],pb[pbord,],sj[sjord,],bnp[bnpord,],sp[spord,],gb[gbord,])

kall<-na.omit(kall)

par(mfrow=c(1,1),mar=c(3,3,1,1))
barplot(t(as.matrix(kall)),col=c("cadetblue2","black"), border=NA, xaxt="n",space=0,
        cex.lab=2,cex.axis=1.9)

ax<-c(12,48,96,132,168,216,264)
ax2<-c(0,120,121,192,193,288)
vert<-c(24,73,120,143,191,239)
axnames<-c("BB","VB","PB", "SJ","BNP","SP","GB")
axcol<-c("black","firebrick2","cadetblue3")
axis(side=1,at= ax[1:3], labels = axnames[1:3],tck=-.02,lwd=0,
     col.axis=axcol[1],col=axcol[1],cex.axis=1.6)
axis(side=1,at= ax[4:5], labels = axnames[4:5],tck=-.02,lwd=0,
     col.axis=axcol[2],col=axcol[2],cex.axis=1.6)
axis(side=1,at= ax[6:7], labels = axnames[6:7],tck=-.02,lwd=0,
     col.axis=axcol[3],col=axcol[3],cex.axis=1.6)
#Just the lines
axis(side=1,at= ax2[1:2], labels=c("",""), tck=0,lwd=4,
     col.axis=axcol[1],col=axcol[1],cex.axis=1.4)
axis(side=1,at= ax2[3:4], labels = c("",""),tck=0,lwd=4,
     col.axis=axcol[2],col=axcol[2],cex.axis=1.4)
axis(side=1,at= ax2[5:6], labels = c("",""),tck=-0,lwd=4,
     col.axis=axcol[3],col=axcol[3],cex.axis=1.4)
abline(v=vert,col="khaki2",lty=1,lwd=2.5)

###histograms and densities

gbh<-density(gb[,1],na.rm=TRUE)
sph<-density(sp[,1],na.rm=TRUE)
bnph<-density(bnp[,1],na.rm=TRUE)
sjh<-density(sj[,1],na.rm=TRUE)
pbh<-density(pb[,1],na.rm=TRUE)
vbh<-density(vb[,1],na.rm=TRUE)
bbh<-density(bb[,1],na.rm=TRUE)

plot(bbh,col="black",ylim=c(0,48),xlim=c(-.2,1.2))
lines(vbh,col="grey50")
lines(pbh,col="red")
lines(sjh,col="darkorange")
lines(bnph,col="gold")
lines(sph,col="cyan")
lines(gbh,col="blue")

#separate

par(mfrow=c(2,1),mar=c(2,4,1,1))

plot(bbh,col="black",ylim=c(0,7),xlim=c(-.2,1.2),
     main="",xaxt='n',
     cex.axis=1.2,lwd=2,bty="l")
lines(vbh,col="black",lwd=2)
lines(pbh,col="black",lwd=2)

legend('topright',legend=c("resistant","intermediate","reference"),col=c("black","red","blue"),
       pch=20,cex=1.5,bty="n",y.intersp=1,x.intersp=.5)

plot(sjh,col="red",ylim=c(0,48),xlim=c(-.2,1.2),main="",
     cex.axis=1.2,lwd=2,bty="l")
lines(bnph,col="red",lwd=2)
lines(sph,col="blue",lwd=2)
lines(gbh,col="blue",lwd=2)
# 
# legend('topleft',legend=c("intermediate","reference"),col=c("red","blue"),
#        pch=20,cex=1.5,bty="n",y.intersp=1,x.intersp=.5)


###
#install.packages("diptest")
library(diptest)

dip.test(bb[,1],simulate.p.value = TRUE,B=2000)
#p=0.92
dip.test(vb[,1],simulate.p.value = TRUE,B=2000)
#p=0.22
dip.test(pb[,1],simulate.p.value = TRUE,B=2000)
#p=0.0015
dip.test(sj[,1],simulate.p.value = TRUE,B=2000)
#p=0.99
dip.test(bnp[,1],simulate.p.value = TRUE,B=2000)
#p=0.99
dip.test(sp[,1],simulate.p.value = TRUE,B=2000)
#p=1
dip.test(gb[,1],simulate.p.value = TRUE,B=2000)
#p=1

###Probs of admixture
a<-matrix(nrow =1,ncol=7)
a[,1]<-sum(bb[,2])/length(bb[,2])
a[,2]<-sum(vb[,2])/length(vb[,2])
a[,3]<-sum(pb[,2])/length(pb[,2])
a[,4]<-sum(sj[,2])/length(sj[,2])
a[,5]<-sum(bnp[,2])/length(bnp[,2])
a[,6]<-sum(sp[,2])/length(sp[,2])
a[,7]<-sum(gb[,2])/length(gb[,2])
colnames(a)<-c("bb","vb","pb","sj","bnp","sp","gb")
rownames(a)<-"alpha"

write.table(a,"~/analysis/data/fastngs/alpha",quote=FALSE,row.names=FALSE)

```

* this gave us an expectation for all allele frequencies for outlier regions.

# Plink MDS

## Full genome MDS
```{bash}
#!/bin/bash
#PBS -l nodes=1:ppn=8
#PBS -l walltime=2:00:00


/data/oziolore/program/plink/plink \
-vcf /data/oziolore/fhet/data/varcall/filtered_chr.vcf.bgz \
--allow-extra-chr \
--cluster \
--mds-plot 5 \
--out /data/oziolore/fhet/data/plink/full.genome

```

##Plotting full genome MDS

```{r}
#R script to start new scaffold analysis in R
read.table("~/analysis/data/plink/full.genome/full.genome.mds",stringsAsFactors=FALSE)->full
read.table("~/analysis/data/plink/metadata",stringsAsFactors=FALSE,sep="\t")->meta
row.names(meta)<-meta[,1]
read.table("~/analysis/data/plink/popcolors.txt",stringsAsFactors=FALSE,sep="\t")->pops
row.names(pops)<-pops[,1]
plot(full[,4:5],pch=20,cex=.8,col=pops[meta[full[,1],2],2])
library(scatterplot3d)
scatterplot3d(full[,4:6],pch=20,color=pops[meta[full[,1],2],2])

#Separating by sex
read.table("~/analysis/data/plink/popcolors_sex.txt",stringsAsFactors=FALSE,sep="\t")->pops_sex
row.names(pops_sex)<-pops_sex[,1]
plot(full[,4:5],pch=20,cex=.8,col=pops_sex[meta[full[,1],3],2])
scatterplot3d(full[,4:6],pch=20,color=pops_sex[meta[full[,1],3],2])


#Separating by collection year
read.table("~/share/metadata_2.txt",stringsAsFactors=FALSE,sep="\t")->meta
row.names(meta)<-meta[,1]
read.table("~/share/popcolors_2.txt",stringsAsFactors=FALSE,sep="\t")->pops
row.names(pops)<-pops[,1]
plot(full[,4:5],pch=20,cex=.8,col=pops[meta[full[,1],3],2])
library(scatterplot3d)
scatterplot3d(full[,4:6],pch=20,color=pops[meta[full[,1],3],2])

```

# Outliers frequency
##Frequency vs. expected frequency

```{r}
library(viridis)
library(dplyr)
library(magrittr)
library(stringr)
library(gtools)
library(rtracklayer)
library(ggplot2)
library(ggsci)
library(reshape2)

pbs_dist<-read.table("~/fgfh_post/data/fst/hudsonpbs_1kb.bed",header=FALSE)
distnames<-c("Scaf","start","end","bb","vb","pb","sj","bnp")
colnames(pbs_dist)<-distnames
col<-c()
for (i in 1:5){
  col[i]<-quantile(pbs_dist[,i+3],prob=.99,na.rm=TRUE)
}


z<-read.table("~/fgfh_post/data/fst/hudson_pbsmergeoutliers.bed",stringsAsFactors = FALSE) #loads a pbs vector with windows merged within 50kb of each other and with max and windows count statistics
names<-c("Scaf","start","end","BBsum","BBcount","VBsum","VBcount","PBsum","PBcount","SJsum","SJcount","BNPsum","BNPcount")
colnames(z)<-names

all<-z[,4]>col[1] & z[,6]>col[2] & z[,8]>col[3] & z[,10]>col[4] & z[,12]>col[5]

###Reading in VCF for outlier regions that include introgression, formatting ----
vcf<-read.table("~/fgfh_post/data/fst/hudson_out_all_intr_haplo.vcf.bgz",stringsAsFactors = FALSE) #vcf that has been filtered out to only present one allele call per site per individual
sexscore<-read.table("~/fgfh_post/scripts/depth/sexscore",header=TRUE)
#vcf<-cbind(vcf[,1],vcf[,2]-1,vcf[,2:297]) #Converting the first three columns into bed type format
cname<-c(seq(1:9),as.character(sexscore[,1])) # colnames for the vcf
colnames(vcf)<-cname

subw<-nchar(vcf[,5])<2 #using only biallelic SNPs

vcf<-vcf[subw,] #restricting to biallelic SNPs

table(nchar(vcf[,4])>2) #Confirming biallelic SNPs with reference allele after restriction

gt<-as.matrix(vcf[,10:297]) #convert to numeric
class(gt)<-"numeric"

keep<-colMeans(is.na(gt))<0.9 #toss individuals with missing info (less than 90%)
gt<-gt[,keep]

#Summing SNP frequencies----

popfr<-cbind(vcf[,1:2])
nam<-c("chr","pos","BB","VB","PB","SJ","BNP","SP","GB")

for(j in 1:length(nam[-1:-2])){
  b<-gt[,grepl(nam[j+2],colnames(gt))]
  f<-as.numeric(rowSums(gt[,grepl(nam[j+2],colnames(gt))],na.rm=TRUE)/ncol(!is.na(b)))
  popfr<-cbind(popfr,f)
  print(nam[j+2])
  print(ncol(b))
}
#summed frequencies over all individuals 
colnames(popfr)<-nam

res<-(rowSums(popfr[,3:5])/3) #summing SNP frequencies over resistant sites and below for all other
int<-(rowSums(popfr[,6:7])/2)
ref<-(rowSums(popfr[,8:9])/2)
rr<-cbind(popfr[,1:2],res,ref,int) #merging these into a single DF

quantile(with(rr,res-ref),probs=0.97)
plot(rr[,"res"]-rr[,"ref"],pch=20,cex=.4,col=ifelse(res-ref>.13,"red","black")) #Plotting difference between res and ref
subw<-with(rr,res-ref)>.13

plot(rr[subw,"res"]-rr[subw,"int"],pch=20,cex=.4,col="firebrick2")
points(rr[subw,"res"]-rr[subw,"ref"],pch=20,cex=.4,col="cadetblue3")

#just plotting where intermediates would lie
# plot(with(rr,(res-int)/(res-ref)),pch=20,cex=.5)
# 
# ggplot(data=rr,
#        aes((res-int)/(res-ref)))+
#   geom_histogram()

###Frequency of haplotypes in individuals based on those SNPs----

vcfo<-vcf[subw,] #using only the biallelic SNPs that are in the 97th percentile of allele frequency difference
zn<-na.omit(z[all,1:3]) #using the rows of merged divergent regions to create regions from which I will merge SNPs
nam<-c("chr","start","end")
colnames(zn)<-nam

vcfo<-cbind(vcfo[,1],vcfo[,2]-1,vcfo[,2:297]) #making vcfo into a bed file
write.table(vcfo[,1:3],"~/fgfh_post/data/expectations/vcf_hudpbs_out.bed",row.names = FALSE,col.names = FALSE,quote = FALSE,sep='\t')
write.table(zn[,1:3],"~/fgfh_post/data/expectations/hudpbs_shared_all.bed",row.names = FALSE,col.names = FALSE,quote = FALSE,sep='\t')

library(rtracklayer)

bed1=import("~/fgfh_post/data/expectations/vcf_hudpbs_out.bed")
bedall=import("~/fgfh_post/data/expectations/hudpbs_shared_all.bed")
bed1overlall=bed1[bed1 %over% bedall]
hitsall<-countOverlaps(bedall,bed1) #creating a vector of overlap counts - # SNPs present in that overlap

gt<-as.matrix(vcfo[,10:297]) #convert to numeric
class(gt)<-"numeric"
keep<-colMeans(is.na(gt))<0.9 #toss sites with low coverage
gt<-gt[,keep]

fr<-c() #this is used to create a matrix of frequencies of the haplotype in each outlier window by counting the number of SNPs in it
j=0
for(i in 1:length(hitsall)){
  if(hitsall[i]>1){
  f<-as.numeric(colSums(gt[(j+1):(hitsall[i]+j),],na.rm=TRUE)/hitsall[i])
  fr<-rbind(fr,f)
  j=j+hitsall[i]
  print(j==sum(hitsall[1:i]))
  print(i)
  } else if (hitsall[i]==1){
    j=j+1
  }
}

colnames(fr)<-colnames(gt)

#Calling individuals as 0,0.5,1 frequency of haplotype ----
#I'll make a judgment call that anything below 0.1 is absence, anything above 0.6 is presence in full, anything in between is half
frr<-fr
for(i in 1:dim(fr)[[2]]){
  for(j in 1:dim(fr)[[1]]){
    if(fr[j,i]<0.1){
      frr[j,i]<-as.numeric(0)
    } else if (fr[j,i]>0.6){
      frr[j,i]<-as.numeric(1)
    } else{
      frr[j,i]<-as.numeric(0.5)
    }
  }
}

###Summing allele frequencies over populations----

nam<-c("BB","VB","PB","SJ","BNP","SP","GB")
subw<-hitsall>1

pfr<-zn[subw,1:3]
for(i in 1:length(nam)){
  f<-as.numeric(rowSums(frr[,grepl(nam[i],colnames(frr))],na.rm=TRUE))/ncol(frr[,grepl(nam[i],colnames(frr))])
  pfr<-cbind(pfr,f)
}

colnames(pfr)<-c(colnames(pfr[1:3]),nam)

pfr<-t(pfr[4:10])

# plot(pfr[,1],ylim=c(0,.5))
# for(i in 1:dim(pfr)[[2]]){
#   lines(pfr[,i],ylim=c(0,.5))
# }

#Seeing if those frequencies meet expectations from admixture----
a<-read.table("~/fgfh_post/data/fastngs/alpha",header=TRUE)
a<-as.numeric(a)

e<-c() #creating a vector e of expected values for each allele
r<-c()
for(i in 1:dim(pfr)[[2]]){
  for(j in 1:dim(pfr)[[1]]){
    b<-a[j]*pfr[1,i]+(1-a[j])*pfr[7,i]
    r[j]<-b
  }
  e<-cbind(e,r)
}

rownames(e)<-rownames(pfr)
colnames(e)<-colnames(pfr)

efr<-pfr-e
colnames(efr)<-(zn[subw,1])
efr1<-efr[,grepl("chr",colnames(efr))]

tiff("~/Documents/UCD/Projects/Adaptation + Introgression/draft/images/outlier_freqs.tiff",width=1000,height=600)
par(mar=c(4,4,2,2))
plot(efr[,1],ylim=c(-.2,.4),type='n',xaxt='n',
     ylab="Deviation from expected allele frequencies due to admixture",bty='l')
for(i in 1:dim(efr)[[2]]){
  lines(efr[,i],lwd=ifelse(zn[i,1]=="chr1"&zn[i,2]==0,4,
                                        ifelse(zn[i,1]=="chr8"&zn[i,2]==16458074,4,0.8))
        ,col=ifelse(zn[i,1]=="chr1"&zn[i,2]==0,"blue",
                    ifelse(zn[i,1]=="chr8"&zn[i,2]==16458074,"green","black")))
}
axis(side=1,at=1:7,labels=c(rownames(efr)))
box(lwd=4,bty='l')
abline(h=1,lwd=3,lty=2,col="black")
dev.off()

tiff("~/Documents/UCD/Projects/Adaptation + Introgression/draft/images/outlier_freqs2.tiff",width=800,height=800)
efrm<-melt(efr) #putting it in a dataframe more readable by ggplot
colnames(efrm)<-c("pop","chr","freq")

ggplot(efrm,
       aes(x=pop,y=freq),color=pop,fill=pop)+
  geom_violin(draw_quantiles=c(0.5),aes(fill=pop),trim=TRUE,scale="width")+
  scale_fill_manual(values=c(rep("black",3),rep("firebrick2",2),rep("cadetblue3",2)))+
  geom_jitter(aes(colour=pop))+
  scale_color_manual(values=c(rep("grey40",3),rep("black",2),rep("black",2)))+
  theme_classic()+
  scale_y_continuous(limits=c(-.2,.4))+
  theme(axis.line = element_line(size=3))
dev.off()

tiff("~/Documents/UCD/Projects/Adaptation + Introgression/draft/images/outlier_main.tiff",width=1000,height=400)
efrm<-melt(efr) #putting it in a dataframe more readable by ggplot
colnames(efrm)<-c("pop","chr","freq")

ggplot(efrm,
       aes(x=pop,y=freq),color=pop,fill=pop)+
  geom_violin(draw_quantiles=c(0.5),aes(fill=pop),trim=TRUE,scale="width")+
  scale_fill_manual(values=c(rep("black",3),rep("firebrick2",2),rep("cadetblue3",2)))+
  geom_jitter(aes(colour=pop),cex=3)+
  scale_color_manual(values=c(rep("grey40",3),rep("black",2),rep("black",2)))+
  theme_classic()+
  scale_y_continuous(limits=c(-.2,.4))+
  theme(axis.line = element_line(size=3))
dev.off()

#Color by chromosome ----
chr<-unique(colnames(efr1))
# color = pal_igv(palette=c("default"),alpha=1)(17)
color=pal_ucscgb(palette=c("default"),alpha=1)(12)
col=color[1:12]
chr<-cbind(chr,col)
rownames(chr)<-chr[,1]

par(mar=c(4,4,2,2))
plot(efr1[,1],ylim=c(-.2,.4),type='n',xaxt='n',
     ylab="Deviation from expected allele frequencies due to admixture",bty='l')
for(i in 1:dim(efr1)[[2]]){
  lines(efr1[,i],ylim=c(0,.4),lwd=1.5,col=chr[colnames(efr1)[i],2])
}
axis(side=1,at=1:7,labels=c(rownames(efr1)))
abline(h=1,lwd=3,lty=2)
legend("topright",legend=c(chr[,1]),col=c(chr[,2]),pch=20,cex=1)

```

#Introgression models
##Plotting models of introgression

```{r}

cl_mig_stagSweeps = readRDS("~/fgfh_post/data/intro_models/compLikelihood_mig_stagSweeps.RDS")
cl_neutral = readRDS("~/fgfh_post/data/intro_models/compLikelihood_neutral.RDS")
cl_sv = readRDS("~/fgfh_post/data/intro_models/compLikelihood_stdVar.RDS")

sels = readRDS("~/fgfh_post/data/intro_models/sels.RDS")
times = readRDS("~/fgfh_post/data/intro_models/times.RDS")
gs = readRDS("~/fgfh_post/data/intro_models/gs.RDS")


maxCL_mig_stagSweeps.sels = sapply(1 : length(sels), function(i) max(unlist(cl_mig_stagSweeps[[i]])))
maxCL_sv.sels = sapply(1 : length(sels), function(i) max(unlist(cl_sv[[i]])))

cl_mig_stagSweeps_byTime = lapply(1 : length(times), function(time) lapply(1 : length(sels), function(sel) lapply(1 : length(gs), function(g) cl_mig_stagSweeps[[sel]][[g]][[time]])))
maxCL_mig_stagSweeps.times = sapply(1 : length(times), function(i) max(unlist(cl_mig_stagSweeps_byTime[[i]])))

sels18_scaled = (sels[18:31] - sels[18]) / (sels[31] - sels[18]) #get last sels and put on (0,1) scale
times18_scaled = (times[1:18] - times[1]) / (times[18] - times[1]) #get last times and put on (0,1) scale

yMin = min(c(maxCL_mig_stagSweeps.sels, maxCL_sv.sels) - cl_neutral)
yMax = max(c(maxCL_mig_stagSweeps.sels, maxCL_sv.sels) - cl_neutral)

jpeg("~/Documents/UCD/Projects/Adaptation + Introgression/draft/images/intro_models.jpeg",width=600,height=400)
  par(oma = c(1,1.5,2,1.5),mar=c(3,3,3,3),mgp=c(1,2,0))
  plot(sels18_scaled, maxCL_mig_stagSweeps.sels[18:31] - cl_neutral, 
       cex.axis = 1.3, ylab = "", ylim = c(4.8e5, yMax), 
       type = "l", col = "seagreen3", xlim = c(0, 1), xaxt = "none", xlab = "", lwd = 6, cex.lab = 1.1)
  box(lwd=6)
  lines(sels18_scaled, maxCL_sv.sels[18:31] - cl_neutral, col = "seagreen3", lwd = 6, lty = 2)
  axis(1, at = seq(0, 1, length.out = 6), labels = seq(0.5, 1, length.out = 6), col = "seagreen3", lwd = 6, cex.axis = 2.8)
  lines(times18_scaled, maxCL_mig_stagSweeps.times[1:18] - cl_neutral, col = "gold2", lwd = 6, lty = 1)
  axis(3, lwd = 6, at = seq(0, 1, length.out = 6), labels = seq(times[1]+18, times[18]+18, length.out = 6), col = "gold2", cex.axis = 2.8)

#legend("bottomright", lty = c(1,2), legend = c("Introgression", "ILS"), lwd = 6)
#mtext(line = 3, side = 1, text = "selection coefficient", cex = 1.3)
#mtext(line = 3, side = 3, text = "time between introgression and selection (generations)", cex = 1.1)
#axis 1 label = Composite log-likelihood (model - neutral)
dev.off()

```

##Plotting genome wide dxy

```{r}
library(stringr)
library(dplyr)
library(gtools)
library('naturalsort')
load("~/analysis/scripts/introgression/dxyscan.Rdata") #loading data into R


subw<-dxyscan[,"keep"]==TRUE
dxy<-dxyscan[subw,1:9]

ord<-mixedorder(dxy$chr)
dxyt<-dxy[ord,]

dxy2<-dxyt %>% filter(str_detect(chr,"chr"))

col<-c()
for(i in 1:3){
  col[i]<-quantile(dxy2[,i+6],probs=0.005)
}

chr16<-dxy2 %>% filter(str_detect(chr,"chr16"))#checking out chr16
ord<-order(chr16[,"BB"],decreasing=FALSE) #ordering them so I can remove the crappy scaffold
crap<-str_detect(chr16$scaf,"NW_012224891.1")
crap2<-str_detect(chr16$scaf,"NW_012224806.1")
ord<-order(chr16[!crap,"BB"],decreasing=FALSE) #ordering them so I can remove the crappy scaffold


crappy<-str_detect(dxy2$scaf,"NW_012224891.1")
dxy3<-dxy2[!crappy,]
crappy2<-str_detect(dxy3$scaf,"NW_012224806.1")
dxy4<-dxy3[!crappy2,]

dxy4$chr<-factor(dxy4$chr,levels=c("chr1","chr2","chr3","chr4","chr5","chr6","chr7","chr8","chr9","chr10",
                                     "chr11","chr12","chr13","chr14","chr15","chr16","chr17","chr18","chr19",
                                     "chr20","chr21","chr22","chr23","chr24"))

tiff("~/backup/UCD/Projects/Adaptation + Introgression/draft/images/introgression_dxy.tiff",width=1200,height=600)
palette(c("grey40","grey80"))
par(mfrow=c(3,1),mar=c(0,4,0,0))
plot(dxy4[,"BB"],pch=20,cex=1,col=ifelse(dxy4[,"BB"]<col[2],"seagreen3",as.factor(dxy4[,"chr"])),bty='n',
     xlab="",ylab="",xaxt='n',ylim=c(-.0271,.01),cex.axis=4)
plot(dxy4[,"VB"],pch=20,cex=1,col=ifelse(dxy4[,"VB"]<col[1],"seagreen3",as.factor(dxy4[,"chr"])),bty='n',
     xlab="",ylab="",xaxt='n',ylim=c(-.0271,.01),cex.axis=4)
plot(dxy4[,"PB"],pch=20,cex=1,col=ifelse(dxy4[,"PB"]<col[3],"seagreen3",as.factor(dxy4[,"chr"])),bty='n',
     xlab="",ylab="",xaxt='n',ylim=c(-.0271,.01),cex.axis=4)
dev.off()

#finding the introgression region

chr10_intr<-dxy4[dxy4$chr=="chr10" & dxy4[,"VB"]<col[1],4:6] #taking only introgressed region
total_chr10<-cbind(head(chr10_intr[,1:2],n=1),tail(chr10_intr[,3],n=1)) #merging the start and end of that region
write.table(total_chr10,"~/analysis/data/intro_models/chr10_region.txt",col.names = FALSE,row.names = FALSE,quote = FALSE) #writing it down
``` 

## Introgression MDS plots of AHR

```{r}
library(viridis)
library(dplyr)
library(magrittr)
library(Rphylip)
library(ape)
library(stringr)

load("~/analysis/scripts/introgression/AHR_elias_plotdata.Rdata")
names<-row.names(mds)
popcol<-ifelse(grepl("-",names),"seagreen3",
               ifelse(grepl("BB",names),"black",
                      ifelse(grepl("VB",names),"black",
                             ifelse(grepl("PB",names),"black",
                                    ifelse(grepl("SJ",names),"firebrick2",
                                           ifelse(grepl("BNP",names),"firebrick2",
                                                  ifelse(grepl("SP",names),"cadetblue3",
                                                         ifelse(grepl("GB",names),"cadetblue3","WRONG"))))))))
popcol2<-ifelse(grepl("-",names),"seagreen3",
               ifelse(grepl("BB",names),"black",
                      ifelse(grepl("VB",names),"grey40",
                             ifelse(grepl("PB",names),"grey80",
                                    ifelse(grepl("SJ",names),"firebrick2",
                                           ifelse(grepl("BNP",names),"lightpink",
                                                  ifelse(grepl("SP",names),"cadetblue3",
                                                         ifelse(grepl("GB",names),"cadetblue1","WRONG"))))))))               
popsym<-ifelse(grepl("d2",pop2),"23",
               ifelse(grepl("d1",pop2),"24",
                      ifelse(grepl("d0",pop2),"21","22")))

#plotting NJ tree
plot(tr,type="unrooted",show.tip.label=FALSE)
tiplabels(pch=as.numeric(popsym),col=popcol,bg=popcol2,cex=1.5)

#plotting MDS
tiff("~/backup/UCD/Projects/Adaptation + Introgression/draft/images/introgression_mds.tiff",width=650,height=600)
plot(mds,col=popcol,cex=2,cex.axis=2,pch=as.numeric(popsym),
     bg=popcol2,bty='n',xlab='',ylab='')
box(bty='l',lwd=5)
dev.off()

```

## Blocks of introgression

```{r}
library('ggplot2')
library('reshape')
block<-read.table("~/analysis/data/introgression/grandis_int_blocks.txt",sep='\t',head=TRUE) #reading in introgression blocks
block[,"sam"]<-sub("SJSP","SJ",block[,"sam"])
subw<-block[,"count"]>4 #filtering regions with less than 4 outliers present
block2<-block[subw,]

a<-seq(400000,13000000,by=1000000) #creating bins for plotting
ranges<-paste(head(a,-1),a[-1],sep=' - ') #putting them in ranges
#fr<-hist(block2[,"length"],breaks=a,include.lowest=TRUE,plot=FALSE)

pops<-c("BB","VB","PB","SJ","BNP","SP","GB")
num<-c(24,49,47,24,48,48,48)
names(num)<-pops
counts<-matrix(nrow = length(ranges),ncol = length(pops))
colnames(counts)<-pops
rownames(counts)<-a[-1]

for(i in pops){
  len<-block2[grepl(i,block2[,"sam"]),"length"]
  fr<-hist(len,breaks=a,include.lowest = TRUE,plot=FALSE )
  counts[,i]<-fr$counts/num[i][[1]]
}

counts2<-melt(counts)
colnames(counts2)<-c("size","pop","count")
counts2$pop<-factor(counts2$pop,levels=c("BB","VB","PB","SJ","BNP","SP","GB"))

tiff("~/backup/UCD/Projects/Adaptation + Introgression/draft/images/introgression_size.tiff",width=700,height=400)
ggplot(counts2,
       aes(x=size/1000000,y=count,by=pop,color=pop))+
#  geom_line(aes(col=pop),lwd=3)+
  stat_smooth(aes(y=count,x=size/1000000),method=lm,formula=y~poly(x,5),se=FALSE,lwd=3)+
  theme_classic()+
  scale_color_manual(values=c("black","grey40","grey80","firebrick2","lightpink","cadetblue3","cadetblue1"))+
  theme(axis.line=element_line(size=2),
        axis.text.x=element_text(size=20),
        axis.text.y=element_text(size=20),
        axis.title.x=element_blank(),
        axis.title.y=element_blank())
dev.off()
```

# Deletion

## Plotting for both species

### Getting the sample names from the vcf file

```{bash}
zcat hetgran.vcf.gz | grep -v "##" | head -n 1 > header.txt

```

### Downloaded depth file from Noah

```{r}
library(viridis)
library(dplyr)
library(magrittr)
library(Rphylip)
library(ape)
library(stringr)

#colnames(gts)[1] <- "pos"
col<-scan("~/fgfh_post/data/depth/header.txt",sep='\t',what = "character") #grabbing names of all individuals
dep<-read.table("~/fgfh_post/data/depth/NW_012234474.1_550000-800000.depth.txt.gz",stringsAsFactors=FALSE) #grabbing depth vector made by samtools
sexscore0<-col[-c(1:9)] #removing non-individual fields
sexscore<-gsub("SJSP","SJ",sexscore0)
names(sexscore)<-sexscore # for counting later
mat<-read.table("~/fgfh_post/data/plink/popcolors.txt",stringsAsFactors=FALSE,sep="\t") #getting colors for later

pops0 <- gsub("-.*||_.*||.*\\.","",sexscore) #getting a vector of all pops for the individuals
pops<-gsub("SJSP","SJ",pops0) #renaming SJSP because it causes problems for grepping SP

popord <- c(grep("ER",sexscore),grep("BB",sexscore),grep("VB",sexscore),grep("PB",sexscore),grep("SJ",sexscore),
            grep("BNP",sexscore),grep("SP",sexscore),grep("GB",sexscore))

ero<-grep("ER",sexscore)
bbo<-grep("BB",sexscore)
vbo<-grep("VB",sexscore)
pbo<-grep("PB",sexscore)
sjo<-grep("SJ",sexscore)
bnpo<-grep("BNP",sexscore)
spo<-grep("SP",sexscore)
gbo<-grep("GB",sexscore)


##deletion boundaries:
  #approximate break points:740000-800000
  #will use a conservative window that doesn't include a little spike in coverage: 760000-800000

#no deletion
nodel<-dep[,2]>750000&dep[,2]<800000
del<-dep[,2]>640000&dep[,2]<710000

scalevec <- colSums(dep[nodel,-c(1,2)])/(sum(nodel))
scalevec2<- colSums(dep[del,-c(1,2)])/sum(del)

copies_per_ind <- data.frame(cbind(n_copies=rep(2,576),pop=gsub("-.*||_.*||.*\\.","",sexscore)),stringsAsFactors=FALSE)
rownames(copies_per_ind) <- sexscore

#my alternative

ercopy<-t(t(dep[del,ero+2])/scalevec[ero])%>%
  (function(x){
    s <- colSums(x)
    o <- order(s,decreasing=TRUE)
    s[o]})

bbcopy<-t(t(dep[del,bbo+2])/scalevec[bbo])%>%
  (function(x){
    s <- colSums(x)
    o <- order(s,decreasing=TRUE)
    s[o]})

vbcopy<-t(t(dep[del,vbo+2])/scalevec[vbo])%>%
  (function(x){
    s <- colSums(x)
    o <- order(s,decreasing=TRUE)
    s[o]})

pbcopy<-t(t(dep[del,pbo+2])/scalevec[pbo])%>%
  (function(x){
    s <- colSums(x)
    o <- order(s,decreasing=TRUE)
    s[o]})

sjcopy<-t(t(dep[del,sjo+2])/scalevec[sjo])%>%
  (function(x){
    s <- colSums(x)
    o <- order(s,decreasing=TRUE)
    s[o]})

bnpcopy<-t(t(dep[del,bnpo+2])/scalevec[bnpo])%>%
  (function(x){
    s <- colSums(x)
    o <- order(s,decreasing=TRUE)
    s[o]})

spcopy<-t(t(dep[del,spo+2])/scalevec[spo])%>%
  (function(x){
    s <- colSums(x)
    o <- order(s,decreasing=TRUE)
    s[o]})

gbcopy<-t(t(dep[del,gbo+2])/scalevec[gbo])%>%
  (function(x){
    s <- colSums(x)
    o <- order(s,decreasing=TRUE)
    s[o]})

plot(bbcopy,col="black",ylim=c(0,50000),xlim=c(1,50),pch=20,cex=1)
plot(vbcopy,col="grey",pch=20,cex=1)
plot(pbcopy,col="red",pch=20,cex=1)
plot(sjcopy,col="darkorange",pch=20,cex=1)
plot(bnpcopy,col="gold",pch=20,cex=1)
plot(spcopy,col="cyan",pch=20,cex=1)
plot(gbcopy,col="blue",pch=20,cex=1)

msp<-mean(spcopy[1:47])
ssp<-sd(spcopy[1:47])

abline(h=msp-2*ssp,lty=2,lwd=3,col="black")
abline(h=10000,lty=2,lwd=3,col="grey")


###Counting the copies

bbnum<-t(t(dep[del,bbo+2])/scalevec[bbo])%>%
  (function(x){
    s <- colSums(x)
    o <- order(s,decreasing=TRUE)
    o}) %>%
  (sexscore[bbo])[.] %>%
  names() %>%
  cbind(
    .,
    c(rep(2,18),rep(1,5),rep(0,1))
  )

copies_per_ind[bbnum[,1],1]<-bbnum[,2]

vbnum<-t(t(dep[del,vbo+2])/scalevec[vbo])%>%
  (function(x){
    s <- colSums(x)
    o <- order(s,decreasing=TRUE)
    o}) %>%
  (sexscore[vbo])[.] %>%
  names() %>%
  cbind(
    .,
    c(rep(2,38),rep(1,10),rep(0,1))
  )

copies_per_ind[vbnum[,1],1]<-vbnum[,2]

pbnum<-t(t(dep[del,pbo+2])/scalevec[pbo])%>%
  (function(x){
    s <- colSums(x)
    o <- order(s,decreasing=TRUE)
    o}) %>%
 (sexscore[pbo])[.] %>%
  names() %>%
  cbind(
    .,
    c(rep(2,21),rep(1,22),rep(0,4))
  )

copies_per_ind[pbnum[,1],1]<-pbnum[,2]

sjnum<-t(t(dep[del,sjo+2])/scalevec[sjo])%>%
  (function(x){
    s <- colSums(x)
    o <- order(s,decreasing=TRUE)
    o}) %>%
  (sexscore[sjo])[.] %>%
  names() %>%
  cbind(
    .,
    c(rep(2,1),rep(1,4),rep(0,19))
  )

copies_per_ind[sjnum[,1],1]<-sjnum[,2]

bnpnum<-t(t(dep[del,bnpo+2])/scalevec[bnpo])%>%
  (function(x){
    s <- colSums(x)
    o <- order(s,decreasing=TRUE)
    o}) %>%
  (sexscore[bnpo])[.] %>%
  names() %>%
  cbind(
    .,
    c(rep(2,0),rep(1,5),rep(0,43))
  )

copies_per_ind[bnpnum[,1],1]<-bnpnum[,2]

spnum<-t(t(dep[del,spo+2])/scalevec[spo])%>%
  (function(x){
    s <- colSums(x)
    o <- order(s,decreasing=TRUE)
    o}) %>%
  (sexscore[spo])[.] %>%
  names() %>%
  cbind(
    .,
    c(rep(2,0),rep(1,0),rep(0,48))
  )

copies_per_ind[spnum[,1],1]<-spnum[,2]

gbnum<-t(t(dep[del,gbo+2])/scalevec[gbo])%>%
  (function(x){
    s <- colSums(x)
    o <- order(s,decreasing=TRUE)
    o}) %>%
  (sexscore[gbo])[.] %>%
  names() %>%
  cbind(
    .,
    c(rep(2,0),rep(1,1),rep(0,47))
  )

copies_per_ind[gbnum[,1],1]<-gbnum[,2]

copies_per_ind[,1] <- as.numeric(copies_per_ind[,1])


# table(copies_per_ind[,c(1,2)]) %>% 
#   (function(x){as.array(x[,c(3,6,2,5,4,7,1)])}) %>% 
#   (function(x){barplot(x,beside=TRUE,col=c("darkolivegreen1","chartreuse3","darkgreen"),
#                        ylab='',cex.axis = 2.5,cex.names = 1.5)})
par(mfrow=c(1,1),mar=c(2,4,2,4))
copies<-as.array(table(copies_per_ind[,c(1,2)]) %>% 
                (function(x){x[,c("BB","VB","PB","SJ","BNP","SP","GB")]}) )
copies.prop<-prop.table(copies,2)*100 

tiff("~/Documents/UCD/Projects/Adaptation + Introgression/draft/images/deletion_freq.tiff",width=1000,height=400)
par(lwd=3)
barplot(copies.prop,beside=TRUE,col=c("white","mediumorchid1","purple3"),
       ylab='',cex.axis = 2.2,cex.names = 1.5,lwd=3)
dev.off

# legend("topright",legend=c("wt","delHet","delHom"),pch=20,cex=1.2,col=c("blue","red","pink","green","lightgrey","grey50","black"),
#        x.intersp = 0.4,y.intersp = .7)

###smoothing vector function

subsmooth <- function(vec,by=10,width=1000){
  
  len <- length(vec)
  subl <- seq(from=by,to=len,by=by)
  submax <- length(subl)
  width <- width/2
  test <- vec[subl]
  
  for(i in 1:submax){
    
    j <- i - width
    k <- i + width
    if(j < 1) {j <- 1}
    if(k > submax) {k <- submax}
    test[i] <- mean(test[j:k],na.rm=TRUE)
  }
  
  return(test)
  
}


###smoothing pop coverage

depsub <- as.data.frame(apply(dep[,-c(1,2)],MAR=2,FUN=subsmooth,by=20,width=500))
jump<-dep[seq(from=20,to=dim(dep)[1],by=20),2]
depsub <- cbind("Chr1sub",jump,depsub)

tiff("~/backup/UCD/Projects/Adaptation + Introgression/draft/images/deletion_heat.tiff",width=1200,height=1000)

par(mfrow=c(8,1),mar=c(2,4,0,0))

er <- grep("ER",sexscore)
t(t(depsub[,ero+2])/scalevec[ero]) %>%
  (function(x){
    s <- colSums(x)
    o <- order(s,decreasing=TRUE)
    x[,o]
  }) %>%
  
  image(z=.,zlim=c(0,4),col=viridis(30),x=depsub[,2],y=(1:length(ero)),ylab="ER",xlab='')

bb <- grep("BB",sexscore)
t(t(depsub[,bbo+2])/scalevec[bbo]) %>%
  (function(x){
    s <- colSums(x)
    o <- order(s,decreasing=TRUE)
    x[,o]
  }) %>%
  
  image(z=.,zlim=c(0,4),col=viridis(30),x=depsub[,2],y=(1:length(bbo)),ylab="BB")

vb <- grep("vb",sexscore)
t(t(depsub[,vbo+2])/scalevec[vbo]) %>%
  (function(x){
    s <- colSums(x)
    o <- order(s,decreasing=TRUE)
    x[,o]
  }) %>%
  
  image(z=.,zlim=c(0,4),col=viridis(30),x=depsub[,2],y=(1:length(vbo)),ylab="VB")

pb <- grep("pb",sexscore)
t(t(depsub[,pbo+2])/scalevec[pbo]) %>%
  (function(x){
    s <- colSums(x)
    o <- order(s,decreasing=TRUE)
    x[,o]
  }) %>%
  
  image(z=.,zlim=c(0,4),col=viridis(30),x=depsub[,2],y=(1:length(pbo)),ylab="PB")

sj <- grep("sj",sexscore)
t(t(depsub[,sjo+2])/scalevec[sjo]) %>%
  (function(x){
    s <- colSums(x)
    o <- order(s,decreasing=TRUE)
    x[,o]
  }) %>%
  
  image(z=.,zlim=c(0,4),col=viridis(30),x=depsub[,2],y=(1:length(sjo)),ylab="SJ")

bnp <- grep("bnp",sexscore)
t(t(depsub[,bnpo+2])/scalevec[bnpo]) %>%
  (function(x){
    s <- colSums(x)
    o <- order(s,decreasing=TRUE)
    x[,o]
  }) %>%
  
  image(z=.,zlim=c(0,4),col=viridis(30),x=depsub[,2],y=(1:length(bnpo)),ylab="BNP")

sp <- grep("sp",sexscore)
t(t(depsub[,spo+2])/scalevec[spo]) %>%
  (function(x){
    s <- colSums(x)
    o <- order(s,decreasing=TRUE)
    x[,o]
  }) %>%
  
  image(z=.,zlim=c(0,4),col=viridis(30),x=depsub[,2],y=(1:length(spo)),ylab="SP")

gb <- grep("gb",sexscore)
t(t(depsub[,gbo+2])/scalevec[gbo]) %>%
  (function(x){
    s <- colSums(x)
    o <- order(s,decreasing=TRUE)
    x[,o]
  }) %>%
  
  image(z=.,zlim=c(0,4),col=viridis(30),x=depsub[,2],y=(1:length(gbo)),ylab="GB")

dev.off()
# par(mfrow=c(2,1),mar=c(2,4,1.5,0.5))

###Sex

# f <- grep("F",sexscore$sex)
# t(t(depsub[,f+2])/scalevec[f]) %>%
#   (function(x){
#     s <- colSums(x)
#     o <- order(s,decreasing=TRUE)
#     x[,o]
#   }) %>%
#   
#   image(z=.,zlim=c(0,4),col=viridis(30),x=depsub[,2],y=(1:length(f)),ylab="F")
# 
# 
# m <- grep("M",sexscore$sex)
# t(t(depsub[,m+2])/scalevec[m]) %>%
#   (function(x){
#     s <- colSums(x)
#     o <- order(s,decreasing=TRUE)
#     x[,o]
#   }) %>%
#   
#   image(z=.,zlim=c(0,4),col=viridis(30),x=depsub[,2],y=(1:length(m)),ylab="M")


####representative graphs
#make representative coverage figures for three individuals,yes/het/no duplication
#264 - homozygous BB
#277 - heterozygous SJ
#19 - no deletion SP
par(mfrow=c(3,1),mar=c(2,2,1.5,0.5))

ind <- 264
subl <- seq(from=10,to=177830,by=10)
plot(dep[subl,2],dep[subl,ind]/scalevec[ind-2],pch=20,cex=.2,ylim=c(0,3))
abline(h=seq(from=0.5,to=2.5,by=0.5),col="darkgray",lwd=2)
points(dep[subl,2],subsmooth(dep[,ind])/scalevec[ind-2],pch=20,cex=.2,col="red")

ind <- 277
subl <- seq(from=10,to=177830,by=10)
plot(dep[subl,2],dep[subl,ind]/scalevec[ind-2],pch=20,cex=.2,ylim=c(0,3))
abline(h=seq(from=0.5,to=2.5,by=0.5),col="darkgray",lwd=2)
points(dep[subl,2],subsmooth(dep[,ind])/scalevec[ind-2],pch=20,cex=.2,col="red")

ind <- 19
subl <- seq(from=10,to=177830,by=10)
plot(dep[subl,2],dep[subl,ind]/scalevec[ind-2],pch=20,cex=.2,ylim=c(0,3))
abline(h=seq(from=0.5,to=2.5,by=0.5),col="darkgray",lwd=2)
points(dep[subl,2],subsmooth(dep[,ind])/scalevec[ind-2],pch=20,cex=.2,col="red")


##Alternative plot
ind1 <- 264
ind2 <- 277
ind3 <- 19
par(mfrow=c(1,1),mar=c(4,4,1.5,0.5))
subl <- seq(from=10,to=177830,by=10)
plot(dep[subl,2],subsmooth(dep[,ind1])/scalevec[ind1-2],pch=20,cex=.3,col="black",ylim=c(0,2.2),
     ylab="Smoothed region coverage",xlab="Location on chromosome1")
abline(h=seq(from=0.5,to=2.5,by=0.5),col="darkgray",lwd=2)
points(dep[subl,2],subsmooth(dep[,ind2])/scalevec[ind2-2],pch=20,cex=.3,col="firebrick2")
points(dep[subl,2],subsmooth(dep[,ind3])/scalevec[ind3-2],pch=20,cex=.3,col="cadetblue3")

legend("bottomright",lty=2,lwd=2,legend=c("wt/wt S2","del/wt IH1","del/del R1"),col=c("cadetblue3","firebrick2","black"),cex=1.4,
       x.intersp = .7,y.intersp = 1)
abline(v=c(729500,806000),lty=2,lwd=2,col="purple")
abline(v=c(728500,730500,765000,767000,805000,807000),lty=2,lwd=2,col="purple")


###returns population frequency given pop,sex,data

freq <- function(df,pop){
  vec <-grepl(pop,colnames(df))
  apply(df[,vec],
        MAR=1,
        FUN=function(x){
          sum(x,na.rm=TRUE)/sum(!is.na(x))/2
        }
  )
}

###make a tree!

Fpopfreqs <- cbind(
  freq(gts,"BB"),
  freq(gts,"VB"),
  freq(gts,"PB"),
  freq(gts,"SJ"),
  freq(gts,"BNP"),
  freq(gts,"SP"),
  freq(gts,"GB")
)
colnames(Fpopfreqs) <- c("BB","VB","PB","SJ","BNP","SP","GB")
Fpopfreqs <- Fpopfreqs[which(rowSums(is.na(Fpopfreqs))==0),]

#using contml
tr <- Rcontml(X=t(Fpopfreqs),path="~/phylip-3.696/exe")

#already ran bootstraps, don't re-run unless necessary. 
#trboot <- boot.phylo(tr,t(Fpopfreqs),FUN=function(x){Rcontml(X=x,path="~/phylip-3.696/exe")},trees=TRUE)

#for some reason boot.phylo calculates BP wrong. 
plot(tr,type="unrooted",show.tip.label=FALSE)
# nodelabels(trboot$BP)
popord <- c(3, 4, 5, 6, 7, 2, 1)
popcol <- c("black","grey","red","darkorange","gold","cyan","blue")
popnames <- c("BB","VB","PB","SJ","BNP","SP","GB")
tiplabels(pch=20,col=popcol[popord],cex=6)
legend("topright",legend=popnames,col=popcol,pch=20,cex=1)

###


trN <- Rgendist(t(Fpopfreqs),path="~/phylip-3.696/exe/") %>% 
  Rneighbor(.,path="~/phylip-3.696/exe/")


trbootN <- boot.phylo(trN,t(Fpopfreqs),FUN=function(x){
  Rgendist(t(Fpopfreqs),path="~/phylip-3.696/exe/") %>% 
    Rneighbor(.,path="~/phylip-3.696/exe/")
},trees=TRUE)

plot(trN,type="unrooted")
nodelabels(trbootN$BP)

```

#Physiology data

##Starting with CYP1A activity

```{r}

#loading in the file----
setwd("~/backup/Elias/Baylor/Papers/11. Gradient and Introgression - DRAFT/Deformity and EROD")

cyp1a<-read.csv("PCB_erod_0.1ppt.csv",header=T)

library(ggplot2)
library(dplyr)

#dotplot of merged pop data----
d<-ggplot(cyp1a,aes(x=sens,y=(resp)/100,fill=sens)) +
  #geom_violin(trim=TRUE, fill="white") +
  geom_dotplot(binaxis='y',stackdir='center',binwidth=.4,
               stackratio=.3,dotsize=35) +
  ggtitle("CYP1A activity at 0.1ppb PCB126")+
  theme_classic()+
  scale_fill_manual(values=c(S="cadetblue3",IL="gold",IH="firebrick2",R="black")) +
  scale_x_discrete(limits=c("S","IL","IH","R"))
d.labs<-d+labs(y="",x="")
larger.thicker<-element_line(color="black",size=3)
d.lines<-d.labs + theme(axis.line.y=larger.thicker,axis.line.x=larger.thicker)
larger.text<-element_text(color="black",size=30)
d.lines+theme(axis.text.y=larger.text)

#boxplot for sensitivity level----
boxplot(cyp1a[,"resp"]~cyp1a[,"sens"],log="y",yaxt='n',
        at=c(2,3,1,4),col=c("firebrick2","gold","black","cadetblue3"),
        cex.axis=1,outline=FALSE,range=TRUE)
box(lwd=5,bty="l")
ticks <- seq(1, 4, by=1)
labels <- sapply(ticks, function(i) as.expression(bquote(10^ .(i))))
axis(side=2, at=c(10, 100, 1000, 10000), labels=labels,las=1)

#boxplot of all pop data----
cyp1a$pop2<-factor(cyp1a$pop, levels=c("BB","VB","PB","SJ","BNP","CB","FP","HP","PG","FB","SP","GB"))

boxplot(cyp1a[,"resp"]~cyp1a[,"pop2"],log="y",yaxt='n',
        col=c(rep("black",3),rep("firebrick2",3),rep("gold",3),rep("cadetblue3",3)),
        cex.axis=1,outline=FALSE,range=TRUE)
box(lwd=5,bty="l")

ticks <- seq(1, 4, by=1)
labels <- sapply(ticks, function(i) as.expression(bquote(10^ .(i))))
axis(side=2, at=c(10, 100, 1000, 10000), labels=labels,las=1)

#USE Violin plot of all pop data----

ticks <- seq(1, 4, by=1)
labels <- sapply(ticks, function(i) as.expression(bquote(10^ .(i))))

ggplot(cyp1a,
       aes(x=pop2,y=log10(resp),fill=pop2,color=pop2))+
  geom_violin(trim=FALSE,draw_quantiles = 0.5,lwd=2)+
  scale_fill_manual(values=c(rep("black",3),rep("firebrick2",3),rep("gold",3),rep("cadetblue3",3)))+
  scale_color_manual(values=c(rep("grey40",3),rep("black",9)))+
  geom_jitter(shape=16,size=3,position=position_jitter(.2))+
  theme_classic()+
  labs(y='',x='')+
  theme(axis.line.y=element_line(color="black",size=3),axis.line=element_line(color="black",size=3))+
  scale_y_continuous(labels=labels,breaks=c(1,2,3,4))+
  theme(axis.text.y=element_text(color="black",size=40))


##LM

cplm=lm(resp~sens,cyp1a)
summary(cplm)

#plotting histogram----
m<-ggplot(cyp1a,aes(x=resp,fill=sens)) + 
  geom_histogram(alpha=.4,aes(y=..density..),position="identity") + 
  ggtitle("CYP1A activity at 0.1ppb PCB126")+
  theme_bw() +
  scale_fill_manual(values=c(S="cadetblue3",IL="gold",IH="firebrick",R="black"))
m

```

# Collaborators
## Recombination rates chromosome 10

Downloaded chr10 table from https://github.com/jthmiller/Reco_rate on June 27th

```{r}
install.packages('xoi')
require(xoi)
chr10<-read.table("~/analysis/data/introgression/CRH10_table.r",sep=',')

window<-1

chr10_1mb<-est.recrate(chr10$cm.pos,chr10$mb.pos,window=window)

write.table(chr10_1mb,"~/analysis/data/introgression/chr10_recrate_1mb_window.csv",sep=",")

```

### Checking on weir high reco rate in the end of region

```{r}
#install.packages('qtl')
library(qtl)

```

## Freq of introgression in pops

* Getting chr10 introgressed region in order to determine haplotype frequencies

* Obtained haplotype region from ##Plotting dxy chunk of code

###Getting VCF of chr10 introgressed region
```{bash}
#!/bin/bash -l

#SBATCH -J c10vcf
#SBATCH -o c10vcf-%j.output
#SBATCH -e c10vcf-%j.output
#SBATCH -N 1
#SBATCH --cpus-per-task=8
#SBATCH -t 1:00:00
#SBATCH --mem=60000

my_tabix=/home/eoziolor/program/htslib/tabix

my_vcf=/home/eoziolor/fgran/data/varcall/chr10_filtered_060218.vcf.bgz
my_out=/home/eoziolor/fgran/data/introgression/chr10_intr.vcf.bgz 

$my_tabix -fh $my_vcf chr10:0-1 | bgzip > $my_out
$my_tabix -f $my_vcf chr10:21507785-29010051 | bgzip >> $my_out
```

### Only keeping individuals needed

```{bash}
#created a small vcf for only individuals I need (three resistant pops and 1 reference)

#!/bin/bash -l

#SBATCH -J freqfilter
#SBATCH -o freqfilter-%j.output
#SBATCH -e freqfilter-%j.output
#SBATCH -N 1
#SBATCH --cpus-per-task=8
#SBATCH -t 24:00:00
#SBATCH --mem=30000

#files and programs
my_vcftools=/home/eoziolor/program/vcftools/bin/vcftools
my_varcall=/home/eoziolor/fgran/data/introgression/chr10_intr.vcf.bgz
outdir=/home/eoziolor/fgran/data/introgression
list=/home/eoziolor/fgran/data/varcall/pops/R2.S2.txt

outfile=chr10_small.vcf.bgz

$my_vcftools --gzvcf $my_varcall \
--keep $list \
--recode \
--stdout |\
bgzip >  $outdir/$outfile

```

### Haploidize function the function I am using to haploidize

```{r}
#what is in haploidize_gran_mine_large.r
#!/usr/bin/env Rscript

library(stringr)
library(magrittr)

sam<-function(x){
      y <- str_split(x,":")[[1]][1] %>% 
    			 unlist() %>% 
    			 as.numeric() 
        return(y)
      }

f <- file("stdin")
#f<-file("~/analysis/data/dfst/outliers/zshared.vcf.bgz")
open(f)
while(length(line <- readLines(f,n=1)) > 0) {
  if(grepl("^#",line)){write(line,stdout());next()}

  line <- str_split(line,"\\t") %>% unlist()
  line[10:585] <- sapply(line[10:585],sam)
  line <- paste(line,collapse="\t")
  write(line,stdout())
  # write(line, stderr())
  # process line
}
```

### Haploidize the introgressed region on chr10

```{bash}
scp -P 2022 farm:/home/eoziolor/fgran/data/introgression/chr10_small.vcf.bgz ~/analysis/data/intro_models/

zcat ~/analysis/data/intro_models/chr10_small.vcf.bgz | ~/analysis/scripts/haplo/haploidize_gran_mine_large.r | gzip > ~/analysis/data/intro_models/chr10_small_haplo.vcf.bgz

```

## Chr10 introgressed population allele frequencies 
* Getting allele frequencies for Chromosome 10 for populations considered under introgression

```{bash}
#making Chr10.vcf.bgz

paste \
<(cat chrompos.txt | cut -f 1,3) \
<(zcat hetgrand.hap.vcf.gz | grep -v ^# ) | \
grep "^chr10" | \
sort -k 2,2n | \
gzip >chr10.txt.gz

#header of hetgrand.vcf.gz will have two less fields because it doesn't have chromosome positoin, remove scaffolds from the chr10

cat \
<(zcat head.vcf.gz | grep "##") \
<(cat header.txt) \
<(zcat chr10.txt.gz | cut -f 1-2,5-587) \
<(cat header.txt) |\
bgzip > chr10.vcf.bgz

#Filtering out non-biallelic snps

#!/bin/bash -l
#SBATCH -J filter
#SBATCH -o filter-%j.output
#SBATCH -e filter-%j.output
#SBATCH -N 1
#SBATCH --cpus-per-task=8
#SBATCH -t 48:00:00
#SBATCH --mem=60000

#files and programs
my_vcftools=/home/eoziolor/program/vcftools/bin/vcftools


my_varcall=/home/eoziolor/fgran/data/varcall/chr10.vcf.bgz
outdir=/home/eoziolor/fgran/data/varcall
outfile=chr10_filtered_060218.vcf.bgz

$my_vcftools --gzvcf $my_varcall \
--minQ 100 \
--min-alleles 2 \
--max-alleles 2 \
--remove-filtered-all \
--recode \
--stdout |\
bgzip > $outdir/$outfile

#Creating lists so that we can "keep" only pop specific freqs

#!/bin/bash -l
#SBATCH -J poplist
#SBATCH -o poplist-%j.output
#SBATCH -e poplist-%j.output
#SBATCH -N 1
#SBATCH --cpus-per-task=8
#SBATCH -t 48:00:00
#SBATCH --mem=60000

#files and programs
my_vcf=/home/eoziolor/fgran/data/varcall/chr10_filtered_060218.vcf.bgz
dir=/home/eoziolor/fgran/data/varcall/pops/

pops=VB\ SP\ ER\ KC\ BP\ F\ BB\ PB

for i in {1..8}
	do theone=$(echo $pops | cut -f $i -d ' ')
	zcat $my_vcf | grep -v "##" | head -n 1 | tr '\t' '\n' | grep $theone > $dir/$theone.txt
done

#be careful, the SP ones catches SJSP too, so change it with

cat SP.txt | grep -v "SJSP" > newSP.txt
mv newSP.txt > SP.txt

#Now getting allele frequencies per pop for the chromosome

#!/bin/bash -l
#SBATCH -J freqfilter
#SBATCH -o freqfilter-%j.output
#SBATCH -e freqfilter-%j.output
#SBATCH -N 1
#SBATCH --cpus-per-task=8
#SBATCH -t 24:00:00
#SBATCH --mem=30000

#files and programs
my_vcftools=/home/eoziolor/program/vcftools/bin/vcftools
my_varcall=/home/eoziolor/fgran/data/varcall/chr10_filtered_060218.vcf.bgz
outdir=/home/eoziolor/fgran/data/varcall
pops=VB\ SP\ ER\ KC\ F\ BP
listdir=/home/eoziolor/fgran/data/varcall/pops

for i in {1..6}

do theone=$(echo $pops | cut -f $i -d ' ')

theonefile=$listdir/$theone.txt

outfile=chr10_freqs.$theone

$my_vcftools --gzvcf $my_varcall \
--keep $theonefile \
--freq \
--out $outdir/$outfile\_060218

done

#only selecting VB and SP to figure out which individuals are with introgression
#!/bin/bash -l

#SBATCH -J freqfilter
#SBATCH -o freqfilter-%j.output
#SBATCH -e freqfilter-%j.output
#SBATCH -N 1
#SBATCH --cpus-per-task=8
#SBATCH -t 24:00:00
#SBATCH --mem=30000

#files and programs
my_vcftools=/home/eoziolor/program/vcftools/bin/vcftools
my_varcall=/home/eoziolor/fgran/data/varcall/chr10_filtered_060218.vcf.bgz
outdir=/home/eoziolor/fgran/data/introgression
list=/home/eoziolor/fgran/data/varcall/pops/R2.S2.txt

outfile=chr10_verysmall_060218.vcf.bgz

$my_vcftools --gzvcf $my_varcall \
--keep $list \
--recode \
--stdout |\
bgzip >  $outdir/$outfile

```

## Frequency of introgression in R2

###Haploidizing the small vcf

```{bash}
zcat ~/analysis/data/intro_models/chr10_verysmall_060218.vcf.bgz | ~/analysis/scripts/haplo/haploidize_gran_mine2_verysmall.r | gzip > ~/analysis/data/intro_models/chr10_verysmall_060218_haplo.vcf.gz
```

### Load haploidized vcf

```{r}
#install.packages("Rphylip")
library(viridis)
library(dplyr)
library(magrittr)
library(Rphylip)
library(ape)
library(stringr)

vcf<-read.table("~/analysis/data/intro_models/chr10_verysmall_060218_haplo.vcf.gz",stringsAsFactors = FALSE) #vcf that has been filtered out to only present one allele call per site per individual
```

### Get header for vcf
```{bash}
zcat ~/analysis/data/intro_models/chr10_verysmall_060218.vcf.bgz | grep -v "##" | head -n 1 > chr10_verysmall_header.txt
```

### Plot introgression frequency
```{r}
sexscore0<-scan("~/analysis/data/intro_models/chr10_verysmall_header.txt",sep='\t',what="character")
sexscore<-sexscore0[10:106]
#toss sites that happen to have more than one allele
keep<-!grepl(",",vcf[,5]) #none because of the way I've called haplotypes table to check that

gt<-as.matrix(vcf[,10:106])
class(gt)<-"numeric"
colnames(gt)<-sexscore

#toss individuals with greater than 90% missing data
keep<-colMeans(is.na(gt))<0.9
gt<-gt[,keep]

#population identifiers
pop<-ifelse(grepl("VB",sexscore),"VB",
            ifelse(grepl("SP",sexscore),"SP","WRONG"))

popcol<-ifelse(grepl("VB",sexscore),"black",
               ifelse(grepl("SP",sexscore),"cadetblue3","WRONG"))

pop2<-pop[keep]
popcol2<-popcol[keep]

popname<-c("VB","SP")
popnamec<-c("black","cadetblue3")
#distance matrix and nj tree
d <- t(gt) %>% dist()
#dd<-as.dist(ultrametric(d)) #imputing data for missing values using ultrametric procedure
mds <- cmdscale(d)
tr <- nj(d)

#plotting tree
plot(tr,"unrooted",show.tip.label=FALSE)
tiplabels(pch=20,col=popcol2,bg="white",cex=1.2)
legend("topright",pch=20,cex=1.2,legend=popname,col=popnamec)

#plotting mds
par(mfrow=c(1,1),mar=c(3,3,0,0))
plot(mds,col=popcol2,cex=2,cex.axis=2,pch=21,
     bg=popcol2,bty='l')
box(bty='l',lwd=5)

legend("topright",legend=c("BB","VB","PB","SJ","BNP","SP","GB"),col=c("black","black","black","firebrick1","firebrick1","cadetblue3","cadetblue3"),
       pch=21,cex=2,y.intersp=.5,bty='n',bg=c("black","grey40","grey80","firebrick1","lightpink","cadetblue1","cadetblue3"))

#Plotting both
par(mfrow=c(1,2))
plot(tr,"unrooted",show.tip.label=FALSE)
tiplabels(pch=20,col=popcol2,bg="white",cex=1.2)
plot(mds,pch=20,col=popcol2)
legend("topleft",pch=20,cex=.8,legend=popname,col=popnamec,y.intersp=.7)

```

###Frequencies for the CHR10 introgressed region

```{r}
#population frequencies calculated over all individuals
popfr<-cbind(vcf[,1:2])
nam<-c("chr","pos","VB","SP")

for(j in 1:length(nam[-1:-2])){
  b<-gt[,grepl(nam[j+2],colnames(gt))]
  f<-as.numeric(rowSums(gt[,grepl(nam[j+2],colnames(gt))],na.rm=TRUE)/ncol(b))
  popfr<-cbind(popfr,f)
  print(nam[j+2])
  print(ncol(b))
}

#frequencies of genotype calculated over whole region
indfr<-c()
for(i in 1:dim(gt)[[2]]){
  indfr[i]<-sum(gt[,i],na.rm=TRUE)/(length(gt[!is.na(gt[,i]),i]))
}

names(indfr)<-colnames(gt)
vb<-grepl("VB",names(indfr))
sp<-grepl("SP",names(indfr))

plot(indfr,col=ifelse(vb==TRUE,"black","cadetblue3"))
abline(h=.4)

intr<-indfr[indfr<0.4] #getting introgressed ind
nonintr<-indfr[indfr>0.4] #getting non-introgressed ind
vbintr<-intr[grepl("VB",names(intr))] #getting only VB introgressed ind
spnonintr<-nonintr[grepl("SP",names(nonintr))] #getting only SP non-intr ind

#getting frequencies only for those
gt_vbintr<-gt[,names(vbintr)]
gt_spnonintr<-gt[,names(spnonintr)]

#getting population frequencies for VB intr
popfr_vbintr<-cbind(vcf[,1:2])
nam<-c("chr","pos","VB")
freq<-c()
for(i in 1:dim(gt_vbintr)[[1]]){
  freq[i]<-sum(gt_vbintr[i,],na.rm=TRUE)/length(gt_vbintr[i,!is.na(gt_vbintr[i,])])
}
popfr_vbintr<-cbind(popfr_vbintr,freq)
colnames(popfr_vbintr)<-c("chr","pos","VBintr")

#getting those for SP non-intr
popfr_spnonintr<-cbind(vcf[,1:2])
nam<-c("chr","pos","VB")
freq<-c()
for(i in 1:dim(gt_spnonintr)[[1]]){
  freq[i]<-sum(gt_spnonintr[i,],na.rm=TRUE)/length(gt_spnonintr[i,!is.na(gt_spnonintr[i,])])
}
popfr_spnonintr<-cbind(popfr_spnonintr,freq)
colnames(popfr_spnonintr)<-c("chr","pos","SPnonintr")

#writing list of individuals (VBintr and SPnonintr) so that we can get frequencies for the whole chr10
vbintrlist<-names(vbintr)
spnonintrlist<-names(spnonintr)

write.table(vbintrlist,"~/analysis/data/intro_models/vbintr.txt",sep='\n',quote = FALSE,row.names = FALSE,col.names = FALSE)
write.table(spnonintrlist,"~/analysis/data/intro_models/spnonintr.txt",sep='\n',quote = FALSE,row.names = FALSE,col.names = FALSE)
```

###Chr10 frequencies for only VB introgressed and SP nonintrogressed individuals
* import those into farm

```{bash}
scp -P 2022 /home/elias/analysis/data/intro_models/*intr.txt farm:/home/eoziolor/fgran/data/varcall/pops/
```

* do these only for VB intr and SP nonintr

```{bash}
#!/bin/bash -l

#SBATCH -J freqfilter
#SBATCH -o freqfilter-%j.output
#SBATCH -e freqfilter-%j.output
#SBATCH -N 1
#SBATCH --cpus-per-task=8
#SBATCH -t 24:00:00
#SBATCH --mem=30000

#files and programs
my_vcftools=/home/eoziolor/program/vcftools/bin/vcftools
my_varcall=/home/eoziolor/fgran/data/varcall/chr10_filtered_060218.vcf.bgz
outdir=/home/eoziolor/fgran/data/varcall
pops=vbintr\ spnonintr
listdir=/home/eoziolor/fgran/data/varcall/pops

for i in {1..2}

do theone=$(echo $pops | cut -f $i -d ' ')

theonefile=$listdir/$theone.txt

outfile=chr10_freqs_060218.$theone

$my_vcftools --gzvcf $my_varcall \
--keep $theonefile \
--freq \
--out $outdir/$outfile

done
```

* copy into computer to send to Sivan

```{bash}
scp -P 2022 farm:/home/eoziolor/fgran/data/varcall/*intr.frq /home/elias/analysis/data/intro_models/
```
